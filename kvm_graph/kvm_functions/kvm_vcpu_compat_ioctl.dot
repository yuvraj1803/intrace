// subgraph node: kvm_vcpu_compat_ioctl
// subgraph edge: kvm_vcpu_compat_ioctl->copy_from_user
// subgraph node: copy_from_user
// subgraph edge: kvm_vcpu_compat_ioctl->compat_ptr
// subgraph node: compat_ptr
// subgraph edge: kvm_vcpu_compat_ioctl->get_compat_sigset
// subgraph node: get_compat_sigset
// subgraph edge: kvm_vcpu_compat_ioctl->kvm_vcpu_ioctl_set_sigmask
// subgraph node: kvm_vcpu_ioctl_set_sigmask
// subgraph edge: kvm_vcpu_ioctl_set_sigmask->sigdelsetmask
// subgraph node: sigdelsetmask
// subgraph edge: kvm_vcpu_ioctl_set_sigmask->sigmask
// subgraph node: sigmask
// subgraph edge: kvm_vcpu_compat_ioctl->kvm_vcpu_ioctl
// subgraph node: kvm_vcpu_ioctl
// subgraph edge: kvm_vcpu_ioctl->unlikely
// subgraph node: unlikely
// subgraph edge: kvm_vcpu_ioctl->IS_ERR
// subgraph node: IS_ERR
// subgraph edge: kvm_vcpu_ioctl->PTR_ERR
// subgraph node: PTR_ERR
// subgraph edge: kvm_vcpu_ioctl->kfree
// subgraph node: kfree
// subgraph edge: kvm_vcpu_ioctl->mutex_unlock
// subgraph node: mutex_unlock
// subgraph edge: kvm_vcpu_ioctl->kzalloc
// subgraph node: kzalloc
// subgraph edge: kvm_vcpu_ioctl->rcu_access_pointer
// subgraph node: rcu_access_pointer
// subgraph edge: kvm_vcpu_ioctl->put_pid
// subgraph node: put_pid
// subgraph edge: kvm_vcpu_ioctl->rcu_assign_pointer
// subgraph node: rcu_assign_pointer
// subgraph edge: kvm_vcpu_ioctl->copy_from_user
// subgraph edge: kvm_vcpu_ioctl->copy_to_user
// subgraph node: copy_to_user
// subgraph edge: kvm_vcpu_ioctl->kvm_vcpu_ioctl_set_sigmask
// subgraph edge: kvm_vcpu_ioctl->kvm_arch_vcpu_async_ioctl
// subgraph node: kvm_arch_vcpu_async_ioctl
// subgraph edge: kvm_vcpu_ioctl->mutex_lock_killable
// subgraph node: mutex_lock_killable
// subgraph edge: kvm_vcpu_ioctl->task_pid
// subgraph node: task_pid
// subgraph edge: kvm_vcpu_ioctl->kvm_arch_vcpu_run_pid_change
// subgraph node: kvm_arch_vcpu_run_pid_change
// subgraph edge: kvm_arch_vcpu_run_pid_change->likely
// subgraph node: likely
// subgraph edge: kvm_arch_vcpu_run_pid_change->irqchip_in_kernel
// subgraph node: irqchip_in_kernel
// subgraph edge: kvm_arch_vcpu_run_pid_change->is_protected_kvm_enabled
// subgraph node: is_protected_kvm_enabled
// subgraph edge: kvm_arch_vcpu_run_pid_change->mutex_lock
// subgraph node: mutex_lock
// subgraph edge: kvm_arch_vcpu_run_pid_change->mutex_unlock
// subgraph edge: kvm_arch_vcpu_run_pid_change->kvm_call_hyp_nvhe
// subgraph node: kvm_call_hyp_nvhe
// subgraph edge: kvm_arch_vcpu_run_pid_change->vcpu_has_run_once
// subgraph node: vcpu_has_run_once
// subgraph edge: kvm_arch_vcpu_run_pid_change->kvm_vcpu_initialized
// subgraph node: kvm_vcpu_initialized
// subgraph edge: kvm_vcpu_initialized->vcpu_get_flag
// subgraph node: vcpu_get_flag
// subgraph edge: kvm_arch_vcpu_run_pid_change->kvm_arm_vcpu_is_finalized
// subgraph node: kvm_arm_vcpu_is_finalized
// subgraph edge: kvm_arm_vcpu_is_finalized->vcpu_has_sve
// subgraph node: vcpu_has_sve
// subgraph edge: kvm_arm_vcpu_is_finalized->kvm_arm_vcpu_sve_finalized
// subgraph node: kvm_arm_vcpu_sve_finalized
// subgraph edge: kvm_arch_vcpu_run_pid_change->kvm_arch_vcpu_run_map_fp
// subgraph node: kvm_arch_vcpu_run_map_fp
// subgraph edge: kvm_arch_vcpu_run_map_fp->is_protected_kvm_enabled
// subgraph edge: kvm_arch_vcpu_run_map_fp->kern_hyp_va
// subgraph node: kern_hyp_va
// subgraph edge: kvm_arch_vcpu_run_map_fp->kvm_vcpu_unshare_task_fp
// subgraph node: kvm_vcpu_unshare_task_fp
// subgraph edge: kvm_vcpu_unshare_task_fp->is_protected_kvm_enabled
// subgraph edge: kvm_vcpu_unshare_task_fp->kvm_unshare_hyp
// subgraph node: kvm_unshare_hyp
// subgraph edge: kvm_unshare_hyp->WARN_ON
// subgraph node: WARN_ON
// subgraph edge: kvm_unshare_hyp->is_kernel_in_hyp_mode
// subgraph node: is_kernel_in_hyp_mode
// subgraph edge: kvm_unshare_hyp->ALIGN_DOWN
// subgraph node: ALIGN_DOWN
// subgraph edge: kvm_unshare_hyp->kvm_host_owns_hyp_mappings
// subgraph node: kvm_host_owns_hyp_mappings
// subgraph edge: kvm_host_owns_hyp_mappings->WARN_ON
// subgraph edge: kvm_host_owns_hyp_mappings->is_protected_kvm_enabled
// subgraph edge: kvm_host_owns_hyp_mappings->is_kernel_in_hyp_mode
// subgraph edge: kvm_host_owns_hyp_mappings->static_branch_likely
// subgraph node: static_branch_likely
// subgraph edge: kvm_unshare_hyp->PAGE_ALIGN
// subgraph node: PAGE_ALIGN
// subgraph edge: kvm_unshare_hyp->unshare_pfn_hyp
// subgraph node: unshare_pfn_hyp
// subgraph edge: unshare_pfn_hyp->WARN_ON
// subgraph edge: unshare_pfn_hyp->kfree
// subgraph edge: unshare_pfn_hyp->mutex_lock
// subgraph edge: unshare_pfn_hyp->mutex_unlock
// subgraph edge: unshare_pfn_hyp->kvm_call_hyp_nvhe
// subgraph edge: unshare_pfn_hyp->find_shared_pfn
// subgraph node: find_shared_pfn
// subgraph edge: find_shared_pfn->container_of
// subgraph node: container_of
// subgraph edge: unshare_pfn_hyp->rb_erase
// subgraph node: rb_erase
// subgraph edge: kvm_vcpu_unshare_task_fp->put_task_struct
// subgraph node: put_task_struct
// subgraph edge: kvm_arch_vcpu_run_map_fp->kvm_share_hyp
// subgraph node: kvm_share_hyp
// subgraph edge: kvm_share_hyp->is_kernel_in_hyp_mode
// subgraph edge: kvm_share_hyp->create_hyp_mappings
// subgraph node: create_hyp_mappings
// subgraph edge: create_hyp_mappings->is_kernel_in_hyp_mode
// subgraph edge: create_hyp_mappings->kern_hyp_va
// subgraph edge: create_hyp_mappings->kvm_host_owns_hyp_mappings
// subgraph edge: create_hyp_mappings->PAGE_ALIGN
// subgraph edge: create_hyp_mappings->kvm_kaddr_to_phys
// subgraph node: kvm_kaddr_to_phys
// subgraph edge: kvm_kaddr_to_phys->BUG_ON
// subgraph node: BUG_ON
// subgraph edge: kvm_kaddr_to_phys->is_vmalloc_addr
// subgraph node: is_vmalloc_addr
// subgraph edge: kvm_kaddr_to_phys->virt_addr_valid
// subgraph node: virt_addr_valid
// subgraph edge: kvm_kaddr_to_phys->page_to_phys
// subgraph node: page_to_phys
// subgraph edge: kvm_kaddr_to_phys->vmalloc_to_page
// subgraph node: vmalloc_to_page
// subgraph edge: kvm_kaddr_to_phys->offset_in_page
// subgraph node: offset_in_page
// subgraph edge: kvm_share_hyp->ALIGN_DOWN
// subgraph edge: kvm_share_hyp->kvm_host_owns_hyp_mappings
// subgraph edge: kvm_share_hyp->PAGE_ALIGN
// subgraph edge: kvm_share_hyp->is_vmalloc_or_module_addr
// subgraph node: is_vmalloc_or_module_addr
// subgraph edge: kvm_share_hyp->share_pfn_hyp
// subgraph node: share_pfn_hyp
// subgraph edge: share_pfn_hyp->mutex_lock
// subgraph edge: share_pfn_hyp->mutex_unlock
// subgraph edge: share_pfn_hyp->kvm_call_hyp_nvhe
// subgraph edge: share_pfn_hyp->kzalloc
// subgraph edge: share_pfn_hyp->find_shared_pfn
// subgraph edge: share_pfn_hyp->rb_link_node
// subgraph node: rb_link_node
// subgraph edge: share_pfn_hyp->rb_insert_color
// subgraph node: rb_insert_color
// subgraph edge: kvm_arch_vcpu_run_map_fp->get_task_struct
// subgraph node: get_task_struct
// subgraph edge: kvm_arch_vcpu_run_pid_change->kvm_init_mpidr_data
// subgraph node: kvm_init_mpidr_data
// subgraph edge: kvm_init_mpidr_data->BIT_ULL
// subgraph node: BIT_ULL
// subgraph edge: kvm_init_mpidr_data->mutex_lock
// subgraph edge: kvm_init_mpidr_data->mutex_unlock
// subgraph edge: kvm_init_mpidr_data->kvm_for_each_vcpu
// subgraph node: kvm_for_each_vcpu
// subgraph edge: kvm_init_mpidr_data->kvm_mpidr_index
// subgraph node: kvm_mpidr_index
// subgraph edge: kvm_init_mpidr_data->kvm_vcpu_get_mpidr_aff
// subgraph node: kvm_vcpu_get_mpidr_aff
// subgraph edge: kvm_init_mpidr_data->kzalloc
// subgraph edge: kvm_init_mpidr_data->atomic_read
// subgraph node: atomic_read
// subgraph edge: kvm_init_mpidr_data->hweight_long
// subgraph node: hweight_long
// subgraph edge: kvm_init_mpidr_data->struct_size
// subgraph node: struct_size
// subgraph edge: kvm_arch_vcpu_run_pid_change->kvm_arm_vcpu_init_debug
// subgraph node: kvm_arm_vcpu_init_debug
// subgraph edge: kvm_arm_vcpu_init_debug->preempt_disable
// subgraph node: preempt_disable
// subgraph edge: kvm_arm_vcpu_init_debug->preempt_enable
// subgraph node: preempt_enable
// subgraph edge: kvm_arm_vcpu_init_debug->kvm_arm_setup_mdcr_el2
// subgraph node: kvm_arm_setup_mdcr_el2
// subgraph edge: kvm_arm_setup_mdcr_el2->vcpu_get_flag
// subgraph edge: kvm_arm_setup_mdcr_el2->kvm_vcpu_os_lock_enabled
// subgraph node: kvm_vcpu_os_lock_enabled
// subgraph edge: kvm_arm_setup_mdcr_el2->trace_kvm_arm_set_dreg32
// subgraph node: trace_kvm_arm_set_dreg32
// subgraph edge: kvm_arch_vcpu_run_pid_change->kvm_vgic_map_resources
// subgraph node: kvm_vgic_map_resources
// subgraph edge: kvm_arch_vcpu_run_pid_change->kvm_timer_enable
// subgraph node: kvm_timer_enable
// subgraph edge: kvm_timer_enable->get_timer_map
// subgraph node: get_timer_map
// subgraph edge: get_timer_map->vcpu_has_nv
// subgraph node: vcpu_has_nv
// subgraph edge: get_timer_map->is_hyp_ctxt
// subgraph node: is_hyp_ctxt
// subgraph edge: get_timer_map->vcpu_hvtimer
// subgraph node: vcpu_hvtimer
// subgraph edge: get_timer_map->vcpu_hptimer
// subgraph node: vcpu_hptimer
// subgraph edge: get_timer_map->vcpu_vtimer
// subgraph node: vcpu_vtimer
// subgraph edge: get_timer_map->vcpu_ptimer
// subgraph node: vcpu_ptimer
// subgraph edge: get_timer_map->has_vhe
// subgraph node: has_vhe
// subgraph edge: get_timer_map->trace_kvm_get_timer_map
// subgraph node: trace_kvm_get_timer_map
// subgraph edge: kvm_timer_enable->timer_irq
// subgraph node: timer_irq
// subgraph edge: kvm_timer_enable->irqchip_in_kernel
// subgraph edge: kvm_timer_enable->vcpu_timer
// subgraph node: vcpu_timer
// subgraph edge: kvm_timer_enable->kvm_debug
// subgraph node: kvm_debug
// subgraph edge: kvm_timer_enable->kvm_vgic_map_phys_irq
// subgraph node: kvm_vgic_map_phys_irq
// subgraph edge: kvm_timer_enable->timer_irqs_are_valid
// subgraph node: timer_irqs_are_valid
// subgraph edge: timer_irqs_are_valid->bool
// subgraph node: bool
// subgraph edge: timer_irqs_are_valid->mutex_lock
// subgraph edge: timer_irqs_are_valid->mutex_unlock
// subgraph edge: timer_irqs_are_valid->nr_timers
// subgraph node: nr_timers
// subgraph edge: nr_timers->vcpu_has_nv
// subgraph edge: timer_irqs_are_valid->set_bit
// subgraph node: set_bit
// subgraph edge: timer_irqs_are_valid->hweight32
// subgraph node: hweight32
// subgraph edge: kvm_arch_vcpu_run_pid_change->kvm_arm_pmu_v3_enable
// subgraph node: kvm_arm_pmu_v3_enable
// subgraph edge: kvm_arm_pmu_v3_enable->irqchip_in_kernel
// subgraph edge: kvm_arm_pmu_v3_enable->kvm_vcpu_has_pmu
// subgraph node: kvm_vcpu_has_pmu
// subgraph edge: kvm_arm_pmu_v3_enable->kvm_make_request
// subgraph node: kvm_make_request
// subgraph edge: kvm_arm_pmu_v3_enable->irq_is_ppi
// subgraph node: irq_is_ppi
// subgraph edge: kvm_arm_pmu_v3_enable->vgic_valid_spi
// subgraph node: vgic_valid_spi
// subgraph edge: kvm_arm_pmu_v3_enable->kvm_arm_pmu_irq_initialized
// subgraph node: kvm_arm_pmu_irq_initialized
// subgraph edge: kvm_arch_vcpu_run_pid_change->pkvm_create_hyp_vm
// subgraph node: pkvm_create_hyp_vm
// subgraph edge: pkvm_create_hyp_vm->mutex_lock
// subgraph edge: pkvm_create_hyp_vm->mutex_unlock
// subgraph edge: kvm_arch_vcpu_run_pid_change->static_branch_inc
// subgraph node: static_branch_inc
// subgraph edge: kvm_arch_vcpu_run_pid_change->kvm_vm_is_protected
// subgraph node: kvm_vm_is_protected
// subgraph edge: kvm_arch_vcpu_run_pid_change->set_bit
// subgraph edge: kvm_vcpu_ioctl->get_task_pid
// subgraph node: get_task_pid
// subgraph edge: kvm_vcpu_ioctl->synchronize_rcu
// subgraph node: synchronize_rcu
// subgraph edge: kvm_vcpu_ioctl->kvm_arch_vcpu_ioctl_run
// subgraph node: kvm_arch_vcpu_ioctl_run
// subgraph edge: kvm_arch_vcpu_ioctl_run->vcpu_get_flag
// subgraph edge: kvm_arch_vcpu_ioctl_run->preempt_disable
// subgraph edge: kvm_arch_vcpu_ioctl_run->preempt_enable
// subgraph edge: kvm_arch_vcpu_ioctl_run->has_vhe
// subgraph edge: kvm_arch_vcpu_ioctl_run->static_branch_unlikely
// subgraph node: static_branch_unlikely
// subgraph edge: kvm_arch_vcpu_ioctl_run->unlikely
// subgraph edge: kvm_arch_vcpu_ioctl_run->irqchip_in_kernel
// subgraph edge: kvm_arch_vcpu_ioctl_run->isb
// subgraph node: isb
// subgraph edge: kvm_arch_vcpu_ioctl_run->kvm_call_hyp
// subgraph node: kvm_call_hyp
// subgraph edge: kvm_arch_vcpu_ioctl_run->vcpu_pc
// subgraph node: vcpu_pc
// subgraph edge: kvm_arch_vcpu_ioctl_run->vcpu_clear_flag
// subgraph node: vcpu_clear_flag
// subgraph edge: kvm_arch_vcpu_ioctl_run->kvm_vcpu_trap_get_class
// subgraph node: kvm_vcpu_trap_get_class
// subgraph edge: kvm_arch_vcpu_ioctl_run->kvm_handle_mmio_return
// subgraph node: kvm_handle_mmio_return
// subgraph edge: kvm_handle_mmio_return->unlikely
// subgraph edge: kvm_handle_mmio_return->vcpu_set_reg
// subgraph node: vcpu_set_reg
// subgraph edge: kvm_handle_mmio_return->kvm_incr_pc
// subgraph node: kvm_incr_pc
// subgraph edge: kvm_handle_mmio_return->kvm_vcpu_dabt_iswrite
// subgraph node: kvm_vcpu_dabt_iswrite
// subgraph edge: kvm_handle_mmio_return->kvm_vcpu_dabt_get_as
// subgraph node: kvm_vcpu_dabt_get_as
// subgraph edge: kvm_handle_mmio_return->kvm_vcpu_dabt_get_rd
// subgraph node: kvm_vcpu_dabt_get_rd
// subgraph edge: kvm_handle_mmio_return->trace_kvm_mmio
// subgraph node: trace_kvm_mmio
// subgraph edge: kvm_handle_mmio_return->kvm_mmio_read_buf
// subgraph node: kvm_mmio_read_buf
// subgraph edge: kvm_mmio_read_buf->memcpy
// subgraph node: memcpy
// subgraph edge: kvm_handle_mmio_return->kvm_vcpu_dabt_issext
// subgraph node: kvm_vcpu_dabt_issext
// subgraph edge: kvm_handle_mmio_return->kvm_vcpu_dabt_issf
// subgraph node: kvm_vcpu_dabt_issf
// subgraph edge: kvm_handle_mmio_return->vcpu_data_host_to_guest
// subgraph node: vcpu_data_host_to_guest
// subgraph edge: kvm_arch_vcpu_ioctl_run->vcpu_load
// subgraph node: vcpu_load
// subgraph edge: vcpu_load->get_cpu
// subgraph node: get_cpu
// subgraph edge: vcpu_load->put_cpu
// subgraph node: put_cpu
// subgraph edge: vcpu_load->kvm_arch_vcpu_load
// subgraph node: kvm_arch_vcpu_load
// subgraph edge: kvm_arch_vcpu_load->has_vhe
// subgraph edge: kvm_arch_vcpu_load->kvm_call_hyp
// subgraph edge: kvm_arch_vcpu_load->kvm_vcpu_pmu_restore_guest
// subgraph node: kvm_vcpu_pmu_restore_guest
// subgraph edge: kvm_vcpu_pmu_restore_guest->preempt_disable
// subgraph edge: kvm_vcpu_pmu_restore_guest->preempt_enable
// subgraph edge: kvm_vcpu_pmu_restore_guest->has_vhe
// subgraph edge: kvm_vcpu_pmu_restore_guest->kvm_arm_support_pmu_v3
// subgraph node: kvm_arm_support_pmu_v3
// subgraph edge: kvm_vcpu_pmu_restore_guest->kvm_get_pmu_events
// subgraph node: kvm_get_pmu_events
// subgraph edge: kvm_get_pmu_events->this_cpu_ptr
// subgraph node: this_cpu_ptr
// subgraph edge: kvm_vcpu_pmu_restore_guest->kvm_vcpu_pmu_enable_el0
// subgraph node: kvm_vcpu_pmu_enable_el0
// subgraph edge: kvm_vcpu_pmu_enable_el0->for_each_set_bit
// subgraph node: for_each_set_bit
// subgraph edge: kvm_vcpu_pmu_enable_el0->kvm_vcpu_pmu_read_evtype_direct
// subgraph node: kvm_vcpu_pmu_read_evtype_direct
// subgraph edge: kvm_vcpu_pmu_read_evtype_direct->WARN_ON
// subgraph edge: kvm_vcpu_pmu_read_evtype_direct->read_sysreg
// subgraph node: read_sysreg
// subgraph edge: kvm_vcpu_pmu_read_evtype_direct->PMEVTYPER_CASES
// subgraph node: PMEVTYPER_CASES
// subgraph edge: kvm_vcpu_pmu_enable_el0->kvm_vcpu_pmu_write_evtype_direct
// subgraph node: kvm_vcpu_pmu_write_evtype_direct
// subgraph edge: kvm_vcpu_pmu_write_evtype_direct->WARN_ON
// subgraph edge: kvm_vcpu_pmu_write_evtype_direct->PMEVTYPER_CASES
// subgraph edge: kvm_vcpu_pmu_write_evtype_direct->write_sysreg
// subgraph node: write_sysreg
// subgraph edge: kvm_vcpu_pmu_restore_guest->kvm_vcpu_pmu_disable_el0
// subgraph node: kvm_vcpu_pmu_disable_el0
// subgraph edge: kvm_vcpu_pmu_disable_el0->for_each_set_bit
// subgraph edge: kvm_vcpu_pmu_disable_el0->kvm_vcpu_pmu_read_evtype_direct
// subgraph edge: kvm_vcpu_pmu_disable_el0->kvm_vcpu_pmu_write_evtype_direct
// subgraph edge: kvm_arch_vcpu_load->kvm_make_request
// subgraph edge: kvm_arch_vcpu_load->this_cpu_ptr
// subgraph edge: kvm_arch_vcpu_load->kvm_vgic_load
// subgraph node: kvm_vgic_load
// subgraph edge: kvm_arch_vcpu_load->kvm_timer_vcpu_load
// subgraph node: kvm_timer_vcpu_load
// subgraph edge: kvm_timer_vcpu_load->vcpu_has_nv
// subgraph edge: kvm_timer_vcpu_load->get_timer_map
// subgraph edge: kvm_timer_vcpu_load->timer_emulate
// subgraph node: timer_emulate
// subgraph edge: timer_emulate->bool
// subgraph edge: timer_emulate->kvm_timer_should_fire
// subgraph node: kvm_timer_should_fire
// subgraph edge: kvm_timer_should_fire->kvm_phys_timer_read
// subgraph node: kvm_phys_timer_read
// subgraph edge: kvm_timer_should_fire->timer_get_offset
// subgraph node: timer_get_offset
// subgraph edge: kvm_timer_should_fire->arch_timer_ctx_index
// subgraph node: arch_timer_ctx_index
// subgraph edge: kvm_timer_should_fire->kvm_timer_irq_can_fire
// subgraph node: kvm_timer_irq_can_fire
// subgraph edge: kvm_timer_irq_can_fire->WARN_ON
// subgraph edge: kvm_timer_irq_can_fire->timer_get_ctl
// subgraph node: timer_get_ctl
// subgraph edge: timer_get_ctl->arch_timer_ctx_index
// subgraph edge: timer_get_ctl->WARN_ON
// subgraph edge: kvm_timer_should_fire->read_sysreg_el0
// subgraph node: read_sysreg_el0
// subgraph edge: kvm_timer_should_fire->timer_get_cval
// subgraph node: timer_get_cval
// subgraph edge: timer_get_cval->arch_timer_ctx_index
// subgraph edge: timer_get_cval->WARN_ON
// subgraph edge: timer_emulate->trace_kvm_timer_emulate
// subgraph node: trace_kvm_timer_emulate
// subgraph edge: timer_emulate->kvm_timer_update_irq
// subgraph node: kvm_timer_update_irq
// subgraph edge: kvm_timer_update_irq->WARN_ON
// subgraph edge: kvm_timer_update_irq->trace_kvm_timer_update_irq
// subgraph node: trace_kvm_timer_update_irq
// subgraph edge: kvm_timer_update_irq->timer_irq
// subgraph edge: kvm_timer_update_irq->userspace_irqchip
// subgraph node: userspace_irqchip
// subgraph edge: userspace_irqchip->static_branch_unlikely
// subgraph edge: userspace_irqchip->unlikely
// subgraph edge: userspace_irqchip->irqchip_in_kernel
// subgraph edge: kvm_timer_update_irq->kvm_vgic_inject_irq
// subgraph node: kvm_vgic_inject_irq
// subgraph edge: timer_emulate->kvm_timer_irq_can_fire
// subgraph edge: timer_emulate->soft_timer_start
// subgraph node: soft_timer_start
// subgraph edge: soft_timer_start->hrtimer_start
// subgraph node: hrtimer_start
// subgraph edge: soft_timer_start->ktime_add_ns
// subgraph node: ktime_add_ns
// subgraph edge: soft_timer_start->ktime_get
// subgraph node: ktime_get
// subgraph edge: timer_emulate->kvm_timer_compute_delta
// subgraph node: kvm_timer_compute_delta
// subgraph edge: kvm_timer_compute_delta->timer_get_cval
// subgraph edge: kvm_timer_compute_delta->kvm_counter_compute_delta
// subgraph node: kvm_counter_compute_delta
// subgraph edge: kvm_counter_compute_delta->kvm_phys_timer_read
// subgraph edge: kvm_counter_compute_delta->timer_get_offset
// subgraph edge: kvm_counter_compute_delta->cyclecounter_cyc2ns
// subgraph node: cyclecounter_cyc2ns
// subgraph edge: kvm_timer_vcpu_load->timer_restore_state
// subgraph node: timer_restore_state
// subgraph edge: timer_restore_state->BUG
// subgraph node: BUG
// subgraph edge: timer_restore_state->timer_get_offset
// subgraph edge: timer_restore_state->arch_timer_ctx_index
// subgraph edge: timer_restore_state->timer_get_cval
// subgraph edge: timer_restore_state->timer_get_ctl
// subgraph edge: timer_restore_state->vcpu_timer
// subgraph edge: timer_restore_state->local_irq_save
// subgraph node: local_irq_save
// subgraph edge: timer_restore_state->write_sysreg_el0
// subgraph node: write_sysreg_el0
// subgraph edge: timer_restore_state->isb
// subgraph edge: timer_restore_state->set_cntvoff
// subgraph node: set_cntvoff
// subgraph edge: set_cntvoff->kvm_call_hyp
// subgraph edge: timer_restore_state->set_cntpoff
// subgraph node: set_cntpoff
// subgraph edge: set_cntpoff->has_cntpoff
// subgraph node: has_cntpoff
// subgraph edge: set_cntpoff->write_sysreg_s
// subgraph node: write_sysreg_s
// subgraph edge: timer_restore_state->local_irq_restore
// subgraph node: local_irq_restore
// subgraph edge: timer_restore_state->trace_kvm_timer_restore_state
// subgraph node: trace_kvm_timer_restore_state
// subgraph edge: kvm_timer_vcpu_load->unlikely
// subgraph edge: kvm_timer_vcpu_load->vcpu_timer
// subgraph edge: kvm_timer_vcpu_load->static_branch_likely
// subgraph edge: kvm_timer_vcpu_load->kvm_timer_vcpu_load_nested_switch
// subgraph node: kvm_timer_vcpu_load_nested_switch
// subgraph edge: kvm_timer_vcpu_load_nested_switch->vcpu_hvtimer
// subgraph edge: kvm_timer_vcpu_load_nested_switch->timer_irq
// subgraph edge: kvm_timer_vcpu_load_nested_switch->irqchip_in_kernel
// subgraph edge: kvm_timer_vcpu_load_nested_switch->vcpu_el2_e2h_is_set
// subgraph node: vcpu_el2_e2h_is_set
// subgraph edge: kvm_timer_vcpu_load_nested_switch->WARN_ON_ONCE
// subgraph node: WARN_ON_ONCE
// subgraph edge: kvm_timer_vcpu_load_nested_switch->kvm_vgic_get_map
// subgraph node: kvm_vgic_get_map
// subgraph edge: kvm_timer_vcpu_load_nested_switch->kvm_vgic_unmap_phys_irq
// subgraph node: kvm_vgic_unmap_phys_irq
// subgraph edge: kvm_timer_vcpu_load_nested_switch->kvm_vgic_map_phys_irq
// subgraph edge: kvm_timer_vcpu_load->kvm_timer_vcpu_load_gic
// subgraph node: kvm_timer_vcpu_load_gic
// subgraph edge: kvm_timer_vcpu_load_gic->bool
// subgraph edge: kvm_timer_vcpu_load_gic->kvm_timer_should_fire
// subgraph edge: kvm_timer_vcpu_load_gic->kvm_timer_update_irq
// subgraph edge: kvm_timer_vcpu_load_gic->timer_irq
// subgraph edge: kvm_timer_vcpu_load_gic->irqchip_in_kernel
// subgraph edge: kvm_timer_vcpu_load_gic->kvm_vgic_map_is_active
// subgraph node: kvm_vgic_map_is_active
// subgraph edge: kvm_timer_vcpu_load_gic->set_timer_irq_phys_active
// subgraph node: set_timer_irq_phys_active
// subgraph edge: set_timer_irq_phys_active->WARN_ON
// subgraph edge: set_timer_irq_phys_active->irq_set_irqchip_state
// subgraph node: irq_set_irqchip_state
// subgraph edge: kvm_timer_vcpu_load->kvm_timer_vcpu_load_nogic
// subgraph node: kvm_timer_vcpu_load_nogic
// subgraph edge: kvm_timer_vcpu_load_nogic->vcpu_vtimer
// subgraph edge: kvm_timer_vcpu_load_nogic->kvm_timer_should_fire
// subgraph edge: kvm_timer_vcpu_load_nogic->kvm_timer_update_irq
// subgraph edge: kvm_timer_vcpu_load_nogic->disable_percpu_irq
// subgraph node: disable_percpu_irq
// subgraph edge: kvm_timer_vcpu_load_nogic->enable_percpu_irq
// subgraph node: enable_percpu_irq
// subgraph edge: kvm_timer_vcpu_load->kvm_timer_unblocking
// subgraph node: kvm_timer_unblocking
// subgraph edge: kvm_timer_unblocking->soft_timer_cancel
// subgraph node: soft_timer_cancel
// subgraph edge: soft_timer_cancel->hrtimer_cancel
// subgraph node: hrtimer_cancel
// subgraph edge: kvm_timer_unblocking->vcpu_timer
// subgraph edge: kvm_timer_vcpu_load->timer_set_traps
// subgraph node: timer_set_traps
// subgraph edge: timer_set_traps->vcpu_has_nv
// subgraph edge: timer_set_traps->is_hyp_ctxt
// subgraph edge: timer_set_traps->has_vhe
// subgraph edge: timer_set_traps->timer_get_offset
// subgraph edge: timer_set_traps->bool
// subgraph edge: timer_set_traps->has_cntpoff
// subgraph edge: timer_set_traps->vcpu_el2_e2h_is_set
// subgraph edge: timer_set_traps->sysreg_clear_set
// subgraph node: sysreg_clear_set
// subgraph edge: timer_set_traps->assign_clear_set_bit
// subgraph node: assign_clear_set_bit
// subgraph edge: kvm_arch_vcpu_load->kvm_vcpu_load_vhe
// subgraph node: kvm_vcpu_load_vhe
// subgraph edge: kvm_arch_vcpu_load->kvm_arch_vcpu_load_fp
// subgraph node: kvm_arch_vcpu_load_fp
// subgraph edge: kvm_arch_vcpu_load_fp->BUG_ON
// subgraph edge: kvm_arch_vcpu_load_fp->read_sysreg
// subgraph edge: kvm_arch_vcpu_load_fp->vcpu_clear_flag
// subgraph edge: kvm_arch_vcpu_load_fp->system_supports_sme
// subgraph node: system_supports_sme
// subgraph edge: kvm_arch_vcpu_load_fp->fpsimd_save_and_flush_cpu_state
// subgraph node: fpsimd_save_and_flush_cpu_state
// subgraph edge: kvm_arch_vcpu_load_fp->system_supports_fpsimd
// subgraph node: system_supports_fpsimd
// subgraph edge: kvm_arch_vcpu_load_fp->fpsimd_kvm_prepare
// subgraph node: fpsimd_kvm_prepare
// subgraph edge: kvm_arch_vcpu_load_fp->vcpu_set_flag
// subgraph node: vcpu_set_flag
// subgraph edge: kvm_arch_vcpu_load_fp->read_sysreg_s
// subgraph node: read_sysreg_s
// subgraph edge: kvm_arch_vcpu_load->kvm_arm_is_pvtime_enabled
// subgraph node: kvm_arm_is_pvtime_enabled
// subgraph edge: kvm_arch_vcpu_load->single_task_running
// subgraph node: single_task_running
// subgraph edge: kvm_arch_vcpu_load->vcpu_clear_wfx_traps
// subgraph node: vcpu_clear_wfx_traps
// subgraph edge: kvm_arch_vcpu_load->vcpu_set_wfx_traps
// subgraph node: vcpu_set_wfx_traps
// subgraph edge: kvm_arch_vcpu_load->vcpu_has_ptrauth
// subgraph node: vcpu_has_ptrauth
// subgraph edge: kvm_arch_vcpu_load->vcpu_ptrauth_disable
// subgraph node: vcpu_ptrauth_disable
// subgraph edge: kvm_arch_vcpu_load->kvm_arch_vcpu_load_debug_state_flags
// subgraph node: kvm_arch_vcpu_load_debug_state_flags
// subgraph edge: kvm_arch_vcpu_load_debug_state_flags->has_vhe
// subgraph edge: kvm_arch_vcpu_load_debug_state_flags->read_sysreg
// subgraph edge: kvm_arch_vcpu_load_debug_state_flags->BIT
// subgraph node: BIT
// subgraph edge: kvm_arch_vcpu_load_debug_state_flags->vcpu_set_flag
// subgraph edge: kvm_arch_vcpu_load_debug_state_flags->read_sysreg_s
// subgraph edge: kvm_arch_vcpu_load_debug_state_flags->cpuid_feature_extract_unsigned_field
// subgraph node: cpuid_feature_extract_unsigned_field
// subgraph edge: kvm_arch_vcpu_load->cpumask_test_cpu
// subgraph node: cpumask_test_cpu
// subgraph edge: kvm_arch_vcpu_load->vcpu_set_on_unsupported_cpu
// subgraph node: vcpu_set_on_unsupported_cpu
// subgraph edge: vcpu_load->preempt_notifier_register
// subgraph node: preempt_notifier_register
// subgraph edge: kvm_arch_vcpu_ioctl_run->kvm_sigset_activate
// subgraph node: kvm_sigset_activate
// subgraph edge: kvm_sigset_activate->sigprocmask
// subgraph node: sigprocmask
// subgraph edge: kvm_arch_vcpu_ioctl_run->xfer_to_guest_mode_handle_work
// subgraph node: xfer_to_guest_mode_handle_work
// subgraph edge: kvm_arch_vcpu_ioctl_run->check_vcpu_requests
// subgraph node: check_vcpu_requests
// subgraph edge: check_vcpu_requests->preempt_disable
// subgraph edge: check_vcpu_requests->preempt_enable
// subgraph edge: check_vcpu_requests->kvm_vcpu_pmu_restore_guest
// subgraph edge: check_vcpu_requests->vgic_v4_put
// subgraph node: vgic_v4_put
// subgraph edge: check_vcpu_requests->vgic_v4_load
// subgraph node: vgic_v4_load
// subgraph edge: check_vcpu_requests->kvm_check_request
// subgraph node: kvm_check_request
// subgraph edge: check_vcpu_requests->kvm_request_pending
// subgraph node: kvm_request_pending
// subgraph edge: check_vcpu_requests->kvm_vcpu_sleep
// subgraph node: kvm_vcpu_sleep
// subgraph edge: kvm_vcpu_sleep->kvm_make_request
// subgraph edge: kvm_vcpu_sleep->smp_rmb
// subgraph node: smp_rmb
// subgraph edge: kvm_vcpu_sleep->kvm_arm_vcpu_stopped
// subgraph node: kvm_arm_vcpu_stopped
// subgraph edge: kvm_arm_vcpu_stopped->READ_ONCE
// subgraph node: READ_ONCE
// subgraph edge: kvm_vcpu_sleep->kvm_arch_vcpu_get_wait
// subgraph node: kvm_arch_vcpu_get_wait
// subgraph edge: kvm_vcpu_sleep->rcuwait_wait_event
// subgraph node: rcuwait_wait_event
// subgraph edge: check_vcpu_requests->kvm_reset_vcpu
// subgraph node: kvm_reset_vcpu
// subgraph edge: kvm_reset_vcpu->vcpu_el1_is_32bit
// subgraph node: vcpu_el1_is_32bit
// subgraph edge: kvm_reset_vcpu->vcpu_has_nv
// subgraph edge: kvm_reset_vcpu->preempt_disable
// subgraph edge: kvm_reset_vcpu->preempt_enable
// subgraph edge: kvm_reset_vcpu->bool
// subgraph edge: kvm_reset_vcpu->vcpu_pc
// subgraph edge: kvm_reset_vcpu->memset
// subgraph node: memset
// subgraph edge: kvm_reset_vcpu->vcpu_mode_is_32bit
// subgraph node: vcpu_mode_is_32bit
// subgraph edge: kvm_reset_vcpu->spin_lock
// subgraph node: spin_lock
// subgraph edge: kvm_reset_vcpu->spin_unlock
// subgraph node: spin_unlock
// subgraph edge: kvm_reset_vcpu->kvm_arch_vcpu_put
// subgraph node: kvm_arch_vcpu_put
// subgraph edge: kvm_arch_vcpu_put->has_vhe
// subgraph edge: kvm_arch_vcpu_put->kvm_arch_vcpu_put_debug_state_flags
// subgraph node: kvm_arch_vcpu_put_debug_state_flags
// subgraph edge: kvm_arch_vcpu_put_debug_state_flags->vcpu_clear_flag
// subgraph edge: kvm_arch_vcpu_put->kvm_arch_vcpu_put_fp
// subgraph node: kvm_arch_vcpu_put_fp
// subgraph edge: kvm_arch_vcpu_put_fp->vcpu_has_sve
// subgraph edge: kvm_arch_vcpu_put_fp->vcpu_get_flag
// subgraph edge: kvm_arch_vcpu_put_fp->has_vhe
// subgraph edge: kvm_arch_vcpu_put_fp->local_irq_save
// subgraph edge: kvm_arch_vcpu_put_fp->isb
// subgraph edge: kvm_arch_vcpu_put_fp->local_irq_restore
// subgraph edge: kvm_arch_vcpu_put_fp->system_supports_sme
// subgraph edge: kvm_arch_vcpu_put_fp->sysreg_clear_set
// subgraph edge: kvm_arch_vcpu_put_fp->read_sysreg_el1
// subgraph node: read_sysreg_el1
// subgraph edge: kvm_arch_vcpu_put_fp->sve_cond_update_zcr_vq
// subgraph node: sve_cond_update_zcr_vq
// subgraph edge: kvm_arch_vcpu_put_fp->vcpu_sve_max_vq
// subgraph node: vcpu_sve_max_vq
// subgraph edge: kvm_arch_vcpu_put_fp->fpsimd_save_and_flush_cpu_state
// subgraph edge: kvm_arch_vcpu_put_fp->system_supports_sve
// subgraph node: system_supports_sve
// subgraph edge: kvm_arch_vcpu_put->kvm_vcpu_put_vhe
// subgraph node: kvm_vcpu_put_vhe
// subgraph edge: kvm_arch_vcpu_put->kvm_timer_vcpu_put
// subgraph node: kvm_timer_vcpu_put
// subgraph edge: kvm_timer_vcpu_put->get_timer_map
// subgraph edge: kvm_timer_vcpu_put->soft_timer_cancel
// subgraph edge: kvm_timer_vcpu_put->timer_save_state
// subgraph node: timer_save_state
// subgraph edge: timer_save_state->BUG
// subgraph edge: timer_save_state->timer_set_cval
// subgraph node: timer_set_cval
// subgraph edge: timer_set_cval->arch_timer_ctx_index
// subgraph edge: timer_set_cval->WARN_ON
// subgraph edge: timer_save_state->timer_get_offset
// subgraph edge: timer_save_state->timer_set_ctl
// subgraph node: timer_set_ctl
// subgraph edge: timer_set_ctl->arch_timer_ctx_index
// subgraph edge: timer_set_ctl->WARN_ON
// subgraph edge: timer_save_state->arch_timer_ctx_index
// subgraph edge: timer_save_state->read_sysreg_el0
// subgraph edge: timer_save_state->vcpu_timer
// subgraph edge: timer_save_state->local_irq_save
// subgraph edge: timer_save_state->write_sysreg_el0
// subgraph edge: timer_save_state->isb
// subgraph edge: timer_save_state->set_cntvoff
// subgraph edge: timer_save_state->set_cntpoff
// subgraph edge: timer_save_state->trace_kvm_timer_save_state
// subgraph node: trace_kvm_timer_save_state
// subgraph edge: timer_save_state->local_irq_restore
// subgraph edge: kvm_timer_vcpu_put->unlikely
// subgraph edge: kvm_timer_vcpu_put->vcpu_timer
// subgraph edge: kvm_timer_vcpu_put->kvm_vcpu_is_blocking
// subgraph node: kvm_vcpu_is_blocking
// subgraph edge: kvm_timer_vcpu_put->kvm_timer_blocking
// subgraph node: kvm_timer_blocking
// subgraph edge: kvm_timer_blocking->get_timer_map
// subgraph edge: kvm_timer_blocking->kvm_timer_irq_can_fire
// subgraph edge: kvm_timer_blocking->soft_timer_start
// subgraph edge: kvm_timer_blocking->vcpu_timer
// subgraph edge: kvm_timer_blocking->vcpu_has_wfit_active
// subgraph node: vcpu_has_wfit_active
// subgraph edge: vcpu_has_wfit_active->vcpu_get_flag
// subgraph edge: vcpu_has_wfit_active->cpus_have_final_cap
// subgraph node: cpus_have_final_cap
// subgraph edge: kvm_timer_blocking->kvm_timer_earliest_exp
// subgraph node: kvm_timer_earliest_exp
// subgraph edge: kvm_timer_earliest_exp->kvm_timer_irq_can_fire
// subgraph edge: kvm_timer_earliest_exp->kvm_timer_compute_delta
// subgraph edge: kvm_timer_earliest_exp->min
// subgraph node: min
// subgraph edge: kvm_timer_earliest_exp->vcpu_has_wfit_active
// subgraph edge: kvm_timer_earliest_exp->nr_timers
// subgraph edge: kvm_timer_earliest_exp->WARN
// subgraph node: WARN
// subgraph edge: kvm_timer_earliest_exp->wfit_delay_ns
// subgraph node: wfit_delay_ns
// subgraph edge: wfit_delay_ns->vcpu_has_nv
// subgraph edge: wfit_delay_ns->is_hyp_ctxt
// subgraph edge: wfit_delay_ns->vcpu_hvtimer
// subgraph edge: wfit_delay_ns->vcpu_vtimer
// subgraph edge: wfit_delay_ns->kvm_counter_compute_delta
// subgraph edge: wfit_delay_ns->vcpu_get_reg
// subgraph node: vcpu_get_reg
// subgraph edge: wfit_delay_ns->kvm_vcpu_sys_get_rt
// subgraph node: kvm_vcpu_sys_get_rt
// subgraph edge: kvm_arch_vcpu_put->kvm_vgic_put
// subgraph node: kvm_vgic_put
// subgraph edge: kvm_arch_vcpu_put->kvm_vcpu_pmu_restore_host
// subgraph node: kvm_vcpu_pmu_restore_host
// subgraph edge: kvm_vcpu_pmu_restore_host->has_vhe
// subgraph edge: kvm_vcpu_pmu_restore_host->kvm_arm_support_pmu_v3
// subgraph edge: kvm_vcpu_pmu_restore_host->kvm_get_pmu_events
// subgraph edge: kvm_vcpu_pmu_restore_host->kvm_vcpu_pmu_enable_el0
// subgraph edge: kvm_vcpu_pmu_restore_host->kvm_vcpu_pmu_disable_el0
// subgraph edge: kvm_arch_vcpu_put->kvm_arm_vmid_clear_active
// subgraph node: kvm_arm_vmid_clear_active
// subgraph edge: kvm_arm_vmid_clear_active->this_cpu_ptr
// subgraph edge: kvm_arm_vmid_clear_active->atomic64_set
// subgraph node: atomic64_set
// subgraph edge: kvm_arch_vcpu_put->vcpu_clear_on_unsupported_cpu
// subgraph node: vcpu_clear_on_unsupported_cpu
// subgraph edge: kvm_reset_vcpu->kvm_arch_vcpu_load
// subgraph edge: kvm_reset_vcpu->smp_processor_id
// subgraph node: smp_processor_id
// subgraph edge: kvm_reset_vcpu->vcpu_set_reg
// subgraph edge: kvm_reset_vcpu->kvm_arm_vcpu_sve_finalized
// subgraph edge: kvm_reset_vcpu->kvm_pmu_vcpu_reset
// subgraph node: kvm_pmu_vcpu_reset
// subgraph edge: kvm_pmu_vcpu_reset->kvm_pmu_valid_counter_mask
// subgraph node: kvm_pmu_valid_counter_mask
// subgraph edge: kvm_pmu_valid_counter_mask->BIT
// subgraph edge: kvm_pmu_valid_counter_mask->kvm_vcpu_read_pmcr
// subgraph node: kvm_vcpu_read_pmcr
// subgraph edge: kvm_pmu_valid_counter_mask->GENMASK
// subgraph node: GENMASK
// subgraph edge: kvm_pmu_vcpu_reset->kvm_vcpu_idx_to_pmc
// subgraph node: kvm_vcpu_idx_to_pmc
// subgraph edge: kvm_pmu_vcpu_reset->kvm_pmu_stop_counter
// subgraph node: kvm_pmu_stop_counter
// subgraph edge: kvm_pmu_stop_counter->kvm_pmc_to_vcpu
// subgraph node: kvm_pmc_to_vcpu
// subgraph edge: kvm_pmc_to_vcpu->container_of
// subgraph edge: kvm_pmu_stop_counter->kvm_pmu_get_pmc_value
// subgraph node: kvm_pmu_get_pmc_value
// subgraph edge: kvm_pmu_get_pmc_value->lower_32_bits
// subgraph node: lower_32_bits
// subgraph edge: kvm_pmu_get_pmc_value->kvm_pmc_to_vcpu
// subgraph edge: kvm_pmu_get_pmc_value->kvm_pmc_is_64bit
// subgraph node: kvm_pmc_is_64bit
// subgraph edge: kvm_pmc_is_64bit->kvm_pmc_to_vcpu
// subgraph edge: kvm_pmc_is_64bit->kvm_pmu_is_3p5
// subgraph node: kvm_pmu_is_3p5
// subgraph edge: kvm_pmu_get_pmc_value->counter_index_to_reg
// subgraph node: counter_index_to_reg
// subgraph edge: kvm_pmu_get_pmc_value->perf_event_read_value
// subgraph node: perf_event_read_value
// subgraph edge: kvm_pmu_stop_counter->counter_index_to_reg
// subgraph edge: kvm_pmu_stop_counter->kvm_pmu_release_perf_event
// subgraph node: kvm_pmu_release_perf_event
// subgraph edge: kvm_pmu_release_perf_event->perf_event_disable
// subgraph node: perf_event_disable
// subgraph edge: kvm_pmu_release_perf_event->perf_event_release_kernel
// subgraph node: perf_event_release_kernel
// subgraph edge: kvm_pmu_vcpu_reset->for_each_set_bit
// subgraph edge: kvm_reset_vcpu->vcpu_has_feature
// subgraph node: vcpu_has_feature
// subgraph edge: kvm_reset_vcpu->kvm_vcpu_enable_sve
// subgraph node: kvm_vcpu_enable_sve
// subgraph edge: kvm_vcpu_enable_sve->vcpu_set_flag
// subgraph edge: kvm_reset_vcpu->kvm_vcpu_reset_sve
// subgraph node: kvm_vcpu_reset_sve
// subgraph edge: kvm_vcpu_reset_sve->vcpu_has_sve
// subgraph edge: kvm_vcpu_reset_sve->memset
// subgraph edge: kvm_vcpu_reset_sve->vcpu_sve_state_size
// subgraph node: vcpu_sve_state_size
// subgraph edge: kvm_reset_vcpu->kvm_vcpu_enable_ptrauth
// subgraph node: kvm_vcpu_enable_ptrauth
// subgraph edge: kvm_vcpu_enable_ptrauth->vcpu_set_flag
// subgraph edge: kvm_reset_vcpu->vcpu_gp_regs
// subgraph node: vcpu_gp_regs
// subgraph edge: kvm_reset_vcpu->kvm_reset_sys_regs
// subgraph node: kvm_reset_sys_regs
// subgraph edge: kvm_reset_sys_regs->reg_to_encoding
// subgraph node: reg_to_encoding
// subgraph edge: kvm_reset_sys_regs->ARRAY_SIZE
// subgraph node: ARRAY_SIZE
// subgraph edge: kvm_reset_sys_regs->kvm_reset_id_regs
// subgraph node: kvm_reset_id_regs
// subgraph edge: kvm_reset_id_regs->reg_to_encoding
// subgraph edge: kvm_reset_id_regs->IDREG
// subgraph node: IDREG
// subgraph edge: kvm_reset_id_regs->test_bit
// subgraph node: test_bit
// subgraph edge: kvm_reset_id_regs->lockdep_assert_held
// subgraph node: lockdep_assert_held
// subgraph edge: kvm_reset_id_regs->set_bit
// subgraph edge: kvm_reset_id_regs->is_id_reg
// subgraph node: is_id_reg
// subgraph edge: is_id_reg->sys_reg_Op0
// subgraph node: sys_reg_Op0
// subgraph edge: is_id_reg->sys_reg_Op1
// subgraph node: sys_reg_Op1
// subgraph edge: is_id_reg->sys_reg_CRn
// subgraph node: sys_reg_CRn
// subgraph edge: is_id_reg->sys_reg_CRm
// subgraph node: sys_reg_CRm
// subgraph edge: kvm_reset_sys_regs->is_id_reg
// subgraph edge: kvm_reset_vcpu->vcpu_set_thumb
// subgraph node: vcpu_set_thumb
// subgraph edge: kvm_reset_vcpu->kvm_vcpu_set_be
// subgraph node: kvm_vcpu_set_be
// subgraph edge: kvm_reset_vcpu->kvm_timer_vcpu_reset
// subgraph node: kvm_timer_vcpu_reset
// subgraph edge: kvm_timer_vcpu_reset->vcpu_has_nv
// subgraph edge: kvm_timer_vcpu_reset->get_timer_map
// subgraph edge: kvm_timer_vcpu_reset->vcpu_get_timer
// subgraph node: vcpu_get_timer
// subgraph edge: kvm_timer_vcpu_reset->soft_timer_cancel
// subgraph edge: kvm_timer_vcpu_reset->vcpu_vtimer
// subgraph edge: kvm_timer_vcpu_reset->timer_set_ctl
// subgraph edge: kvm_timer_vcpu_reset->kvm_timer_update_irq
// subgraph edge: kvm_timer_vcpu_reset->timer_irq
// subgraph edge: kvm_timer_vcpu_reset->irqchip_in_kernel
// subgraph edge: kvm_timer_vcpu_reset->vcpu_timer
// subgraph edge: kvm_timer_vcpu_reset->kvm_vgic_reset_mapped_irq
// subgraph node: kvm_vgic_reset_mapped_irq
// subgraph edge: check_vcpu_requests->kvm_update_stolen_time
// subgraph node: kvm_update_stolen_time
// subgraph edge: kvm_update_stolen_time->srcu_read_lock
// subgraph node: srcu_read_lock
// subgraph edge: kvm_update_stolen_time->srcu_read_unlock
// subgraph node: srcu_read_unlock
// subgraph edge: kvm_update_stolen_time->READ_ONCE
// subgraph edge: kvm_update_stolen_time->offsetof
// subgraph node: offsetof
// subgraph edge: kvm_update_stolen_time->kvm_get_guest
// subgraph node: kvm_get_guest
// subgraph edge: kvm_update_stolen_time->le64_to_cpu
// subgraph node: le64_to_cpu
// subgraph edge: kvm_update_stolen_time->kvm_put_guest
// subgraph node: kvm_put_guest
// subgraph edge: kvm_update_stolen_time->cpu_to_le64
// subgraph node: cpu_to_le64
// subgraph edge: check_vcpu_requests->kvm_vcpu_reload_pmu
// subgraph node: kvm_vcpu_reload_pmu
// subgraph edge: kvm_vcpu_reload_pmu->kvm_pmu_valid_counter_mask
// subgraph edge: kvm_vcpu_reload_pmu->kvm_vcpu_read_pmcr
// subgraph edge: kvm_vcpu_reload_pmu->kvm_pmu_handle_pmcr
// subgraph node: kvm_pmu_handle_pmcr
// subgraph edge: kvm_pmu_handle_pmcr->kvm_vcpu_has_pmu
// subgraph edge: kvm_pmu_handle_pmcr->BIT
// subgraph edge: kvm_pmu_handle_pmcr->kvm_pmu_valid_counter_mask
// subgraph edge: kvm_pmu_handle_pmcr->kvm_pmu_enable_counter_mask
// subgraph node: kvm_pmu_enable_counter_mask
// subgraph edge: kvm_pmu_enable_counter_mask->kvm_vcpu_has_pmu
// subgraph edge: kvm_pmu_enable_counter_mask->BIT
// subgraph edge: kvm_pmu_enable_counter_mask->kvm_vcpu_read_pmcr
// subgraph edge: kvm_pmu_enable_counter_mask->kvm_vcpu_idx_to_pmc
// subgraph edge: kvm_pmu_enable_counter_mask->kvm_pmu_create_perf_event
// subgraph node: kvm_pmu_create_perf_event
// subgraph edge: kvm_pmu_create_perf_event->bool
// subgraph edge: kvm_pmu_create_perf_event->kvm_pmu_event_mask
// subgraph node: kvm_pmu_event_mask
// subgraph edge: kvm_pmu_event_mask->SYS_FIELD_GET
// subgraph node: SYS_FIELD_GET
// subgraph edge: kvm_pmu_event_mask->IDREG
// subgraph edge: kvm_pmu_create_perf_event->kvm_pmc_to_vcpu
// subgraph edge: kvm_pmu_create_perf_event->counter_index_to_evtreg
// subgraph node: counter_index_to_evtreg
// subgraph edge: kvm_pmu_create_perf_event->kvm_pmu_stop_counter
// subgraph edge: kvm_pmu_create_perf_event->test_bit
// subgraph edge: kvm_pmu_create_perf_event->memset
// subgraph edge: kvm_pmu_create_perf_event->kvm_pmu_counter_is_enabled
// subgraph node: kvm_pmu_counter_is_enabled
// subgraph edge: kvm_pmu_counter_is_enabled->BIT
// subgraph edge: kvm_pmu_counter_is_enabled->kvm_vcpu_read_pmcr
// subgraph edge: kvm_pmu_counter_is_enabled->kvm_pmc_to_vcpu
// subgraph edge: kvm_pmu_create_perf_event->kvm_pmc_is_64bit
// subgraph edge: kvm_pmu_create_perf_event->compute_period
// subgraph node: compute_period
// subgraph edge: compute_period->GENMASK
// subgraph edge: compute_period->kvm_pmc_is_64bit
// subgraph edge: compute_period->kvm_pmc_has_64bit_overflow
// subgraph node: kvm_pmc_has_64bit_overflow
// subgraph edge: kvm_pmc_has_64bit_overflow->kvm_vcpu_read_pmcr
// subgraph edge: kvm_pmc_has_64bit_overflow->kvm_pmc_to_vcpu
// subgraph edge: kvm_pmu_create_perf_event->kvm_pmu_get_pmc_value
// subgraph edge: kvm_pmu_create_perf_event->perf_event_create_kernel_counter
// subgraph node: perf_event_create_kernel_counter
// subgraph edge: kvm_pmu_create_perf_event->kvm_pmu_perf_overflow
// subgraph node: kvm_pmu_perf_overflow
// subgraph edge: kvm_pmu_perf_overflow->BIT
// subgraph edge: kvm_pmu_perf_overflow->kvm_pmc_to_vcpu
// subgraph edge: kvm_pmu_perf_overflow->compute_period
// subgraph edge: kvm_pmu_perf_overflow->to_arm_pmu
// subgraph node: to_arm_pmu
// subgraph edge: kvm_pmu_perf_overflow->local64_read
// subgraph node: local64_read
// subgraph edge: kvm_pmu_perf_overflow->local64_set
// subgraph node: local64_set
// subgraph edge: kvm_pmu_perf_overflow->kvm_pmu_counter_can_chain
// subgraph node: kvm_pmu_counter_can_chain
// subgraph edge: kvm_pmu_counter_can_chain->kvm_pmc_has_64bit_overflow
// subgraph edge: kvm_pmu_perf_overflow->kvm_pmu_counter_increment
// subgraph node: kvm_pmu_counter_increment
// subgraph edge: kvm_pmu_counter_increment->lower_32_bits
// subgraph edge: kvm_pmu_counter_increment->BIT
// subgraph edge: kvm_pmu_counter_increment->kvm_pmu_event_mask
// subgraph edge: kvm_pmu_counter_increment->kvm_vcpu_read_pmcr
// subgraph edge: kvm_pmu_counter_increment->kvm_vcpu_idx_to_pmc
// subgraph edge: kvm_pmu_counter_increment->counter_index_to_evtreg
// subgraph edge: kvm_pmu_counter_increment->kvm_pmc_is_64bit
// subgraph edge: kvm_pmu_counter_increment->counter_index_to_reg
// subgraph edge: kvm_pmu_counter_increment->kvm_pmc_has_64bit_overflow
// subgraph edge: kvm_pmu_counter_increment->kvm_pmu_counter_can_chain
// subgraph edge: kvm_pmu_counter_increment->kvm_pmu_counter_increment
// subgraph edge: kvm_pmu_counter_increment->for_each_set_bit
// subgraph edge: kvm_pmu_perf_overflow->kvm_pmu_overflow_status
// subgraph node: kvm_pmu_overflow_status
// subgraph edge: kvm_pmu_overflow_status->kvm_vcpu_read_pmcr
// subgraph edge: kvm_pmu_perf_overflow->kvm_make_request
// subgraph edge: kvm_pmu_perf_overflow->in_nmi
// subgraph node: in_nmi
// subgraph edge: kvm_pmu_perf_overflow->kvm_vcpu_kick
// subgraph node: kvm_vcpu_kick
// subgraph edge: kvm_vcpu_kick->kvm_vcpu_wake_up
// subgraph node: kvm_vcpu_wake_up
// subgraph edge: kvm_vcpu_wake_up->WRITE_ONCE
// subgraph node: WRITE_ONCE
// subgraph edge: kvm_vcpu_kick->get_cpu
// subgraph edge: kvm_vcpu_kick->WRITE_ONCE
// subgraph edge: kvm_vcpu_kick->kvm_arch_vcpu_should_kick
// subgraph node: kvm_arch_vcpu_should_kick
// subgraph edge: kvm_arch_vcpu_should_kick->kvm_vcpu_exiting_guest_mode
// subgraph node: kvm_vcpu_exiting_guest_mode
// subgraph edge: kvm_vcpu_kick->READ_ONCE
// subgraph edge: kvm_vcpu_kick->cpu_online
// subgraph node: cpu_online
// subgraph edge: kvm_vcpu_kick->smp_send_reschedule
// subgraph node: smp_send_reschedule
// subgraph edge: kvm_vcpu_kick->put_cpu
// subgraph edge: kvm_pmu_perf_overflow->irq_work_queue
// subgraph node: irq_work_queue
// subgraph edge: kvm_pmu_create_perf_event->IS_ERR
// subgraph edge: kvm_pmu_create_perf_event->pr_err_once
// subgraph node: pr_err_once
// subgraph edge: kvm_pmu_create_perf_event->PTR_ERR
// subgraph edge: kvm_pmu_enable_counter_mask->perf_event_enable
// subgraph node: perf_event_enable
// subgraph edge: kvm_pmu_enable_counter_mask->kvm_debug
// subgraph edge: kvm_pmu_handle_pmcr->kvm_vcpu_pmu_restore_guest
// subgraph edge: kvm_pmu_handle_pmcr->kvm_pmu_disable_counter_mask
// subgraph node: kvm_pmu_disable_counter_mask
// subgraph edge: kvm_pmu_disable_counter_mask->kvm_vcpu_has_pmu
// subgraph edge: kvm_pmu_disable_counter_mask->BIT
// subgraph edge: kvm_pmu_disable_counter_mask->kvm_vcpu_idx_to_pmc
// subgraph edge: kvm_pmu_disable_counter_mask->perf_event_disable
// subgraph edge: kvm_pmu_handle_pmcr->kvm_vcpu_idx_to_pmc
// subgraph edge: kvm_pmu_handle_pmcr->kvm_pmu_is_3p5
// subgraph edge: kvm_pmu_handle_pmcr->for_each_set_bit
// subgraph edge: kvm_pmu_handle_pmcr->kvm_pmu_set_counter_value
// subgraph node: kvm_pmu_set_counter_value
// subgraph edge: kvm_pmu_set_counter_value->kvm_vcpu_has_pmu
// subgraph edge: kvm_pmu_set_counter_value->kvm_vcpu_idx_to_pmc
// subgraph edge: kvm_pmu_set_counter_value->kvm_pmu_set_pmc_value
// subgraph node: kvm_pmu_set_pmc_value
// subgraph edge: kvm_pmu_set_pmc_value->lower_32_bits
// subgraph edge: kvm_pmu_set_pmc_value->GENMASK
// subgraph edge: kvm_pmu_set_pmc_value->kvm_pmu_create_perf_event
// subgraph edge: kvm_pmu_set_pmc_value->kvm_pmc_to_vcpu
// subgraph edge: kvm_pmu_set_pmc_value->counter_index_to_reg
// subgraph edge: kvm_pmu_set_pmc_value->kvm_pmu_release_perf_event
// subgraph edge: kvm_pmu_set_pmc_value->vcpu_mode_is_32bit
// subgraph edge: kvm_pmu_handle_pmcr->kvm_pmu_set_pmc_value
// subgraph edge: check_vcpu_requests->kvm_vcpu_suspend
// subgraph node: kvm_vcpu_suspend
// subgraph edge: kvm_vcpu_suspend->memset
// subgraph edge: kvm_vcpu_suspend->kvm_make_request
// subgraph edge: kvm_vcpu_suspend->kvm_vcpu_wfi
// subgraph node: kvm_vcpu_wfi
// subgraph edge: kvm_vcpu_wfi->preempt_disable
// subgraph edge: kvm_vcpu_wfi->preempt_enable
// subgraph edge: kvm_vcpu_wfi->vcpu_clear_flag
// subgraph edge: kvm_vcpu_wfi->vcpu_set_flag
// subgraph edge: kvm_vcpu_wfi->kvm_vgic_vmcr_sync
// subgraph node: kvm_vgic_vmcr_sync
// subgraph edge: kvm_vcpu_wfi->vgic_v4_put
// subgraph edge: kvm_vcpu_wfi->kvm_vcpu_halt
// subgraph node: kvm_vcpu_halt
// subgraph edge: kvm_vcpu_halt->ktime_add_ns
// subgraph edge: kvm_vcpu_halt->ktime_get
// subgraph edge: kvm_vcpu_halt->kvm_vcpu_max_halt_poll_ns
// subgraph node: kvm_vcpu_max_halt_poll_ns
// subgraph edge: kvm_vcpu_max_halt_poll_ns->READ_ONCE
// subgraph edge: kvm_vcpu_max_halt_poll_ns->smp_rmb
// subgraph edge: kvm_vcpu_halt->kvm_arch_no_poll
// subgraph node: kvm_arch_no_poll
// subgraph edge: kvm_vcpu_halt->kvm_vcpu_check_block
// subgraph node: kvm_vcpu_check_block
// subgraph edge: kvm_vcpu_check_block->srcu_read_lock
// subgraph edge: kvm_vcpu_check_block->srcu_read_unlock
// subgraph edge: kvm_vcpu_check_block->kvm_arch_vcpu_runnable
// subgraph node: kvm_arch_vcpu_runnable
// subgraph edge: kvm_arch_vcpu_runnable->bool
// subgraph edge: kvm_arch_vcpu_runnable->vcpu_hcr
// subgraph node: vcpu_hcr
// subgraph edge: kvm_arch_vcpu_runnable->kvm_vgic_vcpu_pending_irq
// subgraph node: kvm_vgic_vcpu_pending_irq
// subgraph edge: kvm_arch_vcpu_runnable->kvm_arm_vcpu_stopped
// subgraph edge: kvm_vcpu_check_block->kvm_cpu_has_pending_timer
// subgraph node: kvm_cpu_has_pending_timer
// subgraph edge: kvm_cpu_has_pending_timer->vcpu_has_wfit_active
// subgraph edge: kvm_cpu_has_pending_timer->wfit_delay_ns
// subgraph edge: kvm_vcpu_check_block->signal_pending
// subgraph node: signal_pending
// subgraph edge: kvm_vcpu_check_block->kvm_check_request
// subgraph edge: kvm_vcpu_halt->cpu_relax
// subgraph node: cpu_relax
// subgraph edge: kvm_vcpu_halt->kvm_vcpu_can_poll
// subgraph node: kvm_vcpu_can_poll
// subgraph edge: kvm_vcpu_halt->kvm_vcpu_block
// subgraph node: kvm_vcpu_block
// subgraph edge: kvm_vcpu_block->preempt_disable
// subgraph edge: kvm_vcpu_block->preempt_enable
// subgraph edge: kvm_vcpu_block->kvm_vcpu_check_block
// subgraph edge: kvm_vcpu_block->kvm_arch_vcpu_get_wait
// subgraph edge: kvm_vcpu_block->kvm_arch_vcpu_blocking
// subgraph node: kvm_arch_vcpu_blocking
// subgraph edge: kvm_vcpu_block->prepare_to_rcuwait
// subgraph node: prepare_to_rcuwait
// subgraph edge: kvm_vcpu_block->set_current_state
// subgraph node: set_current_state
// subgraph edge: kvm_vcpu_block->schedule
// subgraph node: schedule
// subgraph edge: kvm_vcpu_block->finish_rcuwait
// subgraph node: finish_rcuwait
// subgraph edge: kvm_vcpu_block->kvm_arch_vcpu_unblocking
// subgraph node: kvm_arch_vcpu_unblocking
// subgraph edge: kvm_vcpu_halt->ktime_to_ns
// subgraph node: ktime_to_ns
// subgraph edge: kvm_vcpu_halt->KVM_STATS_LOG_HIST_UPDATE
// subgraph node: KVM_STATS_LOG_HIST_UPDATE
// subgraph edge: kvm_vcpu_halt->update_halt_poll_stats
// subgraph node: update_halt_poll_stats
// subgraph edge: update_halt_poll_stats->ktime_to_ns
// subgraph edge: update_halt_poll_stats->KVM_STATS_LOG_HIST_UPDATE
// subgraph edge: update_halt_poll_stats->vcpu_valid_wakeup
// subgraph node: vcpu_valid_wakeup
// subgraph edge: update_halt_poll_stats->ktime_sub
// subgraph node: ktime_sub
// subgraph edge: kvm_vcpu_halt->vcpu_valid_wakeup
// subgraph edge: kvm_vcpu_halt->shrink_halt_poll_ns
// subgraph node: shrink_halt_poll_ns
// subgraph edge: shrink_halt_poll_ns->READ_ONCE
// subgraph edge: shrink_halt_poll_ns->trace_kvm_halt_poll_ns_shrink
// subgraph node: trace_kvm_halt_poll_ns_shrink
// subgraph edge: kvm_vcpu_halt->grow_halt_poll_ns
// subgraph node: grow_halt_poll_ns
// subgraph edge: grow_halt_poll_ns->READ_ONCE
// subgraph edge: grow_halt_poll_ns->trace_kvm_halt_poll_ns_grow
// subgraph node: trace_kvm_halt_poll_ns_grow
// subgraph edge: kvm_vcpu_halt->trace_kvm_vcpu_wakeup
// subgraph node: trace_kvm_vcpu_wakeup
// subgraph edge: kvm_vcpu_wfi->vgic_v4_load
// subgraph edge: kvm_vcpu_suspend->kvm_arch_vcpu_runnable
// subgraph edge: kvm_vcpu_suspend->kvm_arm_vcpu_suspended
// subgraph node: kvm_arm_vcpu_suspended
// subgraph edge: kvm_arm_vcpu_suspended->READ_ONCE
// subgraph edge: check_vcpu_requests->kvm_dirty_ring_check_request
// subgraph node: kvm_dirty_ring_check_request
// subgraph edge: kvm_dirty_ring_check_request->kvm_make_request
// subgraph edge: kvm_dirty_ring_check_request->kvm_check_request
// subgraph edge: kvm_dirty_ring_check_request->kvm_dirty_ring_soft_full
// subgraph node: kvm_dirty_ring_soft_full
// subgraph edge: kvm_dirty_ring_soft_full->kvm_dirty_ring_used
// subgraph node: kvm_dirty_ring_used
// subgraph edge: kvm_dirty_ring_used->READ_ONCE
// subgraph edge: kvm_dirty_ring_check_request->trace_kvm_dirty_ring_exit
// subgraph node: trace_kvm_dirty_ring_exit
// subgraph edge: kvm_arch_vcpu_ioctl_run->kvm_arm_vmid_update
// subgraph node: kvm_arm_vmid_update
// subgraph edge: kvm_arm_vmid_update->bool
// subgraph edge: kvm_arm_vmid_update->this_cpu_ptr
// subgraph edge: kvm_arm_vmid_update->atomic64_set
// subgraph edge: kvm_arm_vmid_update->atomic64_read
// subgraph node: atomic64_read
// subgraph edge: kvm_arm_vmid_update->vmid_gen_match
// subgraph node: vmid_gen_match
// subgraph edge: kvm_arm_vmid_update->atomic64_cmpxchg_relaxed
// subgraph node: atomic64_cmpxchg_relaxed
// subgraph edge: kvm_arm_vmid_update->raw_spin_lock_irqsave
// subgraph node: raw_spin_lock_irqsave
// subgraph edge: kvm_arm_vmid_update->new_vmid
// subgraph node: new_vmid
// subgraph edge: new_vmid->atomic64_set
// subgraph edge: new_vmid->atomic64_read
// subgraph edge: new_vmid->check_update_reserved_vmid
// subgraph node: check_update_reserved_vmid
// subgraph edge: check_update_reserved_vmid->bool
// subgraph edge: check_update_reserved_vmid->for_each_possible_cpu
// subgraph node: for_each_possible_cpu
// subgraph edge: check_update_reserved_vmid->per_cpu
// subgraph node: per_cpu
// subgraph edge: new_vmid->vmid2idx
// subgraph node: vmid2idx
// subgraph edge: new_vmid->find_next_zero_bit
// subgraph node: find_next_zero_bit
// subgraph edge: new_vmid->atomic64_add_return_relaxed
// subgraph node: atomic64_add_return_relaxed
// subgraph edge: new_vmid->flush_context
// subgraph node: flush_context
// subgraph edge: flush_context->kvm_call_hyp
// subgraph edge: flush_context->for_each_possible_cpu
// subgraph edge: flush_context->per_cpu
// subgraph edge: flush_context->bitmap_zero
// subgraph node: bitmap_zero
// subgraph edge: flush_context->vmid2idx
// subgraph edge: flush_context->atomic64_xchg_relaxed
// subgraph node: atomic64_xchg_relaxed
// subgraph edge: new_vmid->idx2vmid
// subgraph node: idx2vmid
// subgraph edge: kvm_arm_vmid_update->raw_spin_unlock_irqrestore
// subgraph node: raw_spin_unlock_irqrestore
// subgraph edge: kvm_arch_vcpu_ioctl_run->kvm_pmu_flush_hwstate
// subgraph node: kvm_pmu_flush_hwstate
// subgraph edge: kvm_pmu_flush_hwstate->kvm_pmu_update_state
// subgraph node: kvm_pmu_update_state
// subgraph edge: kvm_pmu_update_state->likely
// subgraph edge: kvm_pmu_update_state->WARN_ON
// subgraph edge: kvm_pmu_update_state->bool
// subgraph edge: kvm_pmu_update_state->kvm_vgic_inject_irq
// subgraph edge: kvm_pmu_update_state->irqchip_in_kernel
// subgraph edge: kvm_pmu_update_state->kvm_vcpu_has_pmu
// subgraph edge: kvm_pmu_update_state->kvm_pmu_overflow_status
// subgraph edge: kvm_arch_vcpu_ioctl_run->local_irq_disable
// subgraph node: local_irq_disable
// subgraph edge: kvm_arch_vcpu_ioctl_run->kvm_vgic_flush_hwstate
// subgraph node: kvm_vgic_flush_hwstate
// subgraph edge: kvm_arch_vcpu_ioctl_run->kvm_pmu_update_vcpu_events
// subgraph node: kvm_pmu_update_vcpu_events
// subgraph edge: kvm_arch_vcpu_ioctl_run->smp_store_mb
// subgraph node: smp_store_mb
// subgraph edge: kvm_arch_vcpu_ioctl_run->kvm_vcpu_exit_request
// subgraph node: kvm_vcpu_exit_request
// subgraph edge: kvm_vcpu_exit_request->static_branch_unlikely
// subgraph edge: kvm_vcpu_exit_request->unlikely
// subgraph edge: kvm_vcpu_exit_request->smp_processor_id
// subgraph edge: kvm_vcpu_exit_request->kvm_request_pending
// subgraph edge: kvm_vcpu_exit_request->kvm_timer_should_notify_user
// subgraph node: kvm_timer_should_notify_user
// subgraph edge: kvm_timer_should_notify_user->likely
// subgraph edge: kvm_timer_should_notify_user->vcpu_vtimer
// subgraph edge: kvm_timer_should_notify_user->vcpu_ptimer
// subgraph edge: kvm_timer_should_notify_user->bool
// subgraph edge: kvm_timer_should_notify_user->kvm_timer_should_fire
// subgraph edge: kvm_timer_should_notify_user->irqchip_in_kernel
// subgraph edge: kvm_vcpu_exit_request->kvm_pmu_should_notify_user
// subgraph node: kvm_pmu_should_notify_user
// subgraph edge: kvm_pmu_should_notify_user->likely
// subgraph edge: kvm_pmu_should_notify_user->bool
// subgraph edge: kvm_pmu_should_notify_user->irqchip_in_kernel
// subgraph edge: kvm_vcpu_exit_request->vcpu_on_unsupported_cpu
// subgraph node: vcpu_on_unsupported_cpu
// subgraph edge: kvm_vcpu_exit_request->xfer_to_guest_mode_work_pending
// subgraph node: xfer_to_guest_mode_work_pending
// subgraph edge: kvm_arch_vcpu_ioctl_run->kvm_pmu_sync_hwstate
// subgraph node: kvm_pmu_sync_hwstate
// subgraph edge: kvm_pmu_sync_hwstate->kvm_pmu_update_state
// subgraph edge: kvm_arch_vcpu_ioctl_run->kvm_timer_sync_user
// subgraph node: kvm_timer_sync_user
// subgraph edge: kvm_timer_sync_user->unlikely
// subgraph edge: kvm_timer_sync_user->irqchip_in_kernel
// subgraph edge: kvm_timer_sync_user->vcpu_timer
// subgraph edge: kvm_timer_sync_user->unmask_vtimer_irq_user
// subgraph node: unmask_vtimer_irq_user
// subgraph edge: unmask_vtimer_irq_user->vcpu_vtimer
// subgraph edge: unmask_vtimer_irq_user->kvm_timer_should_fire
// subgraph edge: unmask_vtimer_irq_user->kvm_timer_update_irq
// subgraph edge: unmask_vtimer_irq_user->static_branch_likely
// subgraph edge: unmask_vtimer_irq_user->set_timer_irq_phys_active
// subgraph edge: unmask_vtimer_irq_user->enable_percpu_irq
// subgraph edge: kvm_arch_vcpu_ioctl_run->kvm_vgic_sync_hwstate
// subgraph node: kvm_vgic_sync_hwstate
// subgraph edge: kvm_arch_vcpu_ioctl_run->local_irq_enable
// subgraph node: local_irq_enable
// subgraph edge: kvm_arch_vcpu_ioctl_run->kvm_arm_setup_debug
// subgraph node: kvm_arm_setup_debug
// subgraph edge: kvm_arm_setup_debug->vcpu_read_sys_reg
// subgraph node: vcpu_read_sys_reg
// subgraph edge: vcpu_read_sys_reg->vcpu_get_flag
// subgraph edge: kvm_arm_setup_debug->vcpu_get_flag
// subgraph edge: kvm_arm_setup_debug->vcpu_write_sys_reg
// subgraph node: vcpu_write_sys_reg
// subgraph edge: vcpu_write_sys_reg->vcpu_get_flag
// subgraph edge: kvm_arm_setup_debug->vcpu_cpsr
// subgraph node: vcpu_cpsr
// subgraph edge: kvm_arm_setup_debug->has_vhe
// subgraph edge: kvm_arm_setup_debug->BUG_ON
// subgraph edge: kvm_arm_setup_debug->write_sysreg
// subgraph edge: kvm_arm_setup_debug->vcpu_set_flag
// subgraph edge: kvm_arm_setup_debug->get_num_brps
// subgraph node: get_num_brps
// subgraph edge: kvm_arm_setup_debug->get_num_wrps
// subgraph node: get_num_wrps
// subgraph edge: kvm_arm_setup_debug->kvm_arm_setup_mdcr_el2
// subgraph edge: kvm_arm_setup_debug->kvm_vcpu_os_lock_enabled
// subgraph edge: kvm_arm_setup_debug->trace_kvm_arm_set_dreg32
// subgraph edge: kvm_arm_setup_debug->trace_kvm_arm_setup_debug
// subgraph node: trace_kvm_arm_setup_debug
// subgraph edge: kvm_arm_setup_debug->save_guest_debug_regs
// subgraph node: save_guest_debug_regs
// subgraph edge: save_guest_debug_regs->vcpu_read_sys_reg
// subgraph edge: save_guest_debug_regs->vcpu_cpsr
// subgraph edge: save_guest_debug_regs->trace_kvm_arm_set_dreg32
// subgraph edge: kvm_arm_setup_debug->trace_kvm_arm_set_regset
// subgraph node: trace_kvm_arm_set_regset
// subgraph edge: kvm_arch_vcpu_ioctl_run->kvm_arch_vcpu_ctxflush_fp
// subgraph node: kvm_arch_vcpu_ctxflush_fp
// subgraph edge: kvm_arch_vcpu_ctxflush_fp->test_thread_flag
// subgraph node: test_thread_flag
// subgraph edge: kvm_arch_vcpu_ioctl_run->trace_kvm_entry
// subgraph node: trace_kvm_entry
// subgraph edge: kvm_arch_vcpu_ioctl_run->guest_timing_enter_irqoff
// subgraph node: guest_timing_enter_irqoff
// subgraph edge: kvm_arch_vcpu_ioctl_run->kvm_arm_vcpu_enter_exit
// subgraph node: kvm_arm_vcpu_enter_exit
// subgraph edge: kvm_arm_vcpu_enter_exit->kvm_call_hyp_ret
// subgraph node: kvm_call_hyp_ret
// subgraph edge: kvm_arm_vcpu_enter_exit->guest_state_enter_irqoff
// subgraph node: guest_state_enter_irqoff
// subgraph edge: kvm_arm_vcpu_enter_exit->guest_state_exit_irqoff
// subgraph node: guest_state_exit_irqoff
// subgraph edge: kvm_arch_vcpu_ioctl_run->kvm_arm_clear_debug
// subgraph node: kvm_arm_clear_debug
// subgraph edge: kvm_arm_clear_debug->vcpu_cpsr
// subgraph edge: kvm_arm_clear_debug->vcpu_set_flag
// subgraph edge: kvm_arm_clear_debug->get_num_brps
// subgraph edge: kvm_arm_clear_debug->get_num_wrps
// subgraph edge: kvm_arm_clear_debug->kvm_vcpu_os_lock_enabled
// subgraph edge: kvm_arm_clear_debug->trace_kvm_arm_set_regset
// subgraph edge: kvm_arm_clear_debug->trace_kvm_arm_clear_debug
// subgraph node: trace_kvm_arm_clear_debug
// subgraph edge: kvm_arm_clear_debug->restore_guest_debug_regs
// subgraph node: restore_guest_debug_regs
// subgraph edge: restore_guest_debug_regs->vcpu_read_sys_reg
// subgraph edge: restore_guest_debug_regs->vcpu_write_sys_reg
// subgraph edge: restore_guest_debug_regs->vcpu_cpsr
// subgraph edge: restore_guest_debug_regs->trace_kvm_arm_set_dreg32
// subgraph edge: kvm_arm_clear_debug->kvm_arm_reset_debug_ptr
// subgraph node: kvm_arm_reset_debug_ptr
// subgraph edge: kvm_arch_vcpu_ioctl_run->kvm_arch_vcpu_ctxsync_fp
// subgraph node: kvm_arch_vcpu_ctxsync_fp
// subgraph edge: kvm_arch_vcpu_ctxsync_fp->vcpu_has_sve
// subgraph edge: kvm_arch_vcpu_ctxsync_fp->WARN_ON_ONCE
// subgraph edge: kvm_arch_vcpu_ctxsync_fp->irqs_disabled
// subgraph node: irqs_disabled
// subgraph edge: kvm_arch_vcpu_ctxsync_fp->fpsimd_bind_state_to_cpu
// subgraph node: fpsimd_bind_state_to_cpu
// subgraph edge: kvm_arch_vcpu_ctxsync_fp->clear_thread_flag
// subgraph node: clear_thread_flag
// subgraph edge: kvm_arch_vcpu_ioctl_run->ARM_EXCEPTION_CODE
// subgraph node: ARM_EXCEPTION_CODE
// subgraph edge: kvm_arch_vcpu_ioctl_run->guest_timing_exit_irqoff
// subgraph node: guest_timing_exit_irqoff
// subgraph edge: kvm_arch_vcpu_ioctl_run->trace_kvm_exit
// subgraph node: trace_kvm_exit
// subgraph edge: kvm_arch_vcpu_ioctl_run->handle_exit_early
// subgraph node: handle_exit_early
// subgraph edge: handle_exit_early->kvm_vcpu_get_esr
// subgraph node: kvm_vcpu_get_esr
// subgraph edge: handle_exit_early->this_cpu_has_cap
// subgraph node: this_cpu_has_cap
// subgraph edge: handle_exit_early->kvm_inject_vabt
// subgraph node: kvm_inject_vabt
// subgraph edge: kvm_inject_vabt->kvm_set_sei_esr
// subgraph node: kvm_set_sei_esr
// subgraph edge: kvm_set_sei_esr->vcpu_hcr
// subgraph edge: kvm_set_sei_esr->vcpu_set_vsesr
// subgraph node: vcpu_set_vsesr
// subgraph edge: handle_exit_early->ARM_EXCEPTION_CODE
// subgraph edge: handle_exit_early->ARM_SERROR_PENDING
// subgraph node: ARM_SERROR_PENDING
// subgraph edge: handle_exit_early->kvm_vcpu_get_disr
// subgraph node: kvm_vcpu_get_disr
// subgraph edge: handle_exit_early->kvm_handle_guest_serror
// subgraph node: kvm_handle_guest_serror
// subgraph edge: kvm_handle_guest_serror->kvm_inject_vabt
// subgraph edge: kvm_handle_guest_serror->arm64_is_ras_serror
// subgraph node: arm64_is_ras_serror
// subgraph edge: kvm_handle_guest_serror->arm64_is_fatal_ras_serror
// subgraph node: arm64_is_fatal_ras_serror
// subgraph edge: handle_exit_early->disr_to_esr
// subgraph node: disr_to_esr
// subgraph edge: kvm_arch_vcpu_ioctl_run->vcpu_mode_is_bad_32bit
// subgraph node: vcpu_mode_is_bad_32bit
// subgraph edge: vcpu_mode_is_bad_32bit->kvm_supports_32bit_el0
// subgraph node: kvm_supports_32bit_el0
// subgraph edge: vcpu_mode_is_bad_32bit->likely
// subgraph edge: vcpu_mode_is_bad_32bit->vcpu_has_nv
// subgraph edge: vcpu_mode_is_bad_32bit->vcpu_mode_is_32bit
// subgraph edge: kvm_arch_vcpu_ioctl_run->handle_exit
// subgraph node: handle_exit
// subgraph edge: handle_exit->kvm_pr_unimpl
// subgraph node: kvm_pr_unimpl
// subgraph edge: handle_exit->ARM_EXCEPTION_CODE
// subgraph edge: handle_exit->ARM_SERROR_PENDING
// subgraph edge: handle_exit->handle_trap_exceptions
// subgraph node: handle_trap_exceptions
// subgraph edge: handle_trap_exceptions->kvm_incr_pc
// subgraph edge: handle_trap_exceptions->kvm_condition_valid
// subgraph node: kvm_condition_valid
// subgraph edge: handle_trap_exceptions->kvm_get_exit_handler
// subgraph node: kvm_get_exit_handler
// subgraph edge: kvm_get_exit_handler->kvm_vcpu_get_esr
// subgraph edge: kvm_get_exit_handler->ESR_ELx_EC
// subgraph node: ESR_ELx_EC
// subgraph edge: kvm_arch_vcpu_ioctl_run->kvm_timer_update_run
// subgraph node: kvm_timer_update_run
// subgraph edge: kvm_timer_update_run->vcpu_vtimer
// subgraph edge: kvm_timer_update_run->vcpu_ptimer
// subgraph edge: kvm_timer_update_run->kvm_timer_should_fire
// subgraph edge: kvm_arch_vcpu_ioctl_run->kvm_pmu_update_run
// subgraph node: kvm_pmu_update_run
// subgraph edge: kvm_arch_vcpu_ioctl_run->kvm_sigset_deactivate
// subgraph node: kvm_sigset_deactivate
// subgraph edge: kvm_sigset_deactivate->sigprocmask
// subgraph edge: kvm_sigset_deactivate->sigemptyset
// subgraph node: sigemptyset
// subgraph edge: kvm_arch_vcpu_ioctl_run->vcpu_put
// subgraph node: vcpu_put
// subgraph edge: vcpu_put->preempt_disable
// subgraph edge: vcpu_put->preempt_enable
// subgraph edge: vcpu_put->kvm_arch_vcpu_put
// subgraph edge: vcpu_put->preempt_notifier_unregister
// subgraph node: preempt_notifier_unregister
// subgraph edge: kvm_vcpu_ioctl->trace_kvm_userspace_exit
// subgraph node: trace_kvm_userspace_exit
// subgraph edge: kvm_vcpu_ioctl->kvm_arch_vcpu_ioctl_get_regs
// subgraph node: kvm_arch_vcpu_ioctl_get_regs
// subgraph edge: kvm_vcpu_ioctl->memdup_user
// subgraph node: memdup_user
// subgraph edge: kvm_vcpu_ioctl->kvm_arch_vcpu_ioctl_set_regs
// subgraph node: kvm_arch_vcpu_ioctl_set_regs
// subgraph edge: kvm_vcpu_ioctl->kvm_arch_vcpu_ioctl_get_sregs
// subgraph node: kvm_arch_vcpu_ioctl_get_sregs
// subgraph edge: kvm_vcpu_ioctl->kvm_arch_vcpu_ioctl_set_sregs
// subgraph node: kvm_arch_vcpu_ioctl_set_sregs
// subgraph edge: kvm_vcpu_ioctl->kvm_arch_vcpu_ioctl_get_mpstate
// subgraph node: kvm_arch_vcpu_ioctl_get_mpstate
// subgraph edge: kvm_arch_vcpu_ioctl_get_mpstate->READ_ONCE
// subgraph edge: kvm_vcpu_ioctl->kvm_arch_vcpu_ioctl_set_mpstate
// subgraph node: kvm_arch_vcpu_ioctl_set_mpstate
// subgraph edge: kvm_arch_vcpu_ioctl_set_mpstate->WRITE_ONCE
// subgraph edge: kvm_arch_vcpu_ioctl_set_mpstate->spin_lock
// subgraph edge: kvm_arch_vcpu_ioctl_set_mpstate->spin_unlock
// subgraph edge: kvm_arch_vcpu_ioctl_set_mpstate->kvm_arm_vcpu_suspend
// subgraph node: kvm_arm_vcpu_suspend
// subgraph edge: kvm_arm_vcpu_suspend->kvm_make_request
// subgraph edge: kvm_arm_vcpu_suspend->kvm_vcpu_kick
// subgraph edge: kvm_arm_vcpu_suspend->WRITE_ONCE
// subgraph edge: kvm_vcpu_ioctl->kvm_arch_vcpu_ioctl_translate
// subgraph node: kvm_arch_vcpu_ioctl_translate
// subgraph edge: kvm_vcpu_ioctl->kvm_arch_vcpu_ioctl_set_guest_debug
// subgraph node: kvm_arch_vcpu_ioctl_set_guest_debug
// subgraph edge: kvm_arch_vcpu_ioctl_set_guest_debug->vcpu_clear_flag
// subgraph edge: kvm_arch_vcpu_ioctl_set_guest_debug->trace_kvm_set_guest_debug
// subgraph node: trace_kvm_set_guest_debug
// subgraph edge: kvm_vcpu_ioctl->kvm_arch_vcpu_ioctl_get_fpu
// subgraph node: kvm_arch_vcpu_ioctl_get_fpu
// subgraph edge: kvm_vcpu_ioctl->kvm_arch_vcpu_ioctl_set_fpu
// subgraph node: kvm_arch_vcpu_ioctl_set_fpu
// subgraph edge: kvm_vcpu_ioctl->kvm_vcpu_ioctl_get_stats_fd
// subgraph node: kvm_vcpu_ioctl_get_stats_fd
// subgraph edge: kvm_vcpu_ioctl_get_stats_fd->IS_ERR
// subgraph edge: kvm_vcpu_ioctl_get_stats_fd->PTR_ERR
// subgraph edge: kvm_vcpu_ioctl_get_stats_fd->get_unused_fd_flags
// subgraph node: get_unused_fd_flags
// subgraph edge: kvm_vcpu_ioctl_get_stats_fd->snprintf
// subgraph node: snprintf
// subgraph edge: kvm_vcpu_ioctl_get_stats_fd->anon_inode_getfile
// subgraph node: anon_inode_getfile
// subgraph edge: kvm_vcpu_ioctl_get_stats_fd->fd_install
// subgraph node: fd_install
// subgraph edge: kvm_vcpu_ioctl_get_stats_fd->put_unused_fd
// subgraph node: put_unused_fd
// subgraph edge: kvm_vcpu_ioctl_get_stats_fd->kvm_get_kvm
// subgraph node: kvm_get_kvm
// subgraph edge: kvm_get_kvm->refcount_inc
// subgraph node: refcount_inc
// subgraph edge: kvm_vcpu_ioctl->kvm_arch_vcpu_ioctl
// subgraph node: kvm_arch_vcpu_ioctl
// subgraph edge: kvm_arch_vcpu_ioctl->unlikely
// subgraph edge: kvm_arch_vcpu_ioctl->kvm_check_request
// subgraph edge: kvm_arch_vcpu_ioctl->copy_from_user
// subgraph edge: kvm_arch_vcpu_ioctl->copy_to_user
// subgraph edge: kvm_arch_vcpu_ioctl->kvm_vcpu_initialized
// subgraph edge: kvm_arch_vcpu_ioctl->kvm_arm_vcpu_is_finalized
// subgraph edge: kvm_arch_vcpu_ioctl->kvm_reset_vcpu
// subgraph edge: kvm_arch_vcpu_ioctl->kvm_arch_vcpu_ioctl_vcpu_init
// subgraph node: kvm_arch_vcpu_ioctl_vcpu_init
// subgraph edge: kvm_arch_vcpu_ioctl_vcpu_init->bool
// subgraph edge: kvm_arch_vcpu_ioctl_vcpu_init->cpus_have_final_cap
// subgraph edge: kvm_arch_vcpu_ioctl_vcpu_init->BIT
// subgraph edge: kvm_arch_vcpu_ioctl_vcpu_init->WRITE_ONCE
// subgraph edge: kvm_arch_vcpu_ioctl_vcpu_init->spin_lock
// subgraph edge: kvm_arch_vcpu_ioctl_vcpu_init->spin_unlock
// subgraph edge: kvm_arch_vcpu_ioctl_vcpu_init->vcpu_has_run_once
// subgraph edge: kvm_arch_vcpu_ioctl_vcpu_init->kvm_vcpu_set_target
// subgraph node: kvm_vcpu_set_target
// subgraph edge: kvm_vcpu_set_target->kvm_vcpu_initialized
// subgraph edge: kvm_vcpu_set_target->kvm_reset_vcpu
// subgraph edge: kvm_vcpu_set_target->kvm_target_cpu
// subgraph node: kvm_target_cpu
// subgraph edge: kvm_target_cpu->read_cpuid_implementor
// subgraph node: read_cpuid_implementor
// subgraph edge: kvm_target_cpu->read_cpuid_part_number
// subgraph node: read_cpuid_part_number
// subgraph edge: kvm_vcpu_set_target->kvm_vcpu_init_check_features
// subgraph node: kvm_vcpu_init_check_features
// subgraph edge: kvm_vcpu_init_check_features->kvm_has_mte
// subgraph node: kvm_has_mte
// subgraph edge: kvm_vcpu_init_check_features->test_bit
// subgraph edge: kvm_vcpu_init_check_features->ARRAY_SIZE
// subgraph edge: kvm_vcpu_init_check_features->system_supported_vcpu_features
// subgraph node: system_supported_vcpu_features
// subgraph edge: system_supported_vcpu_features->cpus_have_final_cap
// subgraph edge: system_supported_vcpu_features->kvm_arm_support_pmu_v3
// subgraph edge: system_supported_vcpu_features->system_supports_sve
// subgraph edge: system_supported_vcpu_features->system_has_full_ptr_auth
// subgraph node: system_has_full_ptr_auth
// subgraph edge: system_supported_vcpu_features->clear_bit
// subgraph node: clear_bit
// subgraph edge: kvm_vcpu_set_target->kvm_vcpu_init_changed
// subgraph node: kvm_vcpu_init_changed
// subgraph edge: kvm_vcpu_init_changed->bitmap_equal
// subgraph node: bitmap_equal
// subgraph edge: kvm_arch_vcpu_ioctl_vcpu_init->stage2_unmap_vm
// subgraph node: stage2_unmap_vm
// subgraph edge: stage2_unmap_vm->srcu_read_lock
// subgraph edge: stage2_unmap_vm->write_lock
// subgraph node: write_lock
// subgraph edge: stage2_unmap_vm->kvm_memslots
// subgraph node: kvm_memslots
// subgraph edge: stage2_unmap_vm->kvm_for_each_memslot
// subgraph node: kvm_for_each_memslot
// subgraph edge: stage2_unmap_vm->write_unlock
// subgraph node: write_unlock
// subgraph edge: stage2_unmap_vm->srcu_read_unlock
// subgraph edge: stage2_unmap_vm->mmap_read_lock
// subgraph node: mmap_read_lock
// subgraph edge: stage2_unmap_vm->mmap_read_unlock
// subgraph node: mmap_read_unlock
// subgraph edge: stage2_unmap_vm->stage2_unmap_memslot
// subgraph node: stage2_unmap_memslot
// subgraph edge: stage2_unmap_memslot->min
// subgraph edge: stage2_unmap_memslot->max
// subgraph node: max
// subgraph edge: stage2_unmap_memslot->find_vma_intersection
// subgraph node: find_vma_intersection
// subgraph edge: stage2_unmap_memslot->unmap_stage2_range
// subgraph node: unmap_stage2_range
// subgraph edge: kvm_arch_vcpu_ioctl_vcpu_init->icache_inval_all_pou
// subgraph node: icache_inval_all_pou
// subgraph edge: kvm_arch_vcpu_ioctl_vcpu_init->vcpu_reset_hcr
// subgraph node: vcpu_reset_hcr
// subgraph edge: kvm_arch_vcpu_ioctl_vcpu_init->kvm_get_reset_cptr_el2
// subgraph node: kvm_get_reset_cptr_el2
// subgraph edge: kvm_arch_vcpu_ioctl->kvm_arm_set_reg
// subgraph node: kvm_arm_set_reg
// subgraph edge: kvm_arm_set_reg->set_core_reg
// subgraph node: set_core_reg
// subgraph edge: set_core_reg->kvm_supports_32bit_el0
// subgraph edge: set_core_reg->vcpu_el1_is_32bit
// subgraph edge: set_core_reg->vcpu_has_nv
// subgraph edge: set_core_reg->vcpu_cpsr
// subgraph edge: set_core_reg->vcpu_pc
// subgraph edge: set_core_reg->memcpy
// subgraph edge: set_core_reg->vcpu_get_reg
// subgraph edge: set_core_reg->vcpu_set_reg
// subgraph edge: set_core_reg->copy_from_user
// subgraph edge: set_core_reg->core_reg_offset_from_id
// subgraph node: core_reg_offset_from_id
// subgraph edge: set_core_reg->KVM_REG_SIZE
// subgraph node: KVM_REG_SIZE
// subgraph edge: set_core_reg->core_reg_addr
// subgraph node: core_reg_addr
// subgraph edge: core_reg_addr->core_reg_offset_from_id
// subgraph edge: core_reg_addr->KVM_REG_SIZE
// subgraph edge: core_reg_addr->KVM_REG_ARM_CORE_REG
// subgraph node: KVM_REG_ARM_CORE_REG
// subgraph edge: core_reg_addr->core_reg_size_from_offset
// subgraph node: core_reg_size_from_offset
// subgraph edge: core_reg_size_from_offset->vcpu_has_sve
// subgraph edge: core_reg_size_from_offset->IS_ALIGNED
// subgraph node: IS_ALIGNED
// subgraph edge: core_reg_size_from_offset->KVM_REG_ARM_CORE_REG
// subgraph edge: core_reg_size_from_offset->core_reg_offset_is_vreg
// subgraph node: core_reg_offset_is_vreg
// subgraph edge: core_reg_offset_is_vreg->KVM_REG_ARM_CORE_REG
// subgraph edge: set_core_reg->KVM_REG_ARM_CORE_REG
// subgraph edge: kvm_arm_set_reg->kvm_arm_set_fw_reg
// subgraph node: kvm_arm_set_fw_reg
// subgraph edge: kvm_arm_set_fw_reg->bool
// subgraph edge: kvm_arm_set_fw_reg->copy_from_user
// subgraph edge: kvm_arm_set_fw_reg->vcpu_has_feature
// subgraph edge: kvm_arm_set_fw_reg->KVM_REG_SIZE
// subgraph edge: kvm_arm_set_fw_reg->get_kernel_wa_level
// subgraph node: get_kernel_wa_level
// subgraph edge: get_kernel_wa_level->cpus_have_final_cap
// subgraph edge: get_kernel_wa_level->arm64_get_spectre_v2_state
// subgraph node: arm64_get_spectre_v2_state
// subgraph edge: get_kernel_wa_level->arm64_get_spectre_v4_state
// subgraph node: arm64_get_spectre_v4_state
// subgraph edge: get_kernel_wa_level->arm64_get_spectre_bhb_state
// subgraph node: arm64_get_spectre_bhb_state
// subgraph edge: kvm_arm_set_fw_reg->kvm_arm_set_fw_reg_bmap
// subgraph node: kvm_arm_set_fw_reg_bmap
// subgraph edge: kvm_arm_set_fw_reg_bmap->WRITE_ONCE
// subgraph edge: kvm_arm_set_fw_reg_bmap->kvm_vm_has_ran_once
// subgraph node: kvm_vm_has_ran_once
// subgraph edge: kvm_arm_set_fw_reg_bmap->mutex_lock
// subgraph edge: kvm_arm_set_fw_reg_bmap->mutex_unlock
// subgraph edge: kvm_arm_set_reg->set_sve_reg
// subgraph node: set_sve_reg
// subgraph edge: set_sve_reg->copy_from_user
// subgraph edge: set_sve_reg->kvm_arm_vcpu_sve_finalized
// subgraph edge: set_sve_reg->set_sve_vls
// subgraph node: set_sve_vls
// subgraph edge: set_sve_vls->vcpu_has_sve
// subgraph edge: set_sve_vls->WARN_ON
// subgraph edge: set_sve_vls->copy_from_user
// subgraph edge: set_sve_vls->kvm_arm_vcpu_sve_finalized
// subgraph edge: set_sve_vls->vq_present
// subgraph node: vq_present
// subgraph edge: set_sve_vls->sve_vq_from_vl
// subgraph node: sve_vq_from_vl
// subgraph edge: set_sve_vls->sve_vq_available
// subgraph node: sve_vq_available
// subgraph edge: set_sve_vls->sve_vl_from_vq
// subgraph node: sve_vl_from_vq
// subgraph edge: set_sve_reg->sve_reg_to_region
// subgraph node: sve_reg_to_region
// subgraph edge: sve_reg_to_region->vcpu_has_sve
// subgraph edge: sve_reg_to_region->WARN_ON
// subgraph edge: sve_reg_to_region->min
// subgraph edge: sve_reg_to_region->vcpu_sve_max_vq
// subgraph edge: sve_reg_to_region->BUILD_BUG_ON
// subgraph node: BUILD_BUG_ON
// subgraph edge: sve_reg_to_region->vcpu_sve_state_size
// subgraph edge: sve_reg_to_region->KVM_REG_ARM64_SVE_ZREG
// subgraph node: KVM_REG_ARM64_SVE_ZREG
// subgraph edge: sve_reg_to_region->KVM_REG_ARM64_SVE_PREG
// subgraph node: KVM_REG_ARM64_SVE_PREG
// subgraph edge: sve_reg_to_region->KVM_REG_ARM64_SVE_FFR
// subgraph node: KVM_REG_ARM64_SVE_FFR
// subgraph edge: sve_reg_to_region->SVE_SIG_ZREG_OFFSET
// subgraph node: SVE_SIG_ZREG_OFFSET
// subgraph edge: sve_reg_to_region->SVE_SIG_ZREG_SIZE
// subgraph node: SVE_SIG_ZREG_SIZE
// subgraph edge: sve_reg_to_region->SVE_SIG_PREG_OFFSET
// subgraph node: SVE_SIG_PREG_OFFSET
// subgraph edge: sve_reg_to_region->SVE_SIG_PREG_SIZE
// subgraph node: SVE_SIG_PREG_SIZE
// subgraph edge: sve_reg_to_region->array_index_nospec
// subgraph node: array_index_nospec
// subgraph edge: kvm_arm_set_reg->is_timer_reg
// subgraph node: is_timer_reg
// subgraph edge: kvm_arm_set_reg->set_timer_reg
// subgraph node: set_timer_reg
// subgraph edge: set_timer_reg->copy_from_user
// subgraph edge: set_timer_reg->KVM_REG_SIZE
// subgraph edge: set_timer_reg->kvm_arm_timer_set_reg
// subgraph node: kvm_arm_timer_set_reg
// subgraph edge: kvm_arm_timer_set_reg->kvm_arm_timer_write
// subgraph node: kvm_arm_timer_write
// subgraph edge: kvm_arm_timer_write->BUG
// subgraph edge: kvm_arm_timer_write->timer_set_cval
// subgraph edge: kvm_arm_timer_write->kvm_phys_timer_read
// subgraph edge: kvm_arm_timer_write->timer_get_offset
// subgraph edge: kvm_arm_timer_write->timer_set_ctl
// subgraph edge: kvm_arm_timer_set_reg->vcpu_vtimer
// subgraph edge: kvm_arm_timer_set_reg->vcpu_ptimer
// subgraph edge: kvm_arm_timer_set_reg->kvm_phys_timer_read
// subgraph edge: kvm_arm_timer_set_reg->test_bit
// subgraph edge: kvm_arm_timer_set_reg->timer_set_offset
// subgraph node: timer_set_offset
// subgraph edge: timer_set_offset->arch_timer_ctx_index
// subgraph edge: timer_set_offset->WRITE_ONCE
// subgraph edge: timer_set_offset->WARN
// subgraph edge: kvm_arm_set_reg->kvm_arm_sys_reg_set_reg
// subgraph node: kvm_arm_sys_reg_set_reg
// subgraph edge: kvm_arm_sys_reg_set_reg->ARRAY_SIZE
// subgraph edge: kvm_arm_sys_reg_set_reg->demux_c15_set
// subgraph node: demux_c15_set
// subgraph edge: demux_c15_set->get_user
// subgraph node: get_user
// subgraph edge: demux_c15_set->KVM_REG_SIZE
// subgraph edge: demux_c15_set->set_ccsidr
// subgraph node: set_ccsidr
// subgraph edge: set_ccsidr->get_ccsidr
// subgraph node: get_ccsidr
// subgraph edge: get_ccsidr->get_min_cache_line_size
// subgraph node: get_min_cache_line_size
// subgraph edge: get_min_cache_line_size->read_sanitised_ftr_reg
// subgraph node: read_sanitised_ftr_reg
// subgraph edge: get_min_cache_line_size->SYS_FIELD_GET
// subgraph edge: get_ccsidr->SYS_FIELD_PREP
// subgraph node: SYS_FIELD_PREP
// subgraph edge: set_ccsidr->get_min_cache_line_size
// subgraph edge: set_ccsidr->FIELD_GET
// subgraph node: FIELD_GET
// subgraph edge: set_ccsidr->kmalloc_array
// subgraph node: kmalloc_array
// subgraph edge: kvm_arm_sys_reg_set_reg->set_invariant_sys_reg
// subgraph node: set_invariant_sys_reg
// subgraph edge: set_invariant_sys_reg->ARRAY_SIZE
// subgraph edge: set_invariant_sys_reg->get_user
// subgraph edge: set_invariant_sys_reg->get_reg_by_id
// subgraph node: get_reg_by_id
// subgraph edge: get_reg_by_id->find_reg
// subgraph node: find_reg
// subgraph edge: get_reg_by_id->index_to_params
// subgraph node: index_to_params
// subgraph edge: kvm_arm_sys_reg_set_reg->kvm_sys_reg_set_user
// subgraph node: kvm_sys_reg_set_user
// subgraph edge: kvm_sys_reg_set_user->get_user
// subgraph edge: kvm_sys_reg_set_user->id_to_sys_reg_desc
// subgraph node: id_to_sys_reg_desc
// subgraph edge: id_to_sys_reg_desc->sysreg_hidden
// subgraph node: sysreg_hidden
// subgraph edge: id_to_sys_reg_desc->get_reg_by_id
// subgraph edge: kvm_sys_reg_set_user->sysreg_hidden_user
// subgraph node: sysreg_hidden_user
// subgraph edge: kvm_sys_reg_set_user->sysreg_user_write_ignore
// subgraph node: sysreg_user_write_ignore
// subgraph edge: kvm_arch_vcpu_ioctl->kvm_arm_get_reg
// subgraph node: kvm_arm_get_reg
// subgraph edge: kvm_arm_get_reg->is_timer_reg
// subgraph edge: kvm_arm_get_reg->get_core_reg
// subgraph node: get_core_reg
// subgraph edge: get_core_reg->copy_to_user
// subgraph edge: get_core_reg->core_reg_offset_from_id
// subgraph edge: get_core_reg->KVM_REG_SIZE
// subgraph edge: get_core_reg->core_reg_addr
// subgraph edge: kvm_arm_get_reg->kvm_arm_get_fw_reg
// subgraph node: kvm_arm_get_fw_reg
// subgraph edge: kvm_arm_get_fw_reg->READ_ONCE
// subgraph edge: kvm_arm_get_fw_reg->kvm_psci_version
// subgraph node: kvm_psci_version
// subgraph edge: kvm_arm_get_fw_reg->copy_to_user
// subgraph edge: kvm_arm_get_fw_reg->KVM_REG_SIZE
// subgraph edge: kvm_arm_get_fw_reg->get_kernel_wa_level
// subgraph edge: kvm_arm_get_reg->get_sve_reg
// subgraph node: get_sve_reg
// subgraph edge: get_sve_reg->copy_to_user
// subgraph edge: get_sve_reg->kvm_arm_vcpu_sve_finalized
// subgraph edge: get_sve_reg->sve_reg_to_region
// subgraph edge: get_sve_reg->get_sve_vls
// subgraph node: get_sve_vls
// subgraph edge: get_sve_vls->vcpu_has_sve
// subgraph edge: get_sve_vls->WARN_ON
// subgraph edge: get_sve_vls->memset
// subgraph edge: get_sve_vls->vcpu_sve_max_vq
// subgraph edge: get_sve_vls->copy_to_user
// subgraph edge: get_sve_vls->sve_vq_available
// subgraph edge: get_sve_vls->sve_vl_valid
// subgraph node: sve_vl_valid
// subgraph edge: get_sve_vls->vq_word
// subgraph node: vq_word
// subgraph edge: get_sve_vls->vq_mask
// subgraph node: vq_mask
// subgraph edge: get_sve_reg->clear_user
// subgraph node: clear_user
// subgraph edge: kvm_arm_get_reg->get_timer_reg
// subgraph node: get_timer_reg
// subgraph edge: get_timer_reg->copy_to_user
// subgraph edge: get_timer_reg->kvm_arm_timer_get_reg
// subgraph node: kvm_arm_timer_get_reg
// subgraph edge: kvm_arm_timer_get_reg->vcpu_vtimer
// subgraph edge: kvm_arm_timer_get_reg->vcpu_ptimer
// subgraph edge: kvm_arm_timer_get_reg->kvm_arm_timer_read
// subgraph node: kvm_arm_timer_read
// subgraph edge: kvm_arm_timer_read->BUG
// subgraph edge: kvm_arm_timer_read->kvm_phys_timer_read
// subgraph edge: kvm_arm_timer_read->timer_get_offset
// subgraph edge: kvm_arm_timer_read->timer_get_cval
// subgraph edge: kvm_arm_timer_read->lower_32_bits
// subgraph edge: kvm_arm_timer_read->read_timer_ctl
// subgraph node: read_timer_ctl
// subgraph edge: read_timer_ctl->kvm_timer_compute_delta
// subgraph edge: read_timer_ctl->timer_get_ctl
// subgraph edge: get_timer_reg->KVM_REG_SIZE
// subgraph edge: kvm_arm_get_reg->kvm_arm_sys_reg_get_reg
// subgraph node: kvm_arm_sys_reg_get_reg
// subgraph edge: kvm_arm_sys_reg_get_reg->ARRAY_SIZE
// subgraph edge: kvm_arm_sys_reg_get_reg->demux_c15_get
// subgraph node: demux_c15_get
// subgraph edge: demux_c15_get->get_ccsidr
// subgraph edge: demux_c15_get->KVM_REG_SIZE
// subgraph edge: demux_c15_get->put_user
// subgraph node: put_user
// subgraph edge: kvm_arm_sys_reg_get_reg->get_invariant_sys_reg
// subgraph node: get_invariant_sys_reg
// subgraph edge: get_invariant_sys_reg->ARRAY_SIZE
// subgraph edge: get_invariant_sys_reg->get_reg_by_id
// subgraph edge: get_invariant_sys_reg->put_user
// subgraph edge: kvm_arm_sys_reg_get_reg->kvm_sys_reg_get_user
// subgraph node: kvm_sys_reg_get_user
// subgraph edge: kvm_sys_reg_get_user->id_to_sys_reg_desc
// subgraph edge: kvm_sys_reg_get_user->sysreg_hidden_user
// subgraph edge: kvm_sys_reg_get_user->put_user
// subgraph edge: kvm_arch_vcpu_ioctl->kvm_arm_num_regs
// subgraph node: kvm_arm_num_regs
// subgraph edge: kvm_arm_num_regs->num_core_regs
// subgraph node: num_core_regs
// subgraph edge: num_core_regs->copy_core_reg_indices
// subgraph node: copy_core_reg_indices
// subgraph edge: copy_core_reg_indices->WARN_ON
// subgraph edge: copy_core_reg_indices->core_reg_size_from_offset
// subgraph edge: copy_core_reg_indices->put_user
// subgraph edge: kvm_arm_num_regs->num_sve_regs
// subgraph node: num_sve_regs
// subgraph edge: num_sve_regs->vcpu_has_sve
// subgraph edge: num_sve_regs->WARN_ON
// subgraph edge: num_sve_regs->kvm_arm_vcpu_sve_finalized
// subgraph edge: num_sve_regs->vcpu_sve_slices
// subgraph node: vcpu_sve_slices
// subgraph edge: kvm_arm_num_regs->kvm_arm_num_sys_reg_descs
// subgraph node: kvm_arm_num_sys_reg_descs
// subgraph edge: kvm_arm_num_sys_reg_descs->ARRAY_SIZE
// subgraph edge: kvm_arm_num_sys_reg_descs->num_demux_regs
// subgraph node: num_demux_regs
// subgraph edge: kvm_arm_num_sys_reg_descs->walk_sys_regs
// subgraph node: walk_sys_regs
// subgraph edge: walk_sys_regs->ARRAY_SIZE
// subgraph edge: walk_sys_regs->walk_one_sys_reg
// subgraph node: walk_one_sys_reg
// subgraph edge: walk_one_sys_reg->sysreg_hidden_user
// subgraph edge: walk_one_sys_reg->copy_reg_to_user
// subgraph node: copy_reg_to_user
// subgraph edge: copy_reg_to_user->put_user
// subgraph edge: copy_reg_to_user->sys_reg_to_index
// subgraph node: sys_reg_to_index
// subgraph edge: kvm_arm_num_regs->kvm_arm_get_fw_num_regs
// subgraph node: kvm_arm_get_fw_num_regs
// subgraph edge: kvm_arm_get_fw_num_regs->ARRAY_SIZE
// subgraph edge: kvm_arch_vcpu_ioctl->kvm_arm_copy_reg_indices
// subgraph node: kvm_arm_copy_reg_indices
// subgraph edge: kvm_arm_copy_reg_indices->kvm_arm_get_fw_num_regs
// subgraph edge: kvm_arm_copy_reg_indices->copy_core_reg_indices
// subgraph edge: kvm_arm_copy_reg_indices->copy_sve_reg_indices
// subgraph node: copy_sve_reg_indices
// subgraph edge: copy_sve_reg_indices->vcpu_has_sve
// subgraph edge: copy_sve_reg_indices->WARN_ON
// subgraph edge: copy_sve_reg_indices->kvm_arm_vcpu_sve_finalized
// subgraph edge: copy_sve_reg_indices->KVM_REG_ARM64_SVE_ZREG
// subgraph edge: copy_sve_reg_indices->KVM_REG_ARM64_SVE_PREG
// subgraph edge: copy_sve_reg_indices->KVM_REG_ARM64_SVE_FFR
// subgraph edge: copy_sve_reg_indices->put_user
// subgraph edge: copy_sve_reg_indices->vcpu_sve_slices
// subgraph edge: kvm_arm_copy_reg_indices->kvm_arm_copy_fw_reg_indices
// subgraph node: kvm_arm_copy_fw_reg_indices
// subgraph edge: kvm_arm_copy_fw_reg_indices->ARRAY_SIZE
// subgraph edge: kvm_arm_copy_fw_reg_indices->put_user
// subgraph edge: kvm_arm_copy_reg_indices->copy_timer_indices
// subgraph node: copy_timer_indices
// subgraph edge: kvm_arm_copy_reg_indices->kvm_arm_copy_sys_reg_indices
// subgraph node: kvm_arm_copy_sys_reg_indices
// subgraph edge: kvm_arm_copy_sys_reg_indices->ARRAY_SIZE
// subgraph edge: kvm_arm_copy_sys_reg_indices->put_user
// subgraph edge: kvm_arm_copy_sys_reg_indices->walk_sys_regs
// subgraph edge: kvm_arm_copy_sys_reg_indices->sys_reg_to_index
// subgraph edge: kvm_arm_copy_sys_reg_indices->write_demux_regids
// subgraph node: write_demux_regids
// subgraph edge: write_demux_regids->put_user
// subgraph edge: kvm_arch_vcpu_ioctl->kvm_arm_vcpu_set_attr
// subgraph node: kvm_arm_vcpu_set_attr
// subgraph edge: kvm_arm_vcpu_set_attr->kvm_arm_vcpu_arch_set_attr
// subgraph node: kvm_arm_vcpu_arch_set_attr
// subgraph edge: kvm_arm_vcpu_arch_set_attr->mutex_lock
// subgraph edge: kvm_arm_vcpu_arch_set_attr->mutex_unlock
// subgraph edge: kvm_arm_vcpu_arch_set_attr->kvm_arm_pmu_v3_set_attr
// subgraph node: kvm_arm_pmu_v3_set_attr
// subgraph edge: kvm_arm_pmu_v3_set_attr->irqchip_in_kernel
// subgraph edge: kvm_arm_pmu_v3_set_attr->kvm_vcpu_has_pmu
// subgraph edge: kvm_arm_pmu_v3_set_attr->kvm_debug
// subgraph edge: kvm_arm_pmu_v3_set_attr->kvm_vm_has_ran_once
// subgraph edge: kvm_arm_pmu_v3_set_attr->bitmap_clear
// subgraph node: bitmap_clear
// subgraph edge: kvm_arm_pmu_v3_set_attr->bitmap_zero
// subgraph edge: kvm_arm_pmu_v3_set_attr->copy_from_user
// subgraph edge: kvm_arm_pmu_v3_set_attr->lockdep_assert_held
// subgraph edge: kvm_arm_pmu_v3_set_attr->kvm_arm_pmu_get_pmuver_limit
// subgraph node: kvm_arm_pmu_get_pmuver_limit
// subgraph edge: kvm_arm_pmu_get_pmuver_limit->read_sanitised_ftr_reg
// subgraph edge: kvm_arm_pmu_get_pmuver_limit->FIELD_GET
// subgraph edge: kvm_arm_pmu_get_pmuver_limit->ARM64_FEATURE_MASK
// subgraph node: ARM64_FEATURE_MASK
// subgraph edge: kvm_arm_pmu_get_pmuver_limit->cpuid_feature_cap_perfmon_field
// subgraph node: cpuid_feature_cap_perfmon_field
// subgraph edge: kvm_arm_pmu_v3_set_attr->irq_is_ppi
// subgraph edge: kvm_arm_pmu_v3_set_attr->kvm_arm_pmu_irq_initialized
// subgraph edge: kvm_arm_pmu_v3_set_attr->get_user
// subgraph edge: kvm_arm_pmu_v3_set_attr->irq_is_spi
// subgraph node: irq_is_spi
// subgraph edge: kvm_arm_pmu_v3_set_attr->pmu_irq_is_valid
// subgraph node: pmu_irq_is_valid
// subgraph edge: pmu_irq_is_valid->kvm_for_each_vcpu
// subgraph edge: pmu_irq_is_valid->irq_is_ppi
// subgraph edge: pmu_irq_is_valid->kvm_arm_pmu_irq_initialized
// subgraph edge: kvm_arm_pmu_v3_set_attr->bitmap_alloc
// subgraph node: bitmap_alloc
// subgraph edge: kvm_arm_pmu_v3_set_attr->bitmap_fill
// subgraph node: bitmap_fill
// subgraph edge: kvm_arm_pmu_v3_set_attr->bitmap_set
// subgraph node: bitmap_set
// subgraph edge: kvm_arm_pmu_v3_set_attr->kvm_arm_pmu_v3_set_pmu
// subgraph node: kvm_arm_pmu_v3_set_pmu
// subgraph edge: kvm_arm_pmu_v3_set_pmu->kvm_vm_has_ran_once
// subgraph edge: kvm_arm_pmu_v3_set_pmu->mutex_lock
// subgraph edge: kvm_arm_pmu_v3_set_pmu->mutex_unlock
// subgraph edge: kvm_arm_pmu_v3_set_pmu->cpumask_copy
// subgraph node: cpumask_copy
// subgraph edge: kvm_arm_pmu_v3_set_pmu->lockdep_assert_held
// subgraph edge: kvm_arm_pmu_v3_set_pmu->list_for_each_entry
// subgraph node: list_for_each_entry
// subgraph edge: kvm_arm_pmu_v3_set_pmu->kvm_arm_set_pmu
// subgraph node: kvm_arm_set_pmu
// subgraph edge: kvm_arm_set_pmu->lockdep_assert_held
// subgraph edge: kvm_arm_set_pmu->kvm_arm_pmu_get_max_counters
// subgraph node: kvm_arm_pmu_get_max_counters
// subgraph edge: kvm_arm_pmu_v3_set_attr->kvm_arm_pmu_v3_init
// subgraph node: kvm_arm_pmu_v3_init
// subgraph edge: kvm_arm_pmu_v3_init->irqchip_in_kernel
// subgraph edge: kvm_arm_pmu_v3_init->kvm_arm_pmu_irq_initialized
// subgraph edge: kvm_arm_pmu_v3_init->vgic_initialized
// subgraph node: vgic_initialized
// subgraph edge: kvm_arm_pmu_v3_init->kvm_vgic_set_owner
// subgraph node: kvm_vgic_set_owner
// subgraph edge: kvm_arm_pmu_v3_init->init_irq_work
// subgraph node: init_irq_work
// subgraph edge: kvm_arm_pmu_v3_init->kvm_pmu_perf_overflow_notify_vcpu
// subgraph node: kvm_pmu_perf_overflow_notify_vcpu
// subgraph edge: kvm_pmu_perf_overflow_notify_vcpu->container_of
// subgraph edge: kvm_pmu_perf_overflow_notify_vcpu->kvm_vcpu_kick
// subgraph edge: kvm_arm_vcpu_arch_set_attr->kvm_arm_timer_set_attr
// subgraph node: kvm_arm_timer_set_attr
// subgraph edge: kvm_arm_timer_set_attr->irqchip_in_kernel
// subgraph edge: kvm_arm_timer_set_attr->test_bit
// subgraph edge: kvm_arm_timer_set_attr->mutex_lock
// subgraph edge: kvm_arm_timer_set_attr->mutex_unlock
// subgraph edge: kvm_arm_timer_set_attr->irq_is_ppi
// subgraph edge: kvm_arm_timer_set_attr->get_user
// subgraph edge: kvm_arm_vcpu_arch_set_attr->kvm_arm_pvtime_set_attr
// subgraph node: kvm_arm_pvtime_set_attr
// subgraph edge: kvm_arm_pvtime_set_attr->srcu_read_lock
// subgraph edge: kvm_arm_pvtime_set_attr->srcu_read_unlock
// subgraph edge: kvm_arm_pvtime_set_attr->kvm_is_error_hva
// subgraph node: kvm_is_error_hva
// subgraph edge: kvm_arm_pvtime_set_attr->IS_ALIGNED
// subgraph edge: kvm_arm_pvtime_set_attr->kvm_arm_pvtime_supported
// subgraph node: kvm_arm_pvtime_supported
// subgraph edge: kvm_arm_pvtime_supported->sched_info_on
// subgraph node: sched_info_on
// subgraph edge: kvm_arm_pvtime_set_attr->get_user
// subgraph edge: kvm_arm_pvtime_set_attr->gfn_to_hva
// subgraph node: gfn_to_hva
// subgraph edge: gfn_to_hva->gfn_to_memslot
// subgraph node: gfn_to_memslot
// subgraph edge: gfn_to_memslot->kvm_memslots
// subgraph edge: gfn_to_hva->gfn_to_hva_many
// subgraph node: gfn_to_hva_many
// subgraph edge: kvm_arch_vcpu_ioctl->kvm_arm_vcpu_get_attr
// subgraph node: kvm_arm_vcpu_get_attr
// subgraph edge: kvm_arm_vcpu_get_attr->kvm_arm_vcpu_arch_get_attr
// subgraph node: kvm_arm_vcpu_arch_get_attr
// subgraph edge: kvm_arm_vcpu_arch_get_attr->kvm_arm_pmu_v3_get_attr
// subgraph node: kvm_arm_pmu_v3_get_attr
// subgraph edge: kvm_arm_pmu_v3_get_attr->irqchip_in_kernel
// subgraph edge: kvm_arm_pmu_v3_get_attr->kvm_vcpu_has_pmu
// subgraph edge: kvm_arm_pmu_v3_get_attr->kvm_arm_pmu_irq_initialized
// subgraph edge: kvm_arm_pmu_v3_get_attr->put_user
// subgraph edge: kvm_arm_vcpu_arch_get_attr->kvm_arm_timer_get_attr
// subgraph node: kvm_arm_timer_get_attr
// subgraph edge: kvm_arm_timer_get_attr->vcpu_hvtimer
// subgraph edge: kvm_arm_timer_get_attr->vcpu_hptimer
// subgraph edge: kvm_arm_timer_get_attr->vcpu_vtimer
// subgraph edge: kvm_arm_timer_get_attr->vcpu_ptimer
// subgraph edge: kvm_arm_timer_get_attr->timer_irq
// subgraph edge: kvm_arm_timer_get_attr->put_user
// subgraph edge: kvm_arm_vcpu_arch_get_attr->kvm_arm_pvtime_get_attr
// subgraph node: kvm_arm_pvtime_get_attr
// subgraph edge: kvm_arm_pvtime_get_attr->kvm_arm_pvtime_supported
// subgraph edge: kvm_arm_pvtime_get_attr->put_user
// subgraph edge: kvm_arch_vcpu_ioctl->kvm_arm_vcpu_has_attr
// subgraph node: kvm_arm_vcpu_has_attr
// subgraph edge: kvm_arm_vcpu_has_attr->kvm_arm_vcpu_arch_has_attr
// subgraph node: kvm_arm_vcpu_arch_has_attr
// subgraph edge: kvm_arm_vcpu_arch_has_attr->kvm_arm_pmu_v3_has_attr
// subgraph node: kvm_arm_pmu_v3_has_attr
// subgraph edge: kvm_arm_pmu_v3_has_attr->kvm_vcpu_has_pmu
// subgraph edge: kvm_arm_vcpu_arch_has_attr->kvm_arm_timer_has_attr
// subgraph node: kvm_arm_timer_has_attr
// subgraph edge: kvm_arm_vcpu_arch_has_attr->kvm_arm_pvtime_has_attr
// subgraph node: kvm_arm_pvtime_has_attr
// subgraph edge: kvm_arm_pvtime_has_attr->kvm_arm_pvtime_supported
// subgraph edge: kvm_arch_vcpu_ioctl->kvm_arm_vcpu_get_events
// subgraph node: kvm_arm_vcpu_get_events
// subgraph edge: kvm_arm_vcpu_get_events->memset
// subgraph edge: kvm_arch_vcpu_ioctl->kvm_arm_vcpu_set_events
// subgraph node: kvm_arm_vcpu_set_events
// subgraph edge: kvm_arm_vcpu_set_events->ARRAY_SIZE
// subgraph edge: kvm_arch_vcpu_ioctl->get_user
// subgraph edge: kvm_arch_vcpu_ioctl->kvm_arm_vcpu_finalize
// subgraph node: kvm_arm_vcpu_finalize
// subgraph edge: kvm_arm_vcpu_finalize->vcpu_has_sve
// subgraph edge: kvm_arm_vcpu_finalize->kvm_arm_vcpu_sve_finalized
// subgraph edge: kvm_arm_vcpu_finalize->kvm_vcpu_finalize_sve
// subgraph node: kvm_vcpu_finalize_sve
// subgraph edge: kvm_vcpu_finalize_sve->WARN_ON
// subgraph edge: kvm_vcpu_finalize_sve->kfree
// subgraph edge: kvm_vcpu_finalize_sve->vcpu_set_flag
// subgraph edge: kvm_vcpu_finalize_sve->sve_max_virtualisable_vl
// subgraph node: sve_max_virtualisable_vl
// subgraph edge: kvm_vcpu_finalize_sve->kzalloc
// subgraph edge: kvm_vcpu_finalize_sve->vcpu_sve_state_size
// subgraph edge: kvm_vcpu_finalize_sve->kvm_share_hyp
// subgraph edge: kvm_vcpu_finalize_sve->sve_vl_valid
digraph gvpr_result {
	node [shape=box];
	kvm_supports_32bit_el0	[label="kvm_supports_32bit_el0()"];
	reg_to_encoding	[label="reg_to_encoding()"];
	vcpu_has_sve	[label="vcpu_has_sve()"];
	vcpu_read_sys_reg	[label="u64 vcpu_read_sys_reg (const struct kvm_vcpu *vcpu, int reg)
arch/arm64/kvm/sys_regs.c:68"];
	vcpu_get_flag	[label="vcpu_get_flag()"];
	vcpu_read_sys_reg -> vcpu_get_flag;
	vcpu_el1_is_32bit	[label="vcpu_el1_is_32bit()"];
	vcpu_write_sys_reg	[label="void vcpu_write_sys_reg (struct kvm_vcpu *vcpu, u64 val, int reg)
arch/arm64/kvm/sys_regs.c:79"];
	vcpu_write_sys_reg -> vcpu_get_flag;
	likely	[label="likely()"];
	vcpu_has_nv	[label="vcpu_has_nv()"];
	vcpu_cpsr	[label="vcpu_cpsr()"];
	BUG	[label="BUG()"];
	get_timer_map	[label="void get_timer_map (struct kvm_vcpu *vcpu, struct timer_map *map)
arch/arm64/kvm/arch_timer.c:178"];
	get_timer_map -> vcpu_has_nv;
	is_hyp_ctxt	[label="is_hyp_ctxt()"];
	get_timer_map -> is_hyp_ctxt;
	vcpu_hvtimer	[label="vcpu_hvtimer()"];
	get_timer_map -> vcpu_hvtimer;
	vcpu_hptimer	[label="vcpu_hptimer()"];
	get_timer_map -> vcpu_hptimer;
	vcpu_vtimer	[label="vcpu_vtimer()"];
	get_timer_map -> vcpu_vtimer;
	vcpu_ptimer	[label="vcpu_ptimer()"];
	get_timer_map -> vcpu_ptimer;
	has_vhe	[label="has_vhe()"];
	get_timer_map -> has_vhe;
	trace_kvm_get_timer_map	[label="trace_kvm_get_timer_map()"];
	get_timer_map -> trace_kvm_get_timer_map;
	vcpu_get_timer	[label="vcpu_get_timer()"];
	soft_timer_cancel	[label="void soft_timer_cancel (struct hrtimer *hrt)
arch/arm64/kvm/arch_timer.c:219"];
	hrtimer_cancel	[label="hrtimer_cancel()"];
	soft_timer_cancel -> hrtimer_cancel;
	kvm_arm_timer_write	[label="void kvm_arm_timer_write (struct kvm_vcpu *vcpu, struct arch_timer_context *timer, enum kvm_arch_timer_regs treg, u64 val)
arch/\
arm64/kvm/arch_timer.c:1193"];
	kvm_arm_timer_write -> BUG;
	timer_set_cval	[label="void timer_set_cval (struct arch_timer_context *ctxt, u64 cval)
arch/arm64/kvm/arch_timer.c:141"];
	kvm_arm_timer_write -> timer_set_cval;
	kvm_phys_timer_read	[label="u64 kvm_phys_timer_read (void)
arch/arm64/kvm/arch_timer.c:173"];
	kvm_arm_timer_write -> kvm_phys_timer_read;
	timer_get_offset	[label="u64 timer_get_offset (struct arch_timer_context *ctxt)
arch/arm64/kvm/arch_timer.c:104"];
	kvm_arm_timer_write -> timer_get_offset;
	timer_set_ctl	[label="void timer_set_ctl (struct arch_timer_context *ctxt, u32 ctl)
arch/arm64/kvm/arch_timer.c:119"];
	kvm_arm_timer_write -> timer_set_ctl;
	timer_emulate	[label="void timer_emulate (struct arch_timer_context *ctx)
arch/arm64/kvm/arch_timer.c:465"];
	bool	[label="bool()"];
	timer_emulate -> bool;
	kvm_timer_should_fire	[label="bool kvm_timer_should_fire (struct arch_timer_context *timer_ctx)
arch/arm64/kvm/arch_timer.c:381"];
	timer_emulate -> kvm_timer_should_fire;
	trace_kvm_timer_emulate	[label="trace_kvm_timer_emulate()"];
	timer_emulate -> trace_kvm_timer_emulate;
	kvm_timer_update_irq	[label="void kvm_timer_update_irq (struct kvm_vcpu *vcpu, bool new_level, struct arch_timer_context *timer_ctx)
arch/arm64/kvm/arch_timer.c:\
446"];
	timer_emulate -> kvm_timer_update_irq;
	kvm_timer_irq_can_fire	[label="bool kvm_timer_irq_can_fire (struct arch_timer_context *timer_ctx)
arch/arm64/kvm/arch_timer.c:279"];
	timer_emulate -> kvm_timer_irq_can_fire;
	soft_timer_start	[label="void soft_timer_start (struct hrtimer *hrt, u64 ns)
arch/arm64/kvm/arch_timer.c:213"];
	timer_emulate -> soft_timer_start;
	kvm_timer_compute_delta	[label="u64 kvm_timer_compute_delta (struct arch_timer_context *timer_ctx)
arch/arm64/kvm/arch_timer.c:274"];
	timer_emulate -> kvm_timer_compute_delta;
	preempt_disable	[label="preempt_disable()"];
	timer_save_state	[label="void timer_save_state (struct arch_timer_context *ctx)
arch/arm64/kvm/arch_timer.c:498"];
	timer_save_state -> BUG;
	timer_save_state -> timer_set_cval;
	timer_save_state -> timer_get_offset;
	timer_save_state -> timer_set_ctl;
	arch_timer_ctx_index	[label="arch_timer_ctx_index()"];
	timer_save_state -> arch_timer_ctx_index;
	read_sysreg_el0	[label="read_sysreg_el0()"];
	timer_save_state -> read_sysreg_el0;
	vcpu_timer	[label="vcpu_timer()"];
	timer_save_state -> vcpu_timer;
	local_irq_save	[label="local_irq_save()"];
	timer_save_state -> local_irq_save;
	write_sysreg_el0	[label="write_sysreg_el0()"];
	timer_save_state -> write_sysreg_el0;
	isb	[label="isb()"];
	timer_save_state -> isb;
	set_cntvoff	[label="void set_cntvoff (u64 cntvoff)
arch/arm64/kvm/arch_timer.c:487"];
	timer_save_state -> set_cntvoff;
	set_cntpoff	[label="void set_cntpoff (u64 cntpoff)
arch/arm64/kvm/arch_timer.c:492"];
	timer_save_state -> set_cntpoff;
	trace_kvm_timer_save_state	[label="trace_kvm_timer_save_state()"];
	timer_save_state -> trace_kvm_timer_save_state;
	local_irq_restore	[label="local_irq_restore()"];
	timer_save_state -> local_irq_restore;
	timer_restore_state	[label="void timer_restore_state (struct arch_timer_context *ctx)
arch/arm64/kvm/arch_timer.c:604"];
	timer_restore_state -> BUG;
	timer_restore_state -> timer_get_offset;
	timer_restore_state -> arch_timer_ctx_index;
	timer_get_cval	[label="u64 timer_get_cval (struct arch_timer_context *ctxt)
arch/arm64/kvm/arch_timer.c:85"];
	timer_restore_state -> timer_get_cval;
	timer_get_ctl	[label="u32 timer_get_ctl (struct arch_timer_context *ctxt)
arch/arm64/kvm/arch_timer.c:66"];
	timer_restore_state -> timer_get_ctl;
	timer_restore_state -> vcpu_timer;
	timer_restore_state -> local_irq_save;
	timer_restore_state -> write_sysreg_el0;
	timer_restore_state -> isb;
	timer_restore_state -> set_cntvoff;
	timer_restore_state -> set_cntpoff;
	timer_restore_state -> local_irq_restore;
	trace_kvm_timer_restore_state	[label="trace_kvm_timer_restore_state()"];
	timer_restore_state -> trace_kvm_timer_restore_state;
	preempt_enable	[label="preempt_enable()"];
	timer_set_cval -> arch_timer_ctx_index;
	WARN_ON	[label="WARN_ON()"];
	timer_set_cval -> WARN_ON;
	timer_set_ctl -> arch_timer_ctx_index;
	timer_set_ctl -> WARN_ON;
	kvm_timer_should_fire -> kvm_phys_timer_read;
	kvm_timer_should_fire -> timer_get_offset;
	kvm_timer_should_fire -> arch_timer_ctx_index;
	kvm_timer_should_fire -> kvm_timer_irq_can_fire;
	kvm_timer_should_fire -> read_sysreg_el0;
	kvm_timer_should_fire -> timer_get_cval;
	kvm_timer_update_irq -> WARN_ON;
	trace_kvm_timer_update_irq	[label="trace_kvm_timer_update_irq()"];
	kvm_timer_update_irq -> trace_kvm_timer_update_irq;
	timer_irq	[label="timer_irq()"];
	kvm_timer_update_irq -> timer_irq;
	userspace_irqchip	[label="inline bool userspace_irqchip (struct kvm *kvm)
arch/arm64/kvm/arch_timer.c:207"];
	kvm_timer_update_irq -> userspace_irqchip;
	kvm_vgic_inject_irq	[label="kvm_vgic_inject_irq()"];
	kvm_timer_update_irq -> kvm_vgic_inject_irq;
	kvm_timer_irq_can_fire -> WARN_ON;
	kvm_timer_irq_can_fire -> timer_get_ctl;
	hrtimer_start	[label="hrtimer_start()"];
	soft_timer_start -> hrtimer_start;
	ktime_add_ns	[label="ktime_add_ns()"];
	soft_timer_start -> ktime_add_ns;
	ktime_get	[label="ktime_get()"];
	soft_timer_start -> ktime_get;
	kvm_timer_compute_delta -> timer_get_cval;
	kvm_counter_compute_delta	[label="u64 kvm_counter_compute_delta (struct arch_timer_context *timer_ctx, u64 val)
arch/arm64/kvm/arch_timer.c:256"];
	kvm_timer_compute_delta -> kvm_counter_compute_delta;
	timer_get_cval -> arch_timer_ctx_index;
	timer_get_cval -> WARN_ON;
	timer_get_ctl -> arch_timer_ctx_index;
	timer_get_ctl -> WARN_ON;
	static_branch_unlikely	[label="static_branch_unlikely()"];
	userspace_irqchip -> static_branch_unlikely;
	unlikely	[label="unlikely()"];
	userspace_irqchip -> unlikely;
	irqchip_in_kernel	[label="irqchip_in_kernel()"];
	userspace_irqchip -> irqchip_in_kernel;
	kvm_counter_compute_delta -> kvm_phys_timer_read;
	kvm_counter_compute_delta -> timer_get_offset;
	cyclecounter_cyc2ns	[label="cyclecounter_cyc2ns()"];
	kvm_counter_compute_delta -> cyclecounter_cyc2ns;
	kvm_call_hyp	[label="kvm_call_hyp()"];
	set_cntvoff -> kvm_call_hyp;
	has_cntpoff	[label="has_cntpoff()"];
	set_cntpoff -> has_cntpoff;
	write_sysreg_s	[label="write_sysreg_s()"];
	set_cntpoff -> write_sysreg_s;
	kvm_arm_timer_read	[label="u64 kvm_arm_timer_read (struct kvm_vcpu *vcpu, struct arch_timer_context *timer, enum kvm_arch_timer_regs treg)
arch/arm64/kvm/arch_\
timer.c:1133"];
	kvm_arm_timer_read -> BUG;
	kvm_arm_timer_read -> kvm_phys_timer_read;
	kvm_arm_timer_read -> timer_get_offset;
	kvm_arm_timer_read -> timer_get_cval;
	lower_32_bits	[label="lower_32_bits()"];
	kvm_arm_timer_read -> lower_32_bits;
	read_timer_ctl	[label="u64 read_timer_ctl (struct arch_timer_context *timer)
arch/arm64/kvm/arch_timer.c:1092"];
	kvm_arm_timer_read -> read_timer_ctl;
	read_timer_ctl -> kvm_timer_compute_delta;
	read_timer_ctl -> timer_get_ctl;
	get_ccsidr	[label="u32 get_ccsidr (struct kvm_vcpu *vcpu, u32 csselr)
arch/arm64/kvm/sys_regs.c:117"];
	get_min_cache_line_size	[label="u8 get_min_cache_line_size (bool icache)
arch/arm64/kvm/sys_regs.c:95"];
	get_ccsidr -> get_min_cache_line_size;
	SYS_FIELD_PREP	[label="SYS_FIELD_PREP()"];
	get_ccsidr -> SYS_FIELD_PREP;
	read_sanitised_ftr_reg	[label="read_sanitised_ftr_reg()"];
	get_min_cache_line_size -> read_sanitised_ftr_reg;
	SYS_FIELD_GET	[label="SYS_FIELD_GET()"];
	get_min_cache_line_size -> SYS_FIELD_GET;
	kvm_has_mte	[label="kvm_has_mte()"];
	cpus_have_final_cap	[label="cpus_have_final_cap()"];
	vcpu_hcr	[label="vcpu_hcr()"];
	vcpu_pc	[label="vcpu_pc()"];
	srcu_read_lock	[label="srcu_read_lock()"];
	write_lock	[label="write_lock()"];
	kvm_memslots	[label="kvm_memslots()"];
	kvm_for_each_memslot	[label="kvm_for_each_memslot()"];
	write_unlock	[label="write_unlock()"];
	srcu_read_unlock	[label="srcu_read_unlock()"];
	IDREG	[label="IDREG()"];
	FIELD_GET	[label="FIELD_GET()"];
	BUG_ON	[label="BUG_ON()"];
	kvm_vcpu_has_pmu	[label="kvm_vcpu_has_pmu()"];
	read_sysreg	[label="read_sysreg()"];
	BIT	[label="BIT()"];
	BIT_ULL	[label="BIT_ULL()"];
	kvm_pmu_event_mask	[label="u32 kvm_pmu_event_mask (struct kvm *kvm)
arch/arm64/kvm/pmu-emul.c:55"];
	kvm_pmu_event_mask -> SYS_FIELD_GET;
	kvm_pmu_event_mask -> IDREG;
	kvm_pmu_valid_counter_mask	[label="u64 kvm_pmu_valid_counter_mask (struct kvm_vcpu *vcpu)
arch/arm64/kvm/pmu-emul.c:268"];
	kvm_pmu_valid_counter_mask -> BIT;
	kvm_vcpu_read_pmcr	[label="u64 kvm_vcpu_read_pmcr (struct kvm_vcpu *vcpu)
arch/arm64/kvm/pmu-emul.c:1137"];
	kvm_pmu_valid_counter_mask -> kvm_vcpu_read_pmcr;
	GENMASK	[label="GENMASK()"];
	kvm_pmu_valid_counter_mask -> GENMASK;
	kvm_pmu_enable_counter_mask	[label="void kvm_pmu_enable_counter_mask (struct kvm_vcpu *vcpu, u64 val)
arch/arm64/kvm/pmu-emul.c:286"];
	kvm_pmu_enable_counter_mask -> kvm_vcpu_has_pmu;
	kvm_pmu_enable_counter_mask -> BIT;
	kvm_pmu_enable_counter_mask -> kvm_vcpu_read_pmcr;
	kvm_vcpu_idx_to_pmc	[label="struct kvm_pmc *kvm_vcpu_idx_to_pmc (struct kvm_vcpu *vcpu, int cnt_idx)
arch/arm64/kvm/pmu-emul.c:34"];
	kvm_pmu_enable_counter_mask -> kvm_vcpu_idx_to_pmc;
	kvm_pmu_create_perf_event	[label="void kvm_pmu_create_perf_event (struct kvm_pmc *pmc)
arch/arm64/kvm/pmu-emul.c:597"];
	kvm_pmu_enable_counter_mask -> kvm_pmu_create_perf_event;
	perf_event_enable	[label="perf_event_enable()"];
	kvm_pmu_enable_counter_mask -> perf_event_enable;
	kvm_debug	[label="kvm_debug()"];
	kvm_pmu_enable_counter_mask -> kvm_debug;
	kvm_vcpu_pmu_restore_guest	[label="void kvm_vcpu_pmu_restore_guest (struct kvm_vcpu *vcpu)
arch/arm64/kvm/pmu.c:176"];
	kvm_vcpu_pmu_restore_guest -> preempt_disable;
	kvm_vcpu_pmu_restore_guest -> preempt_enable;
	kvm_vcpu_pmu_restore_guest -> has_vhe;
	kvm_arm_support_pmu_v3	[label="kvm_arm_support_pmu_v3()"];
	kvm_vcpu_pmu_restore_guest -> kvm_arm_support_pmu_v3;
	kvm_get_pmu_events	[label="struct kvm_pmu_events *kvm_get_pmu_events (void)
arch/arm64/kvm/pmu.c:29"];
	kvm_vcpu_pmu_restore_guest -> kvm_get_pmu_events;
	kvm_vcpu_pmu_enable_el0	[label="void kvm_vcpu_pmu_enable_el0 (unsigned long events)
arch/arm64/kvm/pmu.c:143"];
	kvm_vcpu_pmu_restore_guest -> kvm_vcpu_pmu_enable_el0;
	kvm_vcpu_pmu_disable_el0	[label="void kvm_vcpu_pmu_disable_el0 (unsigned long events)
arch/arm64/kvm/pmu.c:158"];
	kvm_vcpu_pmu_restore_guest -> kvm_vcpu_pmu_disable_el0;
	kvm_pmu_disable_counter_mask	[label="void kvm_pmu_disable_counter_mask (struct kvm_vcpu *vcpu, u64 val)
arch/arm64/kvm/pmu-emul.c:320"];
	kvm_pmu_disable_counter_mask -> kvm_vcpu_has_pmu;
	kvm_pmu_disable_counter_mask -> BIT;
	kvm_pmu_disable_counter_mask -> kvm_vcpu_idx_to_pmc;
	perf_event_disable	[label="perf_event_disable()"];
	kvm_pmu_disable_counter_mask -> perf_event_disable;
	kvm_pmu_create_perf_event -> bool;
	kvm_pmu_create_perf_event -> kvm_pmu_event_mask;
	kvm_pmc_to_vcpu	[label="struct kvm_vcpu *kvm_pmc_to_vcpu (const struct kvm_pmc *pmc)
arch/arm64/kvm/pmu-emul.c:29"];
	kvm_pmu_create_perf_event -> kvm_pmc_to_vcpu;
	counter_index_to_evtreg	[label="u32 counter_index_to_evtreg (u64 idx)
arch/arm64/kvm/pmu-emul.c:109"];
	kvm_pmu_create_perf_event -> counter_index_to_evtreg;
	kvm_pmu_stop_counter	[label="void kvm_pmu_stop_counter (struct kvm_pmc *pmc)
arch/arm64/kvm/pmu-emul.c:209"];
	kvm_pmu_create_perf_event -> kvm_pmu_stop_counter;
	test_bit	[label="test_bit()"];
	kvm_pmu_create_perf_event -> test_bit;
	memset	[label="memset()"];
	kvm_pmu_create_perf_event -> memset;
	kvm_pmu_counter_is_enabled	[label="bool kvm_pmu_counter_is_enabled (struct kvm_pmc *pmc)
arch/arm64/kvm/pmu-emul.c:586"];
	kvm_pmu_create_perf_event -> kvm_pmu_counter_is_enabled;
	kvm_pmc_is_64bit	[label="bool kvm_pmc_is_64bit (struct kvm_pmc *pmc)
arch/arm64/kvm/pmu-emul.c:84"];
	kvm_pmu_create_perf_event -> kvm_pmc_is_64bit;
	compute_period	[label="u64 compute_period (struct kvm_pmc *pmc, u64 counter)
arch/arm64/kvm/pmu-emul.c:482"];
	kvm_pmu_create_perf_event -> compute_period;
	kvm_pmu_get_pmc_value	[label="u64 kvm_pmu_get_pmc_value (struct kvm_pmc *pmc)
arch/arm64/kvm/pmu-emul.c:114"];
	kvm_pmu_create_perf_event -> kvm_pmu_get_pmc_value;
	perf_event_create_kernel_counter	[label="perf_event_create_kernel_counter()"];
	kvm_pmu_create_perf_event -> perf_event_create_kernel_counter;
	kvm_pmu_perf_overflow	[label="void kvm_pmu_perf_overflow (struct perf_event *perf_event, struct perf_sample_data *data, struct pt_regs *regs)
arch/arm64/kvm/pmu-emul.c:\
497"];
	kvm_pmu_create_perf_event -> kvm_pmu_perf_overflow;
	IS_ERR	[label="IS_ERR()"];
	kvm_pmu_create_perf_event -> IS_ERR;
	pr_err_once	[label="pr_err_once()"];
	kvm_pmu_create_perf_event -> pr_err_once;
	PTR_ERR	[label="PTR_ERR()"];
	kvm_pmu_create_perf_event -> PTR_ERR;
	container_of	[label="container_of()"];
	kvm_pmc_to_vcpu -> container_of;
	kvm_pmu_stop_counter -> kvm_pmc_to_vcpu;
	kvm_pmu_stop_counter -> kvm_pmu_get_pmc_value;
	counter_index_to_reg	[label="u32 counter_index_to_reg (u64 idx)
arch/arm64/kvm/pmu-emul.c:104"];
	kvm_pmu_stop_counter -> counter_index_to_reg;
	kvm_pmu_release_perf_event	[label="void kvm_pmu_release_perf_event (struct kvm_pmc *pmc)
arch/arm64/kvm/pmu-emul.c:194"];
	kvm_pmu_stop_counter -> kvm_pmu_release_perf_event;
	kvm_pmu_counter_is_enabled -> BIT;
	kvm_pmu_counter_is_enabled -> kvm_vcpu_read_pmcr;
	kvm_pmu_counter_is_enabled -> kvm_pmc_to_vcpu;
	kvm_pmc_is_64bit -> kvm_pmc_to_vcpu;
	kvm_pmu_is_3p5	[label="kvm_pmu_is_3p5()"];
	kvm_pmc_is_64bit -> kvm_pmu_is_3p5;
	compute_period -> GENMASK;
	compute_period -> kvm_pmc_is_64bit;
	kvm_pmc_has_64bit_overflow	[label="bool kvm_pmc_has_64bit_overflow (struct kvm_pmc *pmc)
arch/arm64/kvm/pmu-emul.c:90"];
	compute_period -> kvm_pmc_has_64bit_overflow;
	kvm_pmu_get_pmc_value -> lower_32_bits;
	kvm_pmu_get_pmc_value -> kvm_pmc_to_vcpu;
	kvm_pmu_get_pmc_value -> kvm_pmc_is_64bit;
	kvm_pmu_get_pmc_value -> counter_index_to_reg;
	perf_event_read_value	[label="perf_event_read_value()"];
	kvm_pmu_get_pmc_value -> perf_event_read_value;
	kvm_pmu_perf_overflow -> BIT;
	kvm_pmu_perf_overflow -> kvm_pmc_to_vcpu;
	kvm_pmu_perf_overflow -> compute_period;
	to_arm_pmu	[label="to_arm_pmu()"];
	kvm_pmu_perf_overflow -> to_arm_pmu;
	local64_read	[label="local64_read()"];
	kvm_pmu_perf_overflow -> local64_read;
	local64_set	[label="local64_set()"];
	kvm_pmu_perf_overflow -> local64_set;
	kvm_pmu_counter_can_chain	[label="bool kvm_pmu_counter_can_chain (struct kvm_pmc *pmc)
arch/arm64/kvm/pmu-emul.c:98"];
	kvm_pmu_perf_overflow -> kvm_pmu_counter_can_chain;
	kvm_pmu_counter_increment	[label="void kvm_pmu_counter_increment (struct kvm_vcpu *vcpu, unsigned long mask, u32 event)
arch/arm64/kvm/pmu-emul.c:441"];
	kvm_pmu_perf_overflow -> kvm_pmu_counter_increment;
	kvm_pmu_overflow_status	[label="u64 kvm_pmu_overflow_status (struct kvm_vcpu *vcpu)
arch/arm64/kvm/pmu-emul.c:340"];
	kvm_pmu_perf_overflow -> kvm_pmu_overflow_status;
	kvm_make_request	[label="kvm_make_request()"];
	kvm_pmu_perf_overflow -> kvm_make_request;
	in_nmi	[label="in_nmi()"];
	kvm_pmu_perf_overflow -> in_nmi;
	kvm_vcpu_kick	[label="void kvm_vcpu_kick (struct kvm_vcpu *vcpu)
virt/kvm/kvm_main.c:3639"];
	kvm_pmu_perf_overflow -> kvm_vcpu_kick;
	irq_work_queue	[label="irq_work_queue()"];
	kvm_pmu_perf_overflow -> irq_work_queue;
	kvm_pmu_release_perf_event -> perf_event_disable;
	perf_event_release_kernel	[label="perf_event_release_kernel()"];
	kvm_pmu_release_perf_event -> perf_event_release_kernel;
	kvm_pmc_has_64bit_overflow -> kvm_vcpu_read_pmcr;
	kvm_pmc_has_64bit_overflow -> kvm_pmc_to_vcpu;
	kvm_pmu_counter_can_chain -> kvm_pmc_has_64bit_overflow;
	kvm_pmu_counter_increment -> lower_32_bits;
	kvm_pmu_counter_increment -> BIT;
	kvm_pmu_counter_increment -> kvm_pmu_event_mask;
	kvm_pmu_counter_increment -> kvm_vcpu_read_pmcr;
	kvm_pmu_counter_increment -> kvm_vcpu_idx_to_pmc;
	kvm_pmu_counter_increment -> counter_index_to_evtreg;
	kvm_pmu_counter_increment -> kvm_pmc_is_64bit;
	kvm_pmu_counter_increment -> counter_index_to_reg;
	kvm_pmu_counter_increment -> kvm_pmc_has_64bit_overflow;
	kvm_pmu_counter_increment -> kvm_pmu_counter_can_chain;
	kvm_pmu_counter_increment -> kvm_pmu_counter_increment;
	for_each_set_bit	[label="for_each_set_bit()"];
	kvm_pmu_counter_increment -> for_each_set_bit;
	kvm_pmu_overflow_status -> kvm_vcpu_read_pmcr;
	kvm_vcpu_wake_up	[label="bool kvm_vcpu_wake_up (struct kvm_vcpu *vcpu)
virt/kvm/kvm_main.c:3623"];
	kvm_vcpu_kick -> kvm_vcpu_wake_up;
	get_cpu	[label="get_cpu()"];
	kvm_vcpu_kick -> get_cpu;
	WRITE_ONCE	[label="WRITE_ONCE()"];
	kvm_vcpu_kick -> WRITE_ONCE;
	kvm_arch_vcpu_should_kick	[label="int kvm_arch_vcpu_should_kick (struct kvm_vcpu *vcpu)
arch/arm64/kvm/arm.c:67"];
	kvm_vcpu_kick -> kvm_arch_vcpu_should_kick;
	READ_ONCE	[label="READ_ONCE()"];
	kvm_vcpu_kick -> READ_ONCE;
	cpu_online	[label="cpu_online()"];
	kvm_vcpu_kick -> cpu_online;
	smp_send_reschedule	[label="smp_send_reschedule()"];
	kvm_vcpu_kick -> smp_send_reschedule;
	put_cpu	[label="put_cpu()"];
	kvm_vcpu_kick -> put_cpu;
	kvm_vcpu_wake_up -> WRITE_ONCE;
	kvm_vcpu_exiting_guest_mode	[label="kvm_vcpu_exiting_guest_mode()"];
	kvm_arch_vcpu_should_kick -> kvm_vcpu_exiting_guest_mode;
	this_cpu_ptr	[label="this_cpu_ptr()"];
	kvm_get_pmu_events -> this_cpu_ptr;
	kvm_vcpu_pmu_enable_el0 -> for_each_set_bit;
	kvm_vcpu_pmu_read_evtype_direct	[label="u64 kvm_vcpu_pmu_read_evtype_direct (int idx)
arch/arm64/kvm/pmu.c:111"];
	kvm_vcpu_pmu_enable_el0 -> kvm_vcpu_pmu_read_evtype_direct;
	kvm_vcpu_pmu_write_evtype_direct	[label="void kvm_vcpu_pmu_write_evtype_direct (int idx, u32 val)
arch/arm64/kvm/pmu.c:128"];
	kvm_vcpu_pmu_enable_el0 -> kvm_vcpu_pmu_write_evtype_direct;
	kvm_vcpu_pmu_disable_el0 -> for_each_set_bit;
	kvm_vcpu_pmu_disable_el0 -> kvm_vcpu_pmu_read_evtype_direct;
	kvm_vcpu_pmu_disable_el0 -> kvm_vcpu_pmu_write_evtype_direct;
	kvm_vcpu_pmu_read_evtype_direct -> WARN_ON;
	kvm_vcpu_pmu_read_evtype_direct -> read_sysreg;
	PMEVTYPER_CASES	[label="PMEVTYPER_CASES()"];
	kvm_vcpu_pmu_read_evtype_direct -> PMEVTYPER_CASES;
	kvm_vcpu_pmu_write_evtype_direct -> WARN_ON;
	kvm_vcpu_pmu_write_evtype_direct -> PMEVTYPER_CASES;
	write_sysreg	[label="write_sysreg()"];
	kvm_vcpu_pmu_write_evtype_direct -> write_sysreg;
	kvm_pmu_handle_pmcr	[label="void kvm_pmu_handle_pmcr (struct kvm_vcpu *vcpu, u64 val)
arch/arm64/kvm/pmu-emul.c:552"];
	kvm_pmu_handle_pmcr -> kvm_vcpu_has_pmu;
	kvm_pmu_handle_pmcr -> BIT;
	kvm_pmu_handle_pmcr -> kvm_pmu_valid_counter_mask;
	kvm_pmu_handle_pmcr -> kvm_pmu_enable_counter_mask;
	kvm_pmu_handle_pmcr -> kvm_vcpu_pmu_restore_guest;
	kvm_pmu_handle_pmcr -> kvm_pmu_disable_counter_mask;
	kvm_pmu_handle_pmcr -> kvm_vcpu_idx_to_pmc;
	kvm_pmu_handle_pmcr -> kvm_pmu_is_3p5;
	kvm_pmu_handle_pmcr -> for_each_set_bit;
	kvm_pmu_set_counter_value	[label="void kvm_pmu_set_counter_value (struct kvm_vcpu *vcpu, u64 select_idx, u64 val)
arch/arm64/kvm/pmu-emul.c:182"];
	kvm_pmu_handle_pmcr -> kvm_pmu_set_counter_value;
	kvm_pmu_set_pmc_value	[label="void kvm_pmu_set_pmc_value (struct kvm_pmc *pmc, u64 val, bool force)
arch/arm64/kvm/pmu-emul.c:149"];
	kvm_pmu_handle_pmcr -> kvm_pmu_set_pmc_value;
	kvm_pmu_set_counter_value -> kvm_vcpu_has_pmu;
	kvm_pmu_set_counter_value -> kvm_vcpu_idx_to_pmc;
	kvm_pmu_set_counter_value -> kvm_pmu_set_pmc_value;
	kvm_pmu_set_pmc_value -> lower_32_bits;
	kvm_pmu_set_pmc_value -> GENMASK;
	kvm_pmu_set_pmc_value -> kvm_pmu_create_perf_event;
	kvm_pmu_set_pmc_value -> kvm_pmc_to_vcpu;
	kvm_pmu_set_pmc_value -> counter_index_to_reg;
	kvm_pmu_set_pmc_value -> kvm_pmu_release_perf_event;
	vcpu_mode_is_32bit	[label="vcpu_mode_is_32bit()"];
	kvm_pmu_set_pmc_value -> vcpu_mode_is_32bit;
	vcpu_el2_e2h_is_set	[label="vcpu_el2_e2h_is_set()"];
	kfree	[label="kfree()"];
	spin_lock	[label="spin_lock()"];
	spin_unlock	[label="spin_unlock()"];
	memcpy	[label="memcpy()"];
	is_protected_kvm_enabled	[label="is_protected_kvm_enabled()"];
	is_kernel_in_hyp_mode	[label="is_kernel_in_hyp_mode()"];
	min	[label="min()"];
	kvm_vm_has_ran_once	[label="kvm_vm_has_ran_once()"];
	mutex_lock	[label="mutex_lock()"];
	mutex_unlock	[label="mutex_unlock()"];
	gfn_to_memslot	[label="struct kvm_memory_slot *gfn_to_memslot (struct kvm *kvm, gfn_t gfn)
virt/kvm/kvm_main.c:2338"];
	gfn_to_memslot -> kvm_memslots;
	kvm_is_error_hva	[label="kvm_is_error_hva()"];
	WARN_ON_ONCE	[label="WARN_ON_ONCE()"];
	gfn_to_hva_many	[label="unsigned long gfn_to_hva_many (struct kvm_memory_slot *slot, gfn_t gfn, gfn_t *nr_pages)
virt/kvm/kvm_main.c:2437"];
	vcpu_get_reg	[label="vcpu_get_reg()"];
	kvm_vcpu_get_esr	[label="kvm_vcpu_get_esr()"];
	kvm_arch_vcpu_put	[label="void kvm_arch_vcpu_put (struct kvm_vcpu *vcpu)
arch/arm64/kvm/arm.c:473"];
	kvm_arch_vcpu_put -> has_vhe;
	kvm_arch_vcpu_put_debug_state_flags	[label="void kvm_arch_vcpu_put_debug_state_flags (struct kvm_vcpu *vcpu)
arch/arm64/kvm/debug.c:340"];
	kvm_arch_vcpu_put -> kvm_arch_vcpu_put_debug_state_flags;
	kvm_arch_vcpu_put_fp	[label="void kvm_arch_vcpu_put_fp (struct kvm_vcpu *vcpu)
arch/arm64/kvm/fpsimd.c:175"];
	kvm_arch_vcpu_put -> kvm_arch_vcpu_put_fp;
	kvm_vcpu_put_vhe	[label="kvm_vcpu_put_vhe()"];
	kvm_arch_vcpu_put -> kvm_vcpu_put_vhe;
	kvm_timer_vcpu_put	[label="void kvm_timer_vcpu_put (struct kvm_vcpu *vcpu)
arch/arm64/kvm/arch_timer.c:878"];
	kvm_arch_vcpu_put -> kvm_timer_vcpu_put;
	kvm_vgic_put	[label="kvm_vgic_put()"];
	kvm_arch_vcpu_put -> kvm_vgic_put;
	kvm_vcpu_pmu_restore_host	[label="void kvm_vcpu_pmu_restore_host (struct kvm_vcpu *vcpu)
arch/arm64/kvm/pmu.c:197"];
	kvm_arch_vcpu_put -> kvm_vcpu_pmu_restore_host;
	kvm_arm_vmid_clear_active	[label="void kvm_arm_vmid_clear_active (void)
arch/arm64/kvm/vmid.c:133"];
	kvm_arch_vcpu_put -> kvm_arm_vmid_clear_active;
	vcpu_clear_on_unsupported_cpu	[label="vcpu_clear_on_unsupported_cpu()"];
	kvm_arch_vcpu_put -> vcpu_clear_on_unsupported_cpu;
	kvm_arch_vcpu_load	[label="void kvm_arch_vcpu_load (struct kvm_vcpu *vcpu, int cpu)
arch/arm64/kvm/arm.c:427"];
	kvm_arch_vcpu_load -> has_vhe;
	kvm_arch_vcpu_load -> kvm_call_hyp;
	kvm_arch_vcpu_load -> kvm_vcpu_pmu_restore_guest;
	kvm_arch_vcpu_load -> kvm_make_request;
	kvm_arch_vcpu_load -> this_cpu_ptr;
	kvm_vgic_load	[label="kvm_vgic_load()"];
	kvm_arch_vcpu_load -> kvm_vgic_load;
	kvm_timer_vcpu_load	[label="void kvm_timer_vcpu_load (struct kvm_vcpu *vcpu)
arch/arm64/kvm/arch_timer.c:827"];
	kvm_arch_vcpu_load -> kvm_timer_vcpu_load;
	kvm_vcpu_load_vhe	[label="kvm_vcpu_load_vhe()"];
	kvm_arch_vcpu_load -> kvm_vcpu_load_vhe;
	kvm_arch_vcpu_load_fp	[label="void kvm_arch_vcpu_load_fp (struct kvm_vcpu *vcpu)
arch/arm64/kvm/fpsimd.c:75"];
	kvm_arch_vcpu_load -> kvm_arch_vcpu_load_fp;
	kvm_arm_is_pvtime_enabled	[label="kvm_arm_is_pvtime_enabled()"];
	kvm_arch_vcpu_load -> kvm_arm_is_pvtime_enabled;
	single_task_running	[label="single_task_running()"];
	kvm_arch_vcpu_load -> single_task_running;
	vcpu_clear_wfx_traps	[label="vcpu_clear_wfx_traps()"];
	kvm_arch_vcpu_load -> vcpu_clear_wfx_traps;
	vcpu_set_wfx_traps	[label="vcpu_set_wfx_traps()"];
	kvm_arch_vcpu_load -> vcpu_set_wfx_traps;
	vcpu_has_ptrauth	[label="vcpu_has_ptrauth()"];
	kvm_arch_vcpu_load -> vcpu_has_ptrauth;
	vcpu_ptrauth_disable	[label="vcpu_ptrauth_disable()"];
	kvm_arch_vcpu_load -> vcpu_ptrauth_disable;
	kvm_arch_vcpu_load_debug_state_flags	[label="void kvm_arch_vcpu_load_debug_state_flags (struct kvm_vcpu *vcpu)
arch/arm64/kvm/debug.c:317"];
	kvm_arch_vcpu_load -> kvm_arch_vcpu_load_debug_state_flags;
	cpumask_test_cpu	[label="cpumask_test_cpu()"];
	kvm_arch_vcpu_load -> cpumask_test_cpu;
	vcpu_set_on_unsupported_cpu	[label="vcpu_set_on_unsupported_cpu()"];
	kvm_arch_vcpu_load -> vcpu_set_on_unsupported_cpu;
	smp_processor_id	[label="smp_processor_id()"];
	vcpu_clear_flag	[label="vcpu_clear_flag()"];
	kvm_arch_vcpu_put_debug_state_flags -> vcpu_clear_flag;
	kvm_arch_vcpu_put_fp -> vcpu_has_sve;
	kvm_arch_vcpu_put_fp -> vcpu_get_flag;
	kvm_arch_vcpu_put_fp -> has_vhe;
	kvm_arch_vcpu_put_fp -> local_irq_save;
	kvm_arch_vcpu_put_fp -> isb;
	kvm_arch_vcpu_put_fp -> local_irq_restore;
	system_supports_sme	[label="system_supports_sme()"];
	kvm_arch_vcpu_put_fp -> system_supports_sme;
	sysreg_clear_set	[label="sysreg_clear_set()"];
	kvm_arch_vcpu_put_fp -> sysreg_clear_set;
	read_sysreg_el1	[label="read_sysreg_el1()"];
	kvm_arch_vcpu_put_fp -> read_sysreg_el1;
	sve_cond_update_zcr_vq	[label="sve_cond_update_zcr_vq()"];
	kvm_arch_vcpu_put_fp -> sve_cond_update_zcr_vq;
	vcpu_sve_max_vq	[label="vcpu_sve_max_vq()"];
	kvm_arch_vcpu_put_fp -> vcpu_sve_max_vq;
	fpsimd_save_and_flush_cpu_state	[label="fpsimd_save_and_flush_cpu_state()"];
	kvm_arch_vcpu_put_fp -> fpsimd_save_and_flush_cpu_state;
	system_supports_sve	[label="system_supports_sve()"];
	kvm_arch_vcpu_put_fp -> system_supports_sve;
	kvm_timer_vcpu_put -> get_timer_map;
	kvm_timer_vcpu_put -> soft_timer_cancel;
	kvm_timer_vcpu_put -> timer_save_state;
	kvm_timer_vcpu_put -> unlikely;
	kvm_timer_vcpu_put -> vcpu_timer;
	kvm_vcpu_is_blocking	[label="kvm_vcpu_is_blocking()"];
	kvm_timer_vcpu_put -> kvm_vcpu_is_blocking;
	kvm_timer_blocking	[label="void kvm_timer_blocking (struct kvm_vcpu *vcpu)
arch/arm64/kvm/arch_timer.c:572"];
	kvm_timer_vcpu_put -> kvm_timer_blocking;
	kvm_vcpu_pmu_restore_host -> has_vhe;
	kvm_vcpu_pmu_restore_host -> kvm_arm_support_pmu_v3;
	kvm_vcpu_pmu_restore_host -> kvm_get_pmu_events;
	kvm_vcpu_pmu_restore_host -> kvm_vcpu_pmu_enable_el0;
	kvm_vcpu_pmu_restore_host -> kvm_vcpu_pmu_disable_el0;
	kvm_arm_vmid_clear_active -> this_cpu_ptr;
	atomic64_set	[label="atomic64_set()"];
	kvm_arm_vmid_clear_active -> atomic64_set;
	kvm_timer_blocking -> get_timer_map;
	kvm_timer_blocking -> kvm_timer_irq_can_fire;
	kvm_timer_blocking -> soft_timer_start;
	kvm_timer_blocking -> vcpu_timer;
	vcpu_has_wfit_active	[label="bool vcpu_has_wfit_active (struct kvm_vcpu *vcpu)
arch/arm64/kvm/arch_timer.c:287"];
	kvm_timer_blocking -> vcpu_has_wfit_active;
	kvm_timer_earliest_exp	[label="u64 kvm_timer_earliest_exp (struct kvm_vcpu *vcpu)
arch/arm64/kvm/arch_timer.c:308"];
	kvm_timer_blocking -> kvm_timer_earliest_exp;
	vcpu_has_wfit_active -> vcpu_get_flag;
	vcpu_has_wfit_active -> cpus_have_final_cap;
	kvm_timer_earliest_exp -> kvm_timer_irq_can_fire;
	kvm_timer_earliest_exp -> kvm_timer_compute_delta;
	kvm_timer_earliest_exp -> min;
	kvm_timer_earliest_exp -> vcpu_has_wfit_active;
	nr_timers	[label="int nr_timers (struct kvm_vcpu *vcpu)
arch/arm64/kvm/arch_timer.c:58"];
	kvm_timer_earliest_exp -> nr_timers;
	WARN	[label="WARN()"];
	kvm_timer_earliest_exp -> WARN;
	wfit_delay_ns	[label="u64 wfit_delay_ns (struct kvm_vcpu *vcpu)
arch/arm64/kvm/arch_timer.c:293"];
	kvm_timer_earliest_exp -> wfit_delay_ns;
	nr_timers -> vcpu_has_nv;
	wfit_delay_ns -> vcpu_has_nv;
	wfit_delay_ns -> is_hyp_ctxt;
	wfit_delay_ns -> vcpu_hvtimer;
	wfit_delay_ns -> vcpu_vtimer;
	wfit_delay_ns -> kvm_counter_compute_delta;
	wfit_delay_ns -> vcpu_get_reg;
	kvm_vcpu_sys_get_rt	[label="kvm_vcpu_sys_get_rt()"];
	wfit_delay_ns -> kvm_vcpu_sys_get_rt;
	kvm_timer_vcpu_load -> vcpu_has_nv;
	kvm_timer_vcpu_load -> get_timer_map;
	kvm_timer_vcpu_load -> timer_emulate;
	kvm_timer_vcpu_load -> timer_restore_state;
	kvm_timer_vcpu_load -> unlikely;
	kvm_timer_vcpu_load -> vcpu_timer;
	static_branch_likely	[label="static_branch_likely()"];
	kvm_timer_vcpu_load -> static_branch_likely;
	kvm_timer_vcpu_load_nested_switch	[label="void kvm_timer_vcpu_load_nested_switch (struct kvm_vcpu *vcpu, struct timer_map *map)
arch/arm64/kvm/arch_timer.c:714"];
	kvm_timer_vcpu_load -> kvm_timer_vcpu_load_nested_switch;
	kvm_timer_vcpu_load_gic	[label="void kvm_timer_vcpu_load_gic (struct arch_timer_context *ctx)
arch/arm64/kvm/arch_timer.c:656"];
	kvm_timer_vcpu_load -> kvm_timer_vcpu_load_gic;
	kvm_timer_vcpu_load_nogic	[label="void kvm_timer_vcpu_load_nogic (struct kvm_vcpu *vcpu)
arch/arm64/kvm/arch_timer.c:677"];
	kvm_timer_vcpu_load -> kvm_timer_vcpu_load_nogic;
	kvm_timer_unblocking	[label="void kvm_timer_unblocking (struct kvm_vcpu *vcpu)
arch/arm64/kvm/arch_timer.c:597"];
	kvm_timer_vcpu_load -> kvm_timer_unblocking;
	timer_set_traps	[label="void timer_set_traps (struct kvm_vcpu *vcpu, struct timer_map *map)
arch/arm64/kvm/arch_timer.c:765"];
	kvm_timer_vcpu_load -> timer_set_traps;
	kvm_arch_vcpu_load_fp -> BUG_ON;
	kvm_arch_vcpu_load_fp -> read_sysreg;
	kvm_arch_vcpu_load_fp -> vcpu_clear_flag;
	kvm_arch_vcpu_load_fp -> system_supports_sme;
	kvm_arch_vcpu_load_fp -> fpsimd_save_and_flush_cpu_state;
	system_supports_fpsimd	[label="system_supports_fpsimd()"];
	kvm_arch_vcpu_load_fp -> system_supports_fpsimd;
	fpsimd_kvm_prepare	[label="fpsimd_kvm_prepare()"];
	kvm_arch_vcpu_load_fp -> fpsimd_kvm_prepare;
	vcpu_set_flag	[label="vcpu_set_flag()"];
	kvm_arch_vcpu_load_fp -> vcpu_set_flag;
	read_sysreg_s	[label="read_sysreg_s()"];
	kvm_arch_vcpu_load_fp -> read_sysreg_s;
	kvm_arch_vcpu_load_debug_state_flags -> has_vhe;
	kvm_arch_vcpu_load_debug_state_flags -> read_sysreg;
	kvm_arch_vcpu_load_debug_state_flags -> BIT;
	kvm_arch_vcpu_load_debug_state_flags -> vcpu_set_flag;
	kvm_arch_vcpu_load_debug_state_flags -> read_sysreg_s;
	cpuid_feature_extract_unsigned_field	[label="cpuid_feature_extract_unsigned_field()"];
	kvm_arch_vcpu_load_debug_state_flags -> cpuid_feature_extract_unsigned_field;
	kvm_timer_vcpu_load_nested_switch -> vcpu_hvtimer;
	kvm_timer_vcpu_load_nested_switch -> timer_irq;
	kvm_timer_vcpu_load_nested_switch -> irqchip_in_kernel;
	kvm_timer_vcpu_load_nested_switch -> vcpu_el2_e2h_is_set;
	kvm_timer_vcpu_load_nested_switch -> WARN_ON_ONCE;
	kvm_vgic_get_map	[label="kvm_vgic_get_map()"];
	kvm_timer_vcpu_load_nested_switch -> kvm_vgic_get_map;
	kvm_vgic_unmap_phys_irq	[label="kvm_vgic_unmap_phys_irq()"];
	kvm_timer_vcpu_load_nested_switch -> kvm_vgic_unmap_phys_irq;
	kvm_vgic_map_phys_irq	[label="kvm_vgic_map_phys_irq()"];
	kvm_timer_vcpu_load_nested_switch -> kvm_vgic_map_phys_irq;
	kvm_timer_vcpu_load_gic -> bool;
	kvm_timer_vcpu_load_gic -> kvm_timer_should_fire;
	kvm_timer_vcpu_load_gic -> kvm_timer_update_irq;
	kvm_timer_vcpu_load_gic -> timer_irq;
	kvm_timer_vcpu_load_gic -> irqchip_in_kernel;
	kvm_vgic_map_is_active	[label="kvm_vgic_map_is_active()"];
	kvm_timer_vcpu_load_gic -> kvm_vgic_map_is_active;
	set_timer_irq_phys_active	[label="inline void set_timer_irq_phys_active (struct arch_timer_context *ctx, bool active)
arch/arm64/kvm/arch_timer.c:649"];
	kvm_timer_vcpu_load_gic -> set_timer_irq_phys_active;
	kvm_timer_vcpu_load_nogic -> vcpu_vtimer;
	kvm_timer_vcpu_load_nogic -> kvm_timer_should_fire;
	kvm_timer_vcpu_load_nogic -> kvm_timer_update_irq;
	disable_percpu_irq	[label="disable_percpu_irq()"];
	kvm_timer_vcpu_load_nogic -> disable_percpu_irq;
	enable_percpu_irq	[label="enable_percpu_irq()"];
	kvm_timer_vcpu_load_nogic -> enable_percpu_irq;
	kvm_timer_unblocking -> soft_timer_cancel;
	kvm_timer_unblocking -> vcpu_timer;
	timer_set_traps -> vcpu_has_nv;
	timer_set_traps -> is_hyp_ctxt;
	timer_set_traps -> has_vhe;
	timer_set_traps -> timer_get_offset;
	timer_set_traps -> bool;
	timer_set_traps -> has_cntpoff;
	timer_set_traps -> vcpu_el2_e2h_is_set;
	timer_set_traps -> sysreg_clear_set;
	assign_clear_set_bit	[label="assign_clear_set_bit()"];
	timer_set_traps -> assign_clear_set_bit;
	set_timer_irq_phys_active -> WARN_ON;
	irq_set_irqchip_state	[label="irq_set_irqchip_state()"];
	set_timer_irq_phys_active -> irq_set_irqchip_state;
	arm64_get_spectre_v2_state	[label="arm64_get_spectre_v2_state()"];
	arm64_get_spectre_v4_state	[label="arm64_get_spectre_v4_state()"];
	arm64_get_spectre_bhb_state	[label="arm64_get_spectre_bhb_state()"];
	ESR_ELx_EC	[label="ESR_ELx_EC()"];
	bitmap_clear	[label="bitmap_clear()"];
	kvm_psci_version	[label="kvm_psci_version()"];
	vcpu_set_reg	[label="vcpu_set_reg()"];
	kvm_for_each_vcpu	[label="kvm_for_each_vcpu()"];
	kvm_vcpu_wfi	[label="void kvm_vcpu_wfi (struct kvm_vcpu *vcpu)
arch/arm64/kvm/arm.c:764"];
	kvm_vcpu_wfi -> preempt_disable;
	kvm_vcpu_wfi -> preempt_enable;
	kvm_vcpu_wfi -> vcpu_clear_flag;
	kvm_vcpu_wfi -> vcpu_set_flag;
	kvm_vgic_vmcr_sync	[label="kvm_vgic_vmcr_sync()"];
	kvm_vcpu_wfi -> kvm_vgic_vmcr_sync;
	vgic_v4_put	[label="vgic_v4_put()"];
	kvm_vcpu_wfi -> vgic_v4_put;
	kvm_vcpu_halt	[label="void kvm_vcpu_halt (struct kvm_vcpu *vcpu)
virt/kvm/kvm_main.c:3550"];
	kvm_vcpu_wfi -> kvm_vcpu_halt;
	vgic_v4_load	[label="vgic_v4_load()"];
	kvm_vcpu_wfi -> vgic_v4_load;
	kvm_vcpu_halt -> ktime_add_ns;
	kvm_vcpu_halt -> ktime_get;
	kvm_vcpu_max_halt_poll_ns	[label="unsigned int kvm_vcpu_max_halt_poll_ns (struct kvm_vcpu *vcpu)
virt/kvm/kvm_main.c:3526"];
	kvm_vcpu_halt -> kvm_vcpu_max_halt_poll_ns;
	kvm_arch_no_poll	[label="kvm_arch_no_poll()"];
	kvm_vcpu_halt -> kvm_arch_no_poll;
	kvm_vcpu_check_block	[label="int kvm_vcpu_check_block (struct kvm_vcpu *vcpu)
virt/kvm/kvm_main.c:3447"];
	kvm_vcpu_halt -> kvm_vcpu_check_block;
	cpu_relax	[label="cpu_relax()"];
	kvm_vcpu_halt -> cpu_relax;
	kvm_vcpu_can_poll	[label="kvm_vcpu_can_poll()"];
	kvm_vcpu_halt -> kvm_vcpu_can_poll;
	kvm_vcpu_block	[label="bool kvm_vcpu_block (struct kvm_vcpu *vcpu)
virt/kvm/kvm_main.c:3472"];
	kvm_vcpu_halt -> kvm_vcpu_block;
	ktime_to_ns	[label="ktime_to_ns()"];
	kvm_vcpu_halt -> ktime_to_ns;
	KVM_STATS_LOG_HIST_UPDATE	[label="KVM_STATS_LOG_HIST_UPDATE()"];
	kvm_vcpu_halt -> KVM_STATS_LOG_HIST_UPDATE;
	update_halt_poll_stats	[label="inline void update_halt_poll_stats (struct kvm_vcpu *vcpu, ktime_t start, ktime_t end, bool success)
virt/kvm/kvm_main.c:3504"];
	kvm_vcpu_halt -> update_halt_poll_stats;
	vcpu_valid_wakeup	[label="vcpu_valid_wakeup()"];
	kvm_vcpu_halt -> vcpu_valid_wakeup;
	shrink_halt_poll_ns	[label="void shrink_halt_poll_ns (struct kvm_vcpu *vcpu)
virt/kvm/kvm_main.c:3428"];
	kvm_vcpu_halt -> shrink_halt_poll_ns;
	grow_halt_poll_ns	[label="void grow_halt_poll_ns (struct kvm_vcpu *vcpu)
virt/kvm/kvm_main.c:3409"];
	kvm_vcpu_halt -> grow_halt_poll_ns;
	trace_kvm_vcpu_wakeup	[label="trace_kvm_vcpu_wakeup()"];
	kvm_vcpu_halt -> trace_kvm_vcpu_wakeup;
	kvm_vcpu_max_halt_poll_ns -> READ_ONCE;
	smp_rmb	[label="smp_rmb()"];
	kvm_vcpu_max_halt_poll_ns -> smp_rmb;
	kvm_vcpu_check_block -> srcu_read_lock;
	kvm_vcpu_check_block -> srcu_read_unlock;
	kvm_arch_vcpu_runnable	[label="int kvm_arch_vcpu_runnable (struct kvm_vcpu *v)
arch/arm64/kvm/arm.c:560"];
	kvm_vcpu_check_block -> kvm_arch_vcpu_runnable;
	kvm_cpu_has_pending_timer	[label="int kvm_cpu_has_pending_timer (struct kvm_vcpu *vcpu)
arch/arm64/kvm/arch_timer.c:423"];
	kvm_vcpu_check_block -> kvm_cpu_has_pending_timer;
	signal_pending	[label="signal_pending()"];
	kvm_vcpu_check_block -> signal_pending;
	kvm_check_request	[label="kvm_check_request()"];
	kvm_vcpu_check_block -> kvm_check_request;
	kvm_vcpu_block -> preempt_disable;
	kvm_vcpu_block -> preempt_enable;
	kvm_vcpu_block -> kvm_vcpu_check_block;
	kvm_arch_vcpu_get_wait	[label="kvm_arch_vcpu_get_wait()"];
	kvm_vcpu_block -> kvm_arch_vcpu_get_wait;
	kvm_arch_vcpu_blocking	[label="void kvm_arch_vcpu_blocking (struct kvm_vcpu *vcpu)
arch/arm64/kvm/arm.c:417"];
	kvm_vcpu_block -> kvm_arch_vcpu_blocking;
	prepare_to_rcuwait	[label="prepare_to_rcuwait()"];
	kvm_vcpu_block -> prepare_to_rcuwait;
	set_current_state	[label="set_current_state()"];
	kvm_vcpu_block -> set_current_state;
	schedule	[label="schedule()"];
	kvm_vcpu_block -> schedule;
	finish_rcuwait	[label="finish_rcuwait()"];
	kvm_vcpu_block -> finish_rcuwait;
	kvm_arch_vcpu_unblocking	[label="void kvm_arch_vcpu_unblocking (struct kvm_vcpu *vcpu)
arch/arm64/kvm/arm.c:422"];
	kvm_vcpu_block -> kvm_arch_vcpu_unblocking;
	update_halt_poll_stats -> ktime_to_ns;
	update_halt_poll_stats -> KVM_STATS_LOG_HIST_UPDATE;
	update_halt_poll_stats -> vcpu_valid_wakeup;
	ktime_sub	[label="ktime_sub()"];
	update_halt_poll_stats -> ktime_sub;
	shrink_halt_poll_ns -> READ_ONCE;
	trace_kvm_halt_poll_ns_shrink	[label="trace_kvm_halt_poll_ns_shrink()"];
	shrink_halt_poll_ns -> trace_kvm_halt_poll_ns_shrink;
	grow_halt_poll_ns -> READ_ONCE;
	trace_kvm_halt_poll_ns_grow	[label="trace_kvm_halt_poll_ns_grow()"];
	grow_halt_poll_ns -> trace_kvm_halt_poll_ns_grow;
	kvm_arch_vcpu_runnable -> bool;
	kvm_arch_vcpu_runnable -> vcpu_hcr;
	kvm_vgic_vcpu_pending_irq	[label="kvm_vgic_vcpu_pending_irq()"];
	kvm_arch_vcpu_runnable -> kvm_vgic_vcpu_pending_irq;
	kvm_arm_vcpu_stopped	[label="bool kvm_arm_vcpu_stopped (struct kvm_vcpu *vcpu)
arch/arm64/kvm/arm.c:502"];
	kvm_arch_vcpu_runnable -> kvm_arm_vcpu_stopped;
	kvm_cpu_has_pending_timer -> vcpu_has_wfit_active;
	kvm_cpu_has_pending_timer -> wfit_delay_ns;
	kvm_arm_vcpu_stopped -> READ_ONCE;
	kvm_mpidr_index	[label="kvm_mpidr_index()"];
	kvm_vcpu_get_mpidr_aff	[label="kvm_vcpu_get_mpidr_aff()"];
	kvm_incr_pc	[label="kvm_incr_pc()"];
	this_cpu_has_cap	[label="this_cpu_has_cap()"];
	kvm_call_hyp_nvhe	[label="kvm_call_hyp_nvhe()"];
	kvm_call_hyp_ret	[label="kvm_call_hyp_ret()"];
	IS_ALIGNED	[label="IS_ALIGNED()"];
	sys_reg_Op0	[label="sys_reg_Op0()"];
	sys_reg_Op1	[label="sys_reg_Op1()"];
	sys_reg_CRn	[label="sys_reg_CRn()"];
	sys_reg_CRm	[label="sys_reg_CRm()"];
	ARRAY_SIZE	[label="ARRAY_SIZE()"];
	find_reg	[label="find_reg()"];
	BUILD_BUG_ON	[label="BUILD_BUG_ON()"];
	sve_max_virtualisable_vl	[label="sve_max_virtualisable_vl()"];
	for_each_possible_cpu	[label="for_each_possible_cpu()"];
	per_cpu	[label="per_cpu()"];
	create_hyp_mappings	[label="int create_hyp_mappings (void *from, void *to, enum kvm_pgtable_prot prot)
arch/arm64/kvm/mmu.c:574"];
	create_hyp_mappings -> is_kernel_in_hyp_mode;
	kern_hyp_va	[label="kern_hyp_va()"];
	create_hyp_mappings -> kern_hyp_va;
	kvm_host_owns_hyp_mappings	[label="bool kvm_host_owns_hyp_mappings (void)
arch/arm64/kvm/mmu.c:383"];
	create_hyp_mappings -> kvm_host_owns_hyp_mappings;
	PAGE_ALIGN	[label="PAGE_ALIGN()"];
	create_hyp_mappings -> PAGE_ALIGN;
	kvm_kaddr_to_phys	[label="phys_addr_t kvm_kaddr_to_phys (void *kaddr)
arch/arm64/kvm/mmu.c:419"];
	create_hyp_mappings -> kvm_kaddr_to_phys;
	ALIGN_DOWN	[label="ALIGN_DOWN()"];
	max	[label="max()"];
	kzalloc	[label="kzalloc()"];
	kvm_host_owns_hyp_mappings -> WARN_ON;
	kvm_host_owns_hyp_mappings -> is_protected_kvm_enabled;
	kvm_host_owns_hyp_mappings -> is_kernel_in_hyp_mode;
	kvm_host_owns_hyp_mappings -> static_branch_likely;
	kvm_kaddr_to_phys -> BUG_ON;
	is_vmalloc_addr	[label="is_vmalloc_addr()"];
	kvm_kaddr_to_phys -> is_vmalloc_addr;
	virt_addr_valid	[label="virt_addr_valid()"];
	kvm_kaddr_to_phys -> virt_addr_valid;
	page_to_phys	[label="page_to_phys()"];
	kvm_kaddr_to_phys -> page_to_phys;
	vmalloc_to_page	[label="vmalloc_to_page()"];
	kvm_kaddr_to_phys -> vmalloc_to_page;
	offset_in_page	[label="offset_in_page()"];
	kvm_kaddr_to_phys -> offset_in_page;
	ARM64_FEATURE_MASK	[label="ARM64_FEATURE_MASK()"];
	offsetof	[label="offsetof()"];
	rcu_access_pointer	[label="rcu_access_pointer()"];
	kvm_unshare_hyp	[label="void kvm_unshare_hyp (void *from, void *to)
arch/arm64/kvm/mmu.c:548"];
	kvm_unshare_hyp -> WARN_ON;
	kvm_unshare_hyp -> is_kernel_in_hyp_mode;
	kvm_unshare_hyp -> ALIGN_DOWN;
	kvm_unshare_hyp -> kvm_host_owns_hyp_mappings;
	kvm_unshare_hyp -> PAGE_ALIGN;
	unshare_pfn_hyp	[label="int unshare_pfn_hyp (u64 pfn)
arch/arm64/kvm/mmu.c:490"];
	kvm_unshare_hyp -> unshare_pfn_hyp;
	put_pid	[label="put_pid()"];
	vcpu_has_run_once	[label="vcpu_has_run_once()"];
	kvm_vcpu_unshare_task_fp	[label="void kvm_vcpu_unshare_task_fp (struct kvm_vcpu *vcpu)
arch/arm64/kvm/fpsimd.c:17"];
	kvm_vcpu_unshare_task_fp -> is_protected_kvm_enabled;
	kvm_vcpu_unshare_task_fp -> kvm_unshare_hyp;
	put_task_struct	[label="put_task_struct()"];
	kvm_vcpu_unshare_task_fp -> put_task_struct;
	vcpu_sve_state_size	[label="vcpu_sve_state_size()"];
	unshare_pfn_hyp -> WARN_ON;
	unshare_pfn_hyp -> kfree;
	unshare_pfn_hyp -> mutex_lock;
	unshare_pfn_hyp -> mutex_unlock;
	unshare_pfn_hyp -> kvm_call_hyp_nvhe;
	find_shared_pfn	[label="struct hyp_shared_pfn *find_shared_pfn (u64 pfn, struct rb_node ***node, struct rb_node **parent)
arch/arm64/kvm/mmu.c:439"];
	unshare_pfn_hyp -> find_shared_pfn;
	rb_erase	[label="rb_erase()"];
	unshare_pfn_hyp -> rb_erase;
	find_shared_pfn -> container_of;
	get_unused_fd_flags	[label="get_unused_fd_flags()"];
	snprintf	[label="snprintf()"];
	anon_inode_getfile	[label="anon_inode_getfile()"];
	fd_install	[label="fd_install()"];
	put_unused_fd	[label="put_unused_fd()"];
	rcu_assign_pointer	[label="rcu_assign_pointer()"];
	kvm_share_hyp	[label="int kvm_share_hyp (void *from, void *to)
arch/arm64/kvm/mmu.c:516"];
	kvm_share_hyp -> is_kernel_in_hyp_mode;
	kvm_share_hyp -> create_hyp_mappings;
	kvm_share_hyp -> ALIGN_DOWN;
	kvm_share_hyp -> kvm_host_owns_hyp_mappings;
	kvm_share_hyp -> PAGE_ALIGN;
	is_vmalloc_or_module_addr	[label="is_vmalloc_or_module_addr()"];
	kvm_share_hyp -> is_vmalloc_or_module_addr;
	share_pfn_hyp	[label="int share_pfn_hyp (u64 pfn)
arch/arm64/kvm/mmu.c:460"];
	kvm_share_hyp -> share_pfn_hyp;
	cpumask_copy	[label="cpumask_copy()"];
	bitmap_zero	[label="bitmap_zero()"];
	share_pfn_hyp -> mutex_lock;
	share_pfn_hyp -> mutex_unlock;
	share_pfn_hyp -> kvm_call_hyp_nvhe;
	share_pfn_hyp -> kzalloc;
	share_pfn_hyp -> find_shared_pfn;
	rb_link_node	[label="rb_link_node()"];
	share_pfn_hyp -> rb_link_node;
	rb_insert_color	[label="rb_insert_color()"];
	share_pfn_hyp -> rb_insert_color;
	atomic_read	[label="atomic_read()"];
	kvm_arm_pvtime_supported	[label="bool kvm_arm_pvtime_supported (void)
arch/arm64/kvm/pvtime.c:70"];
	sched_info_on	[label="sched_info_on()"];
	kvm_arm_pvtime_supported -> sched_info_on;
	get_num_brps	[label="get_num_brps()"];
	get_num_wrps	[label="get_num_wrps()"];
	system_has_full_ptr_auth	[label="system_has_full_ptr_auth()"];
	copy_from_user	[label="copy_from_user()"];
	copy_to_user	[label="copy_to_user()"];
	lockdep_assert_held	[label="lockdep_assert_held()"];
	kvm_pr_unimpl	[label="kvm_pr_unimpl()"];
	sysreg_hidden	[label="sysreg_hidden()"];
	kvm_vcpu_trap_get_class	[label="kvm_vcpu_trap_get_class()"];
	kvm_inject_vabt	[label="void kvm_inject_vabt (struct kvm_vcpu *vcpu)
arch/arm64/kvm/inject_fault.c:251"];
	kvm_set_sei_esr	[label="void kvm_set_sei_esr (struct kvm_vcpu *vcpu, u64 esr)
arch/arm64/kvm/inject_fault.c:233"];
	kvm_inject_vabt -> kvm_set_sei_esr;
	kvm_set_sei_esr -> vcpu_hcr;
	vcpu_set_vsesr	[label="vcpu_set_vsesr()"];
	kvm_set_sei_esr -> vcpu_set_vsesr;
	kvm_vcpu_dabt_iswrite	[label="kvm_vcpu_dabt_iswrite()"];
	kvm_vcpu_dabt_get_as	[label="kvm_vcpu_dabt_get_as()"];
	kvm_vcpu_dabt_get_rd	[label="kvm_vcpu_dabt_get_rd()"];
	trace_kvm_mmio	[label="trace_kvm_mmio()"];
	kvm_handle_mmio_return	[label="int kvm_handle_mmio_return (struct kvm_vcpu *vcpu)
arch/arm64/kvm/mmio.c:81"];
	kvm_handle_mmio_return -> unlikely;
	kvm_handle_mmio_return -> vcpu_set_reg;
	kvm_handle_mmio_return -> kvm_incr_pc;
	kvm_handle_mmio_return -> kvm_vcpu_dabt_iswrite;
	kvm_handle_mmio_return -> kvm_vcpu_dabt_get_as;
	kvm_handle_mmio_return -> kvm_vcpu_dabt_get_rd;
	kvm_handle_mmio_return -> trace_kvm_mmio;
	kvm_mmio_read_buf	[label="unsigned long kvm_mmio_read_buf (const void *buf, unsigned int len)
arch/arm64/kvm/mmio.c:45"];
	kvm_handle_mmio_return -> kvm_mmio_read_buf;
	kvm_vcpu_dabt_issext	[label="kvm_vcpu_dabt_issext()"];
	kvm_handle_mmio_return -> kvm_vcpu_dabt_issext;
	kvm_vcpu_dabt_issf	[label="kvm_vcpu_dabt_issf()"];
	kvm_handle_mmio_return -> kvm_vcpu_dabt_issf;
	vcpu_data_host_to_guest	[label="vcpu_data_host_to_guest()"];
	kvm_handle_mmio_return -> vcpu_data_host_to_guest;
	kvm_mmio_read_buf -> memcpy;
	mmap_read_lock	[label="mmap_read_lock()"];
	mmap_read_unlock	[label="mmap_read_unlock()"];
	kvm_dirty_ring_soft_full	[label="bool kvm_dirty_ring_soft_full (struct kvm_dirty_ring *ring)
virt/kvm/dirty_ring.c:43"];
	kvm_dirty_ring_used	[label="u32 kvm_dirty_ring_used (struct kvm_dirty_ring *ring)
virt/kvm/dirty_ring.c:38"];
	kvm_dirty_ring_soft_full -> kvm_dirty_ring_used;
	kvm_dirty_ring_used -> READ_ONCE;
	kvm_arm_timer_get_reg	[label="u64 kvm_arm_timer_get_reg (struct kvm_vcpu *vcpu, u64 regid)
arch/arm64/kvm/arch_timer.c:1108"];
	kvm_arm_timer_get_reg -> vcpu_vtimer;
	kvm_arm_timer_get_reg -> vcpu_ptimer;
	kvm_arm_timer_get_reg -> kvm_arm_timer_read;
	kvm_arm_pmu_get_pmuver_limit	[label="u8 kvm_arm_pmu_get_pmuver_limit (void)
arch/arm64/kvm/pmu-emul.c:1122"];
	kvm_arm_pmu_get_pmuver_limit -> read_sanitised_ftr_reg;
	kvm_arm_pmu_get_pmuver_limit -> FIELD_GET;
	kvm_arm_pmu_get_pmuver_limit -> ARM64_FEATURE_MASK;
	cpuid_feature_cap_perfmon_field	[label="cpuid_feature_cap_perfmon_field()"];
	kvm_arm_pmu_get_pmuver_limit -> cpuid_feature_cap_perfmon_field;
	list_for_each_entry	[label="list_for_each_entry()"];
	kvm_get_kvm	[label="void kvm_get_kvm (struct kvm *kvm)
virt/kvm/kvm_main.c:1347"];
	refcount_inc	[label="refcount_inc()"];
	kvm_get_kvm -> refcount_inc;
	kvm_vcpu_compat_ioctl	[label="long kvm_vcpu_compat_ioctl (struct file *filp, unsigned int ioctl, unsigned long arg)
virt/kvm/kvm_main.c:4321"];
	kvm_vcpu_compat_ioctl -> copy_from_user;
	compat_ptr	[label="compat_ptr()"];
	kvm_vcpu_compat_ioctl -> compat_ptr;
	get_compat_sigset	[label="get_compat_sigset()"];
	kvm_vcpu_compat_ioctl -> get_compat_sigset;
	kvm_vcpu_ioctl_set_sigmask	[label="int kvm_vcpu_ioctl_set_sigmask (struct kvm_vcpu *vcpu, sigset_t *sigset)
virt/kvm/kvm_main.c:4047"];
	kvm_vcpu_compat_ioctl -> kvm_vcpu_ioctl_set_sigmask;
	kvm_vcpu_ioctl	[label="long kvm_vcpu_ioctl (struct file *filp, unsigned int ioctl, unsigned long arg)
virt/kvm/kvm_main.c:4109"];
	kvm_vcpu_compat_ioctl -> kvm_vcpu_ioctl;
	sigdelsetmask	[label="sigdelsetmask()"];
	kvm_vcpu_ioctl_set_sigmask -> sigdelsetmask;
	sigmask	[label="sigmask()"];
	kvm_vcpu_ioctl_set_sigmask -> sigmask;
	kvm_vcpu_ioctl -> unlikely;
	kvm_vcpu_ioctl -> IS_ERR;
	kvm_vcpu_ioctl -> PTR_ERR;
	kvm_vcpu_ioctl -> kfree;
	kvm_vcpu_ioctl -> mutex_unlock;
	kvm_vcpu_ioctl -> kzalloc;
	kvm_vcpu_ioctl -> rcu_access_pointer;
	kvm_vcpu_ioctl -> put_pid;
	kvm_vcpu_ioctl -> rcu_assign_pointer;
	kvm_vcpu_ioctl -> copy_from_user;
	kvm_vcpu_ioctl -> copy_to_user;
	kvm_vcpu_ioctl -> kvm_vcpu_ioctl_set_sigmask;
	kvm_arch_vcpu_async_ioctl	[label="kvm_arch_vcpu_async_ioctl()"];
	kvm_vcpu_ioctl -> kvm_arch_vcpu_async_ioctl;
	mutex_lock_killable	[label="mutex_lock_killable()"];
	kvm_vcpu_ioctl -> mutex_lock_killable;
	task_pid	[label="task_pid()"];
	kvm_vcpu_ioctl -> task_pid;
	kvm_arch_vcpu_run_pid_change	[label="int kvm_arch_vcpu_run_pid_change (struct kvm_vcpu *vcpu)
arch/arm64/kvm/arm.c:640"];
	kvm_vcpu_ioctl -> kvm_arch_vcpu_run_pid_change;
	get_task_pid	[label="get_task_pid()"];
	kvm_vcpu_ioctl -> get_task_pid;
	synchronize_rcu	[label="synchronize_rcu()"];
	kvm_vcpu_ioctl -> synchronize_rcu;
	kvm_arch_vcpu_ioctl_run	[label="int kvm_arch_vcpu_ioctl_run (struct kvm_vcpu *vcpu)
arch/arm64/kvm/arm.c:960"];
	kvm_vcpu_ioctl -> kvm_arch_vcpu_ioctl_run;
	trace_kvm_userspace_exit	[label="trace_kvm_userspace_exit()"];
	kvm_vcpu_ioctl -> trace_kvm_userspace_exit;
	kvm_arch_vcpu_ioctl_get_regs	[label="int kvm_arch_vcpu_ioctl_get_regs (struct kvm_vcpu *vcpu, struct kvm_regs *regs)
arch/arm64/kvm/guest.c:535"];
	kvm_vcpu_ioctl -> kvm_arch_vcpu_ioctl_get_regs;
	memdup_user	[label="memdup_user()"];
	kvm_vcpu_ioctl -> memdup_user;
	kvm_arch_vcpu_ioctl_set_regs	[label="int kvm_arch_vcpu_ioctl_set_regs (struct kvm_vcpu *vcpu, struct kvm_regs *regs)
arch/arm64/kvm/guest.c:540"];
	kvm_vcpu_ioctl -> kvm_arch_vcpu_ioctl_set_regs;
	kvm_arch_vcpu_ioctl_get_sregs	[label="int kvm_arch_vcpu_ioctl_get_sregs (struct kvm_vcpu *vcpu, struct kvm_sregs *sregs)
arch/arm64/kvm/guest.c:802"];
	kvm_vcpu_ioctl -> kvm_arch_vcpu_ioctl_get_sregs;
	kvm_arch_vcpu_ioctl_set_sregs	[label="int kvm_arch_vcpu_ioctl_set_sregs (struct kvm_vcpu *vcpu, struct kvm_sregs *sregs)
arch/arm64/kvm/guest.c:808"];
	kvm_vcpu_ioctl -> kvm_arch_vcpu_ioctl_set_sregs;
	kvm_arch_vcpu_ioctl_get_mpstate	[label="int kvm_arch_vcpu_ioctl_get_mpstate (struct kvm_vcpu *vcpu, struct kvm_mp_state *mp_state)
arch/arm64/kvm/arm.c:519"];
	kvm_vcpu_ioctl -> kvm_arch_vcpu_ioctl_get_mpstate;
	kvm_arch_vcpu_ioctl_set_mpstate	[label="int kvm_arch_vcpu_ioctl_set_mpstate (struct kvm_vcpu *vcpu, struct kvm_mp_state *mp_state)
arch/arm64/kvm/arm.c:527"];
	kvm_vcpu_ioctl -> kvm_arch_vcpu_ioctl_set_mpstate;
	kvm_arch_vcpu_ioctl_translate	[label="int kvm_arch_vcpu_ioctl_translate (struct kvm_vcpu *vcpu, struct kvm_translation *tr)
arch/arm64/kvm/guest.c:897"];
	kvm_vcpu_ioctl -> kvm_arch_vcpu_ioctl_translate;
	kvm_arch_vcpu_ioctl_set_guest_debug	[label="int kvm_arch_vcpu_ioctl_set_guest_debug (struct kvm_vcpu *vcpu, struct kvm_guest_debug *dbg)
arch/arm64/kvm/guest.c:913"];
	kvm_vcpu_ioctl -> kvm_arch_vcpu_ioctl_set_guest_debug;
	kvm_arch_vcpu_ioctl_get_fpu	[label="int kvm_arch_vcpu_ioctl_get_fpu (struct kvm_vcpu *vcpu, struct kvm_fpu *fpu)
arch/arm64/kvm/guest.c:887"];
	kvm_vcpu_ioctl -> kvm_arch_vcpu_ioctl_get_fpu;
	kvm_arch_vcpu_ioctl_set_fpu	[label="int kvm_arch_vcpu_ioctl_set_fpu (struct kvm_vcpu *vcpu, struct kvm_fpu *fpu)
arch/arm64/kvm/guest.c:892"];
	kvm_vcpu_ioctl -> kvm_arch_vcpu_ioctl_set_fpu;
	kvm_vcpu_ioctl_get_stats_fd	[label="int kvm_vcpu_ioctl_get_stats_fd (struct kvm_vcpu *vcpu)
virt/kvm/kvm_main.c:4083"];
	kvm_vcpu_ioctl -> kvm_vcpu_ioctl_get_stats_fd;
	kvm_arch_vcpu_ioctl	[label="long kvm_arch_vcpu_ioctl (struct file *filp, unsigned int ioctl, unsigned long arg)
arch/arm64/kvm/arm.c:1511"];
	kvm_vcpu_ioctl -> kvm_arch_vcpu_ioctl;
	kvm_arch_vcpu_run_pid_change -> likely;
	kvm_arch_vcpu_run_pid_change -> irqchip_in_kernel;
	kvm_arch_vcpu_run_pid_change -> is_protected_kvm_enabled;
	kvm_arch_vcpu_run_pid_change -> mutex_lock;
	kvm_arch_vcpu_run_pid_change -> mutex_unlock;
	kvm_arch_vcpu_run_pid_change -> kvm_call_hyp_nvhe;
	kvm_arch_vcpu_run_pid_change -> vcpu_has_run_once;
	kvm_vcpu_initialized	[label="int kvm_vcpu_initialized (struct kvm_vcpu *vcpu)
arch/arm64/kvm/arm.c:579"];
	kvm_arch_vcpu_run_pid_change -> kvm_vcpu_initialized;
	kvm_arm_vcpu_is_finalized	[label="bool kvm_arm_vcpu_is_finalized (struct kvm_vcpu *vcpu)
arch/arm64/kvm/reset.c:142"];
	kvm_arch_vcpu_run_pid_change -> kvm_arm_vcpu_is_finalized;
	kvm_arch_vcpu_run_map_fp	[label="int kvm_arch_vcpu_run_map_fp (struct kvm_vcpu *vcpu)
arch/arm64/kvm/fpsimd.c:39"];
	kvm_arch_vcpu_run_pid_change -> kvm_arch_vcpu_run_map_fp;
	kvm_init_mpidr_data	[label="void kvm_init_mpidr_data (struct kvm *kvm)
arch/arm64/kvm/arm.c:584"];
	kvm_arch_vcpu_run_pid_change -> kvm_init_mpidr_data;
	kvm_arm_vcpu_init_debug	[label="void kvm_arm_vcpu_init_debug (struct kvm_vcpu *vcpu)
arch/arm64/kvm/debug.c:137"];
	kvm_arch_vcpu_run_pid_change -> kvm_arm_vcpu_init_debug;
	kvm_vgic_map_resources	[label="kvm_vgic_map_resources()"];
	kvm_arch_vcpu_run_pid_change -> kvm_vgic_map_resources;
	kvm_timer_enable	[label="int kvm_timer_enable (struct kvm_vcpu *vcpu)
arch/arm64/kvm/arch_timer.c:1507"];
	kvm_arch_vcpu_run_pid_change -> kvm_timer_enable;
	kvm_arm_pmu_v3_enable	[label="int kvm_arm_pmu_v3_enable (struct kvm_vcpu *vcpu)
arch/arm64/kvm/pmu-emul.c:817"];
	kvm_arch_vcpu_run_pid_change -> kvm_arm_pmu_v3_enable;
	pkvm_create_hyp_vm	[label="int pkvm_create_hyp_vm (struct kvm *host_kvm)
arch/arm64/kvm/pkvm.c:204"];
	kvm_arch_vcpu_run_pid_change -> pkvm_create_hyp_vm;
	static_branch_inc	[label="static_branch_inc()"];
	kvm_arch_vcpu_run_pid_change -> static_branch_inc;
	kvm_vm_is_protected	[label="kvm_vm_is_protected()"];
	kvm_arch_vcpu_run_pid_change -> kvm_vm_is_protected;
	set_bit	[label="set_bit()"];
	kvm_arch_vcpu_run_pid_change -> set_bit;
	kvm_arch_vcpu_ioctl_run -> vcpu_get_flag;
	kvm_arch_vcpu_ioctl_run -> preempt_disable;
	kvm_arch_vcpu_ioctl_run -> preempt_enable;
	kvm_arch_vcpu_ioctl_run -> has_vhe;
	kvm_arch_vcpu_ioctl_run -> static_branch_unlikely;
	kvm_arch_vcpu_ioctl_run -> unlikely;
	kvm_arch_vcpu_ioctl_run -> irqchip_in_kernel;
	kvm_arch_vcpu_ioctl_run -> isb;
	kvm_arch_vcpu_ioctl_run -> kvm_call_hyp;
	kvm_arch_vcpu_ioctl_run -> vcpu_pc;
	kvm_arch_vcpu_ioctl_run -> vcpu_clear_flag;
	kvm_arch_vcpu_ioctl_run -> kvm_vcpu_trap_get_class;
	kvm_arch_vcpu_ioctl_run -> kvm_handle_mmio_return;
	vcpu_load	[label="void vcpu_load (struct kvm_vcpu *vcpu)
virt/kvm/kvm_main.c:208"];
	kvm_arch_vcpu_ioctl_run -> vcpu_load;
	kvm_sigset_activate	[label="void kvm_sigset_activate (struct kvm_vcpu *vcpu)
virt/kvm/kvm_main.c:3386"];
	kvm_arch_vcpu_ioctl_run -> kvm_sigset_activate;
	xfer_to_guest_mode_handle_work	[label="xfer_to_guest_mode_handle_work()"];
	kvm_arch_vcpu_ioctl_run -> xfer_to_guest_mode_handle_work;
	check_vcpu_requests	[label="int check_vcpu_requests (struct kvm_vcpu *vcpu)
arch/arm64/kvm/arm.c:833"];
	kvm_arch_vcpu_ioctl_run -> check_vcpu_requests;
	kvm_arm_vmid_update	[label="bool kvm_arm_vmid_update (struct kvm_vmid *kvm_vmid)
arch/arm64/kvm/vmid.c:138"];
	kvm_arch_vcpu_ioctl_run -> kvm_arm_vmid_update;
	kvm_pmu_flush_hwstate	[label="void kvm_pmu_flush_hwstate (struct kvm_vcpu *vcpu)
arch/arm64/kvm/pmu-emul.c:406"];
	kvm_arch_vcpu_ioctl_run -> kvm_pmu_flush_hwstate;
	local_irq_disable	[label="local_irq_disable()"];
	kvm_arch_vcpu_ioctl_run -> local_irq_disable;
	kvm_vgic_flush_hwstate	[label="kvm_vgic_flush_hwstate()"];
	kvm_arch_vcpu_ioctl_run -> kvm_vgic_flush_hwstate;
	kvm_pmu_update_vcpu_events	[label="kvm_pmu_update_vcpu_events()"];
	kvm_arch_vcpu_ioctl_run -> kvm_pmu_update_vcpu_events;
	smp_store_mb	[label="smp_store_mb()"];
	kvm_arch_vcpu_ioctl_run -> smp_store_mb;
	kvm_vcpu_exit_request	[label="bool kvm_vcpu_exit_request (struct kvm_vcpu *vcpu, int *ret)
arch/arm64/kvm/arm.c:900"];
	kvm_arch_vcpu_ioctl_run -> kvm_vcpu_exit_request;
	kvm_pmu_sync_hwstate	[label="void kvm_pmu_sync_hwstate (struct kvm_vcpu *vcpu)
arch/arm64/kvm/pmu-emul.c:418"];
	kvm_arch_vcpu_ioctl_run -> kvm_pmu_sync_hwstate;
	kvm_timer_sync_user	[label="void kvm_timer_sync_user (struct kvm_vcpu *vcpu)
arch/arm64/kvm/arch_timer.c:928"];
	kvm_arch_vcpu_ioctl_run -> kvm_timer_sync_user;
	kvm_vgic_sync_hwstate	[label="kvm_vgic_sync_hwstate()"];
	kvm_arch_vcpu_ioctl_run -> kvm_vgic_sync_hwstate;
	local_irq_enable	[label="local_irq_enable()"];
	kvm_arch_vcpu_ioctl_run -> local_irq_enable;
	kvm_arm_setup_debug	[label="void kvm_arm_setup_debug (struct kvm_vcpu *vcpu)
arch/arm64/kvm/debug.c:169"];
	kvm_arch_vcpu_ioctl_run -> kvm_arm_setup_debug;
	kvm_arch_vcpu_ctxflush_fp	[label="void kvm_arch_vcpu_ctxflush_fp (struct kvm_vcpu *vcpu)
arch/arm64/kvm/fpsimd.c:126"];
	kvm_arch_vcpu_ioctl_run -> kvm_arch_vcpu_ctxflush_fp;
	trace_kvm_entry	[label="trace_kvm_entry()"];
	kvm_arch_vcpu_ioctl_run -> trace_kvm_entry;
	guest_timing_enter_irqoff	[label="guest_timing_enter_irqoff()"];
	kvm_arch_vcpu_ioctl_run -> guest_timing_enter_irqoff;
	kvm_arm_vcpu_enter_exit	[label="int noinstr kvm_arm_vcpu_enter_exit (struct kvm_vcpu *vcpu)
arch/arm64/kvm/arm.c:939"];
	kvm_arch_vcpu_ioctl_run -> kvm_arm_vcpu_enter_exit;
	kvm_arm_clear_debug	[label="void kvm_arm_clear_debug (struct kvm_vcpu *vcpu)
arch/arm64/kvm/debug.c:280"];
	kvm_arch_vcpu_ioctl_run -> kvm_arm_clear_debug;
	kvm_arch_vcpu_ctxsync_fp	[label="void kvm_arch_vcpu_ctxsync_fp (struct kvm_vcpu *vcpu)
arch/arm64/kvm/fpsimd.c:139"];
	kvm_arch_vcpu_ioctl_run -> kvm_arch_vcpu_ctxsync_fp;
	ARM_EXCEPTION_CODE	[label="ARM_EXCEPTION_CODE()"];
	kvm_arch_vcpu_ioctl_run -> ARM_EXCEPTION_CODE;
	guest_timing_exit_irqoff	[label="guest_timing_exit_irqoff()"];
	kvm_arch_vcpu_ioctl_run -> guest_timing_exit_irqoff;
	trace_kvm_exit	[label="trace_kvm_exit()"];
	kvm_arch_vcpu_ioctl_run -> trace_kvm_exit;
	handle_exit_early	[label="void handle_exit_early (struct kvm_vcpu *vcpu, int exception_index)
arch/arm64/kvm/handle_exit.c:366"];
	kvm_arch_vcpu_ioctl_run -> handle_exit_early;
	vcpu_mode_is_bad_32bit	[label="bool vcpu_mode_is_bad_32bit (struct kvm_vcpu *vcpu)
arch/arm64/kvm/arm.c:875"];
	kvm_arch_vcpu_ioctl_run -> vcpu_mode_is_bad_32bit;
	handle_exit	[label="int handle_exit (struct kvm_vcpu *vcpu, int exception_index)
arch/arm64/kvm/handle_exit.c:322"];
	kvm_arch_vcpu_ioctl_run -> handle_exit;
	kvm_timer_update_run	[label="void kvm_timer_update_run (struct kvm_vcpu *vcpu)
arch/arm64/kvm/arch_timer.c:431"];
	kvm_arch_vcpu_ioctl_run -> kvm_timer_update_run;
	kvm_pmu_update_run	[label="void kvm_pmu_update_run (struct kvm_vcpu *vcpu)
arch/arm64/kvm/pmu-emul.c:389"];
	kvm_arch_vcpu_ioctl_run -> kvm_pmu_update_run;
	kvm_sigset_deactivate	[label="void kvm_sigset_deactivate (struct kvm_vcpu *vcpu)
virt/kvm/kvm_main.c:3400"];
	kvm_arch_vcpu_ioctl_run -> kvm_sigset_deactivate;
	vcpu_put	[label="void vcpu_put (struct kvm_vcpu *vcpu)
virt/kvm/kvm_main.c:219"];
	kvm_arch_vcpu_ioctl_run -> vcpu_put;
	kvm_arch_vcpu_ioctl_get_mpstate -> READ_ONCE;
	kvm_arch_vcpu_ioctl_set_mpstate -> WRITE_ONCE;
	kvm_arch_vcpu_ioctl_set_mpstate -> spin_lock;
	kvm_arch_vcpu_ioctl_set_mpstate -> spin_unlock;
	kvm_arm_vcpu_suspend	[label="void kvm_arm_vcpu_suspend (struct kvm_vcpu *vcpu)
arch/arm64/kvm/arm.c:507"];
	kvm_arch_vcpu_ioctl_set_mpstate -> kvm_arm_vcpu_suspend;
	kvm_arch_vcpu_ioctl_set_guest_debug -> vcpu_clear_flag;
	trace_kvm_set_guest_debug	[label="trace_kvm_set_guest_debug()"];
	kvm_arch_vcpu_ioctl_set_guest_debug -> trace_kvm_set_guest_debug;
	kvm_vcpu_ioctl_get_stats_fd -> IS_ERR;
	kvm_vcpu_ioctl_get_stats_fd -> PTR_ERR;
	kvm_vcpu_ioctl_get_stats_fd -> get_unused_fd_flags;
	kvm_vcpu_ioctl_get_stats_fd -> snprintf;
	kvm_vcpu_ioctl_get_stats_fd -> anon_inode_getfile;
	kvm_vcpu_ioctl_get_stats_fd -> fd_install;
	kvm_vcpu_ioctl_get_stats_fd -> put_unused_fd;
	kvm_vcpu_ioctl_get_stats_fd -> kvm_get_kvm;
	kvm_arch_vcpu_ioctl -> unlikely;
	kvm_arch_vcpu_ioctl -> kvm_check_request;
	kvm_arch_vcpu_ioctl -> copy_from_user;
	kvm_arch_vcpu_ioctl -> copy_to_user;
	kvm_arch_vcpu_ioctl -> kvm_vcpu_initialized;
	kvm_arch_vcpu_ioctl -> kvm_arm_vcpu_is_finalized;
	kvm_reset_vcpu	[label="void kvm_reset_vcpu (struct kvm_vcpu *vcpu)
arch/arm64/kvm/reset.c:191"];
	kvm_arch_vcpu_ioctl -> kvm_reset_vcpu;
	kvm_arch_vcpu_ioctl_vcpu_init	[label="int kvm_arch_vcpu_ioctl_vcpu_init (struct kvm_vcpu *vcpu, struct kvm_vcpu_init *init)
arch/arm64/kvm/arm.c:1389"];
	kvm_arch_vcpu_ioctl -> kvm_arch_vcpu_ioctl_vcpu_init;
	kvm_arm_set_reg	[label="int kvm_arm_set_reg (struct kvm_vcpu *vcpu, const struct kvm_one_reg *reg)
arch/arm64/kvm/guest.c:782"];
	kvm_arch_vcpu_ioctl -> kvm_arm_set_reg;
	kvm_arm_get_reg	[label="int kvm_arm_get_reg (struct kvm_vcpu *vcpu, const struct kvm_one_reg *reg)
arch/arm64/kvm/guest.c:762"];
	kvm_arch_vcpu_ioctl -> kvm_arm_get_reg;
	kvm_arm_num_regs	[label="unsigned long kvm_arm_num_regs (struct kvm_vcpu *vcpu)
arch/arm64/kvm/guest.c:717"];
	kvm_arch_vcpu_ioctl -> kvm_arm_num_regs;
	kvm_arm_copy_reg_indices	[label="int kvm_arm_copy_reg_indices (struct kvm_vcpu *vcpu, u64 __user *uindices)
arch/arm64/kvm/guest.c:735"];
	kvm_arch_vcpu_ioctl -> kvm_arm_copy_reg_indices;
	kvm_arm_vcpu_set_attr	[label="int kvm_arm_vcpu_set_attr (struct kvm_vcpu *vcpu, struct kvm_device_attr *attr)
arch/arm64/kvm/arm.c:1443"];
	kvm_arch_vcpu_ioctl -> kvm_arm_vcpu_set_attr;
	kvm_arm_vcpu_get_attr	[label="int kvm_arm_vcpu_get_attr (struct kvm_vcpu *vcpu, struct kvm_device_attr *attr)
arch/arm64/kvm/arm.c:1457"];
	kvm_arch_vcpu_ioctl -> kvm_arm_vcpu_get_attr;
	kvm_arm_vcpu_has_attr	[label="int kvm_arm_vcpu_has_attr (struct kvm_vcpu *vcpu, struct kvm_device_attr *attr)
arch/arm64/kvm/arm.c:1471"];
	kvm_arch_vcpu_ioctl -> kvm_arm_vcpu_has_attr;
	kvm_arm_vcpu_get_events	[label="int kvm_arm_vcpu_get_events (struct kvm_vcpu *vcpu, struct kvm_vcpu_events *events)
arch/arm64/kvm/arm.c:1485"];
	kvm_arch_vcpu_ioctl -> kvm_arm_vcpu_get_events;
	kvm_arm_vcpu_set_events	[label="int kvm_arm_vcpu_set_events (struct kvm_vcpu *vcpu, struct kvm_vcpu_events *events)
arch/arm64/kvm/arm.c:1493"];
	kvm_arch_vcpu_ioctl -> kvm_arm_vcpu_set_events;
	get_user	[label="get_user()"];
	kvm_arch_vcpu_ioctl -> get_user;
	kvm_arm_vcpu_finalize	[label="int kvm_arm_vcpu_finalize (struct kvm_vcpu *vcpu, int feature)
arch/arm64/kvm/reset.c:126"];
	kvm_arch_vcpu_ioctl -> kvm_arm_vcpu_finalize;
	kvm_vcpu_initialized -> vcpu_get_flag;
	kvm_arm_vcpu_is_finalized -> vcpu_has_sve;
	kvm_arm_vcpu_sve_finalized	[label="kvm_arm_vcpu_sve_finalized()"];
	kvm_arm_vcpu_is_finalized -> kvm_arm_vcpu_sve_finalized;
	kvm_arch_vcpu_run_map_fp -> is_protected_kvm_enabled;
	kvm_arch_vcpu_run_map_fp -> kern_hyp_va;
	kvm_arch_vcpu_run_map_fp -> kvm_vcpu_unshare_task_fp;
	kvm_arch_vcpu_run_map_fp -> kvm_share_hyp;
	get_task_struct	[label="get_task_struct()"];
	kvm_arch_vcpu_run_map_fp -> get_task_struct;
	kvm_init_mpidr_data -> BIT_ULL;
	kvm_init_mpidr_data -> mutex_lock;
	kvm_init_mpidr_data -> mutex_unlock;
	kvm_init_mpidr_data -> kvm_for_each_vcpu;
	kvm_init_mpidr_data -> kvm_mpidr_index;
	kvm_init_mpidr_data -> kvm_vcpu_get_mpidr_aff;
	kvm_init_mpidr_data -> kzalloc;
	kvm_init_mpidr_data -> atomic_read;
	hweight_long	[label="hweight_long()"];
	kvm_init_mpidr_data -> hweight_long;
	struct_size	[label="struct_size()"];
	kvm_init_mpidr_data -> struct_size;
	kvm_arm_vcpu_init_debug -> preempt_disable;
	kvm_arm_vcpu_init_debug -> preempt_enable;
	kvm_arm_setup_mdcr_el2	[label="void kvm_arm_setup_mdcr_el2 (struct kvm_vcpu *vcpu)
arch/arm64/kvm/debug.c:96"];
	kvm_arm_vcpu_init_debug -> kvm_arm_setup_mdcr_el2;
	kvm_timer_enable -> get_timer_map;
	kvm_timer_enable -> timer_irq;
	kvm_timer_enable -> irqchip_in_kernel;
	kvm_timer_enable -> vcpu_timer;
	kvm_timer_enable -> kvm_debug;
	kvm_timer_enable -> kvm_vgic_map_phys_irq;
	timer_irqs_are_valid	[label="bool timer_irqs_are_valid (struct kvm_vcpu *vcpu)
arch/arm64/kvm/arch_timer.c:1453"];
	kvm_timer_enable -> timer_irqs_are_valid;
	kvm_arm_pmu_v3_enable -> irqchip_in_kernel;
	kvm_arm_pmu_v3_enable -> kvm_vcpu_has_pmu;
	kvm_arm_pmu_v3_enable -> kvm_make_request;
	irq_is_ppi	[label="irq_is_ppi()"];
	kvm_arm_pmu_v3_enable -> irq_is_ppi;
	vgic_valid_spi	[label="vgic_valid_spi()"];
	kvm_arm_pmu_v3_enable -> vgic_valid_spi;
	kvm_arm_pmu_irq_initialized	[label="kvm_arm_pmu_irq_initialized()"];
	kvm_arm_pmu_v3_enable -> kvm_arm_pmu_irq_initialized;
	pkvm_create_hyp_vm -> mutex_lock;
	pkvm_create_hyp_vm -> mutex_unlock;
	kvm_arm_setup_mdcr_el2 -> vcpu_get_flag;
	kvm_vcpu_os_lock_enabled	[label="kvm_vcpu_os_lock_enabled()"];
	kvm_arm_setup_mdcr_el2 -> kvm_vcpu_os_lock_enabled;
	trace_kvm_arm_set_dreg32	[label="trace_kvm_arm_set_dreg32()"];
	kvm_arm_setup_mdcr_el2 -> trace_kvm_arm_set_dreg32;
	timer_irqs_are_valid -> bool;
	timer_irqs_are_valid -> mutex_lock;
	timer_irqs_are_valid -> mutex_unlock;
	timer_irqs_are_valid -> nr_timers;
	timer_irqs_are_valid -> set_bit;
	hweight32	[label="hweight32()"];
	timer_irqs_are_valid -> hweight32;
	vcpu_load -> get_cpu;
	vcpu_load -> put_cpu;
	vcpu_load -> kvm_arch_vcpu_load;
	preempt_notifier_register	[label="preempt_notifier_register()"];
	vcpu_load -> preempt_notifier_register;
	sigprocmask	[label="sigprocmask()"];
	kvm_sigset_activate -> sigprocmask;
	check_vcpu_requests -> preempt_disable;
	check_vcpu_requests -> preempt_enable;
	check_vcpu_requests -> kvm_vcpu_pmu_restore_guest;
	check_vcpu_requests -> vgic_v4_put;
	check_vcpu_requests -> vgic_v4_load;
	check_vcpu_requests -> kvm_check_request;
	kvm_request_pending	[label="kvm_request_pending()"];
	check_vcpu_requests -> kvm_request_pending;
	kvm_vcpu_sleep	[label="void kvm_vcpu_sleep (struct kvm_vcpu *vcpu)
arch/arm64/kvm/arm.c:735"];
	check_vcpu_requests -> kvm_vcpu_sleep;
	check_vcpu_requests -> kvm_reset_vcpu;
	kvm_update_stolen_time	[label="void kvm_update_stolen_time (struct kvm_vcpu *vcpu)
arch/arm64/kvm/pvtime.c:13"];
	check_vcpu_requests -> kvm_update_stolen_time;
	kvm_vcpu_reload_pmu	[label="void kvm_vcpu_reload_pmu (struct kvm_vcpu *vcpu)
arch/arm64/kvm/pmu-emul.c:806"];
	check_vcpu_requests -> kvm_vcpu_reload_pmu;
	kvm_vcpu_suspend	[label="int kvm_vcpu_suspend (struct kvm_vcpu *vcpu)
arch/arm64/kvm/arm.c:791"];
	check_vcpu_requests -> kvm_vcpu_suspend;
	kvm_dirty_ring_check_request	[label="bool kvm_dirty_ring_check_request (struct kvm_vcpu *vcpu)
virt/kvm/dirty_ring.c:194"];
	check_vcpu_requests -> kvm_dirty_ring_check_request;
	kvm_arm_vmid_update -> bool;
	kvm_arm_vmid_update -> this_cpu_ptr;
	kvm_arm_vmid_update -> atomic64_set;
	atomic64_read	[label="atomic64_read()"];
	kvm_arm_vmid_update -> atomic64_read;
	vmid_gen_match	[label="vmid_gen_match()"];
	kvm_arm_vmid_update -> vmid_gen_match;
	atomic64_cmpxchg_relaxed	[label="atomic64_cmpxchg_relaxed()"];
	kvm_arm_vmid_update -> atomic64_cmpxchg_relaxed;
	raw_spin_lock_irqsave	[label="raw_spin_lock_irqsave()"];
	kvm_arm_vmid_update -> raw_spin_lock_irqsave;
	new_vmid	[label="u64 new_vmid (struct kvm_vmid *kvm_vmid)
arch/arm64/kvm/vmid.c:92"];
	kvm_arm_vmid_update -> new_vmid;
	raw_spin_unlock_irqrestore	[label="raw_spin_unlock_irqrestore()"];
	kvm_arm_vmid_update -> raw_spin_unlock_irqrestore;
	kvm_pmu_update_state	[label="void kvm_pmu_update_state (struct kvm_vcpu *vcpu)
arch/arm64/kvm/pmu-emul.c:353"];
	kvm_pmu_flush_hwstate -> kvm_pmu_update_state;
	kvm_vcpu_exit_request -> static_branch_unlikely;
	kvm_vcpu_exit_request -> unlikely;
	kvm_vcpu_exit_request -> smp_processor_id;
	kvm_vcpu_exit_request -> kvm_request_pending;
	kvm_timer_should_notify_user	[label="bool kvm_timer_should_notify_user (struct kvm_vcpu *vcpu)
arch/arm64/kvm/arch_timer.c:861"];
	kvm_vcpu_exit_request -> kvm_timer_should_notify_user;
	kvm_pmu_should_notify_user	[label="bool kvm_pmu_should_notify_user (struct kvm_vcpu *vcpu)
arch/arm64/kvm/pmu-emul.c:374"];
	kvm_vcpu_exit_request -> kvm_pmu_should_notify_user;
	vcpu_on_unsupported_cpu	[label="vcpu_on_unsupported_cpu()"];
	kvm_vcpu_exit_request -> vcpu_on_unsupported_cpu;
	xfer_to_guest_mode_work_pending	[label="xfer_to_guest_mode_work_pending()"];
	kvm_vcpu_exit_request -> xfer_to_guest_mode_work_pending;
	kvm_pmu_sync_hwstate -> kvm_pmu_update_state;
	kvm_timer_sync_user -> unlikely;
	kvm_timer_sync_user -> irqchip_in_kernel;
	kvm_timer_sync_user -> vcpu_timer;
	unmask_vtimer_irq_user	[label="void unmask_vtimer_irq_user (struct kvm_vcpu *vcpu)
arch/arm64/kvm/arch_timer.c:915"];
	kvm_timer_sync_user -> unmask_vtimer_irq_user;
	kvm_arm_setup_debug -> vcpu_read_sys_reg;
	kvm_arm_setup_debug -> vcpu_get_flag;
	kvm_arm_setup_debug -> vcpu_write_sys_reg;
	kvm_arm_setup_debug -> vcpu_cpsr;
	kvm_arm_setup_debug -> has_vhe;
	kvm_arm_setup_debug -> BUG_ON;
	kvm_arm_setup_debug -> write_sysreg;
	kvm_arm_setup_debug -> vcpu_set_flag;
	kvm_arm_setup_debug -> get_num_brps;
	kvm_arm_setup_debug -> get_num_wrps;
	kvm_arm_setup_debug -> kvm_arm_setup_mdcr_el2;
	kvm_arm_setup_debug -> kvm_vcpu_os_lock_enabled;
	kvm_arm_setup_debug -> trace_kvm_arm_set_dreg32;
	trace_kvm_arm_setup_debug	[label="trace_kvm_arm_setup_debug()"];
	kvm_arm_setup_debug -> trace_kvm_arm_setup_debug;
	save_guest_debug_regs	[label="void save_guest_debug_regs (struct kvm_vcpu *vcpu)
arch/arm64/kvm/debug.c:40"];
	kvm_arm_setup_debug -> save_guest_debug_regs;
	trace_kvm_arm_set_regset	[label="trace_kvm_arm_set_regset()"];
	kvm_arm_setup_debug -> trace_kvm_arm_set_regset;
	test_thread_flag	[label="test_thread_flag()"];
	kvm_arch_vcpu_ctxflush_fp -> test_thread_flag;
	kvm_arm_vcpu_enter_exit -> kvm_call_hyp_ret;
	guest_state_enter_irqoff	[label="guest_state_enter_irqoff()"];
	kvm_arm_vcpu_enter_exit -> guest_state_enter_irqoff;
	guest_state_exit_irqoff	[label="guest_state_exit_irqoff()"];
	kvm_arm_vcpu_enter_exit -> guest_state_exit_irqoff;
	kvm_arm_clear_debug -> vcpu_cpsr;
	kvm_arm_clear_debug -> vcpu_set_flag;
	kvm_arm_clear_debug -> get_num_brps;
	kvm_arm_clear_debug -> get_num_wrps;
	kvm_arm_clear_debug -> kvm_vcpu_os_lock_enabled;
	kvm_arm_clear_debug -> trace_kvm_arm_set_regset;
	trace_kvm_arm_clear_debug	[label="trace_kvm_arm_clear_debug()"];
	kvm_arm_clear_debug -> trace_kvm_arm_clear_debug;
	restore_guest_debug_regs	[label="void restore_guest_debug_regs (struct kvm_vcpu *vcpu)
arch/arm64/kvm/debug.c:53"];
	kvm_arm_clear_debug -> restore_guest_debug_regs;
	kvm_arm_reset_debug_ptr	[label="void kvm_arm_reset_debug_ptr (struct kvm_vcpu *vcpu)
arch/arm64/kvm/debug.c:148"];
	kvm_arm_clear_debug -> kvm_arm_reset_debug_ptr;
	kvm_arch_vcpu_ctxsync_fp -> vcpu_has_sve;
	kvm_arch_vcpu_ctxsync_fp -> WARN_ON_ONCE;
	irqs_disabled	[label="irqs_disabled()"];
	kvm_arch_vcpu_ctxsync_fp -> irqs_disabled;
	fpsimd_bind_state_to_cpu	[label="fpsimd_bind_state_to_cpu()"];
	kvm_arch_vcpu_ctxsync_fp -> fpsimd_bind_state_to_cpu;
	clear_thread_flag	[label="clear_thread_flag()"];
	kvm_arch_vcpu_ctxsync_fp -> clear_thread_flag;
	handle_exit_early -> kvm_vcpu_get_esr;
	handle_exit_early -> this_cpu_has_cap;
	handle_exit_early -> kvm_inject_vabt;
	handle_exit_early -> ARM_EXCEPTION_CODE;
	ARM_SERROR_PENDING	[label="ARM_SERROR_PENDING()"];
	handle_exit_early -> ARM_SERROR_PENDING;
	kvm_vcpu_get_disr	[label="kvm_vcpu_get_disr()"];
	handle_exit_early -> kvm_vcpu_get_disr;
	kvm_handle_guest_serror	[label="void kvm_handle_guest_serror (struct kvm_vcpu *vcpu, u64 esr)
arch/arm64/kvm/handle_exit.c:31"];
	handle_exit_early -> kvm_handle_guest_serror;
	disr_to_esr	[label="disr_to_esr()"];
	handle_exit_early -> disr_to_esr;
	vcpu_mode_is_bad_32bit -> kvm_supports_32bit_el0;
	vcpu_mode_is_bad_32bit -> likely;
	vcpu_mode_is_bad_32bit -> vcpu_has_nv;
	vcpu_mode_is_bad_32bit -> vcpu_mode_is_32bit;
	handle_exit -> kvm_pr_unimpl;
	handle_exit -> ARM_EXCEPTION_CODE;
	handle_exit -> ARM_SERROR_PENDING;
	handle_trap_exceptions	[label="int handle_trap_exceptions (struct kvm_vcpu *vcpu)
arch/arm64/kvm/handle_exit.c:297"];
	handle_exit -> handle_trap_exceptions;
	kvm_timer_update_run -> vcpu_vtimer;
	kvm_timer_update_run -> vcpu_ptimer;
	kvm_timer_update_run -> kvm_timer_should_fire;
	kvm_sigset_deactivate -> sigprocmask;
	sigemptyset	[label="sigemptyset()"];
	kvm_sigset_deactivate -> sigemptyset;
	vcpu_put -> preempt_disable;
	vcpu_put -> preempt_enable;
	vcpu_put -> kvm_arch_vcpu_put;
	preempt_notifier_unregister	[label="preempt_notifier_unregister()"];
	vcpu_put -> preempt_notifier_unregister;
	kvm_vcpu_sleep -> kvm_make_request;
	kvm_vcpu_sleep -> smp_rmb;
	kvm_vcpu_sleep -> kvm_arm_vcpu_stopped;
	kvm_vcpu_sleep -> kvm_arch_vcpu_get_wait;
	rcuwait_wait_event	[label="rcuwait_wait_event()"];
	kvm_vcpu_sleep -> rcuwait_wait_event;
	kvm_reset_vcpu -> vcpu_el1_is_32bit;
	kvm_reset_vcpu -> vcpu_has_nv;
	kvm_reset_vcpu -> preempt_disable;
	kvm_reset_vcpu -> preempt_enable;
	kvm_reset_vcpu -> bool;
	kvm_reset_vcpu -> vcpu_pc;
	kvm_reset_vcpu -> memset;
	kvm_reset_vcpu -> vcpu_mode_is_32bit;
	kvm_reset_vcpu -> spin_lock;
	kvm_reset_vcpu -> spin_unlock;
	kvm_reset_vcpu -> kvm_arch_vcpu_put;
	kvm_reset_vcpu -> kvm_arch_vcpu_load;
	kvm_reset_vcpu -> smp_processor_id;
	kvm_reset_vcpu -> vcpu_set_reg;
	kvm_reset_vcpu -> kvm_arm_vcpu_sve_finalized;
	kvm_pmu_vcpu_reset	[label="void kvm_pmu_vcpu_reset (struct kvm_vcpu *vcpu)
arch/arm64/kvm/pmu-emul.c:245"];
	kvm_reset_vcpu -> kvm_pmu_vcpu_reset;
	vcpu_has_feature	[label="vcpu_has_feature()"];
	kvm_reset_vcpu -> vcpu_has_feature;
	kvm_vcpu_enable_sve	[label="void kvm_vcpu_enable_sve (struct kvm_vcpu *vcpu)
arch/arm64/kvm/reset.c:76"];
	kvm_reset_vcpu -> kvm_vcpu_enable_sve;
	kvm_vcpu_reset_sve	[label="void kvm_vcpu_reset_sve (struct kvm_vcpu *vcpu)
arch/arm64/kvm/reset.c:162"];
	kvm_reset_vcpu -> kvm_vcpu_reset_sve;
	kvm_vcpu_enable_ptrauth	[label="void kvm_vcpu_enable_ptrauth (struct kvm_vcpu *vcpu)
arch/arm64/kvm/reset.c:168"];
	kvm_reset_vcpu -> kvm_vcpu_enable_ptrauth;
	vcpu_gp_regs	[label="vcpu_gp_regs()"];
	kvm_reset_vcpu -> vcpu_gp_regs;
	kvm_reset_sys_regs	[label="void kvm_reset_sys_regs (struct kvm_vcpu *vcpu)
arch/arm64/kvm/sys_regs.c:3313"];
	kvm_reset_vcpu -> kvm_reset_sys_regs;
	vcpu_set_thumb	[label="vcpu_set_thumb()"];
	kvm_reset_vcpu -> vcpu_set_thumb;
	kvm_vcpu_set_be	[label="kvm_vcpu_set_be()"];
	kvm_reset_vcpu -> kvm_vcpu_set_be;
	kvm_timer_vcpu_reset	[label="void kvm_timer_vcpu_reset (struct kvm_vcpu *vcpu)
arch/arm64/kvm/arch_timer.c:939"];
	kvm_reset_vcpu -> kvm_timer_vcpu_reset;
	kvm_update_stolen_time -> srcu_read_lock;
	kvm_update_stolen_time -> srcu_read_unlock;
	kvm_update_stolen_time -> READ_ONCE;
	kvm_update_stolen_time -> offsetof;
	kvm_get_guest	[label="kvm_get_guest()"];
	kvm_update_stolen_time -> kvm_get_guest;
	le64_to_cpu	[label="le64_to_cpu()"];
	kvm_update_stolen_time -> le64_to_cpu;
	kvm_put_guest	[label="kvm_put_guest()"];
	kvm_update_stolen_time -> kvm_put_guest;
	cpu_to_le64	[label="cpu_to_le64()"];
	kvm_update_stolen_time -> cpu_to_le64;
	kvm_vcpu_reload_pmu -> kvm_pmu_valid_counter_mask;
	kvm_vcpu_reload_pmu -> kvm_vcpu_read_pmcr;
	kvm_vcpu_reload_pmu -> kvm_pmu_handle_pmcr;
	kvm_vcpu_suspend -> memset;
	kvm_vcpu_suspend -> kvm_make_request;
	kvm_vcpu_suspend -> kvm_vcpu_wfi;
	kvm_vcpu_suspend -> kvm_arch_vcpu_runnable;
	kvm_arm_vcpu_suspended	[label="bool kvm_arm_vcpu_suspended (struct kvm_vcpu *vcpu)
arch/arm64/kvm/arm.c:514"];
	kvm_vcpu_suspend -> kvm_arm_vcpu_suspended;
	kvm_dirty_ring_check_request -> kvm_make_request;
	kvm_dirty_ring_check_request -> kvm_check_request;
	kvm_dirty_ring_check_request -> kvm_dirty_ring_soft_full;
	trace_kvm_dirty_ring_exit	[label="trace_kvm_dirty_ring_exit()"];
	kvm_dirty_ring_check_request -> trace_kvm_dirty_ring_exit;
	kvm_pmu_vcpu_reset -> kvm_pmu_valid_counter_mask;
	kvm_pmu_vcpu_reset -> kvm_vcpu_idx_to_pmc;
	kvm_pmu_vcpu_reset -> kvm_pmu_stop_counter;
	kvm_pmu_vcpu_reset -> for_each_set_bit;
	kvm_vcpu_enable_sve -> vcpu_set_flag;
	kvm_vcpu_reset_sve -> vcpu_has_sve;
	kvm_vcpu_reset_sve -> memset;
	kvm_vcpu_reset_sve -> vcpu_sve_state_size;
	kvm_vcpu_enable_ptrauth -> vcpu_set_flag;
	kvm_reset_sys_regs -> reg_to_encoding;
	kvm_reset_sys_regs -> ARRAY_SIZE;
	kvm_reset_id_regs	[label="void kvm_reset_id_regs (struct kvm_vcpu *vcpu)
arch/arm64/kvm/sys_regs.c:3284"];
	kvm_reset_sys_regs -> kvm_reset_id_regs;
	is_id_reg	[label="inline bool is_id_reg (u32 id)
arch/arm64/kvm/sys_regs.c:1449"];
	kvm_reset_sys_regs -> is_id_reg;
	kvm_timer_vcpu_reset -> vcpu_has_nv;
	kvm_timer_vcpu_reset -> get_timer_map;
	kvm_timer_vcpu_reset -> vcpu_get_timer;
	kvm_timer_vcpu_reset -> soft_timer_cancel;
	kvm_timer_vcpu_reset -> vcpu_vtimer;
	kvm_timer_vcpu_reset -> timer_set_ctl;
	kvm_timer_vcpu_reset -> kvm_timer_update_irq;
	kvm_timer_vcpu_reset -> timer_irq;
	kvm_timer_vcpu_reset -> irqchip_in_kernel;
	kvm_timer_vcpu_reset -> vcpu_timer;
	kvm_vgic_reset_mapped_irq	[label="kvm_vgic_reset_mapped_irq()"];
	kvm_timer_vcpu_reset -> kvm_vgic_reset_mapped_irq;
	kvm_reset_id_regs -> reg_to_encoding;
	kvm_reset_id_regs -> IDREG;
	kvm_reset_id_regs -> test_bit;
	kvm_reset_id_regs -> lockdep_assert_held;
	kvm_reset_id_regs -> set_bit;
	kvm_reset_id_regs -> is_id_reg;
	is_id_reg -> sys_reg_Op0;
	is_id_reg -> sys_reg_Op1;
	is_id_reg -> sys_reg_CRn;
	is_id_reg -> sys_reg_CRm;
	kvm_arm_vcpu_suspended -> READ_ONCE;
	new_vmid -> atomic64_set;
	new_vmid -> atomic64_read;
	check_update_reserved_vmid	[label="bool check_update_reserved_vmid (u64 vmid, u64 newvmid)
arch/arm64/kvm/vmid.c:72"];
	new_vmid -> check_update_reserved_vmid;
	vmid2idx	[label="vmid2idx()"];
	new_vmid -> vmid2idx;
	find_next_zero_bit	[label="find_next_zero_bit()"];
	new_vmid -> find_next_zero_bit;
	atomic64_add_return_relaxed	[label="atomic64_add_return_relaxed()"];
	new_vmid -> atomic64_add_return_relaxed;
	flush_context	[label="void flush_context (void)
arch/arm64/kvm/vmid.c:45"];
	new_vmid -> flush_context;
	idx2vmid	[label="idx2vmid()"];
	new_vmid -> idx2vmid;
	check_update_reserved_vmid -> bool;
	check_update_reserved_vmid -> for_each_possible_cpu;
	check_update_reserved_vmid -> per_cpu;
	flush_context -> kvm_call_hyp;
	flush_context -> for_each_possible_cpu;
	flush_context -> per_cpu;
	flush_context -> bitmap_zero;
	flush_context -> vmid2idx;
	atomic64_xchg_relaxed	[label="atomic64_xchg_relaxed()"];
	flush_context -> atomic64_xchg_relaxed;
	kvm_pmu_update_state -> likely;
	kvm_pmu_update_state -> WARN_ON;
	kvm_pmu_update_state -> bool;
	kvm_pmu_update_state -> kvm_vgic_inject_irq;
	kvm_pmu_update_state -> irqchip_in_kernel;
	kvm_pmu_update_state -> kvm_vcpu_has_pmu;
	kvm_pmu_update_state -> kvm_pmu_overflow_status;
	kvm_timer_should_notify_user -> likely;
	kvm_timer_should_notify_user -> vcpu_vtimer;
	kvm_timer_should_notify_user -> vcpu_ptimer;
	kvm_timer_should_notify_user -> bool;
	kvm_timer_should_notify_user -> kvm_timer_should_fire;
	kvm_timer_should_notify_user -> irqchip_in_kernel;
	kvm_pmu_should_notify_user -> likely;
	kvm_pmu_should_notify_user -> bool;
	kvm_pmu_should_notify_user -> irqchip_in_kernel;
	unmask_vtimer_irq_user -> vcpu_vtimer;
	unmask_vtimer_irq_user -> kvm_timer_should_fire;
	unmask_vtimer_irq_user -> kvm_timer_update_irq;
	unmask_vtimer_irq_user -> static_branch_likely;
	unmask_vtimer_irq_user -> set_timer_irq_phys_active;
	unmask_vtimer_irq_user -> enable_percpu_irq;
	save_guest_debug_regs -> vcpu_read_sys_reg;
	save_guest_debug_regs -> vcpu_cpsr;
	save_guest_debug_regs -> trace_kvm_arm_set_dreg32;
	restore_guest_debug_regs -> vcpu_read_sys_reg;
	restore_guest_debug_regs -> vcpu_write_sys_reg;
	restore_guest_debug_regs -> vcpu_cpsr;
	restore_guest_debug_regs -> trace_kvm_arm_set_dreg32;
	kvm_handle_guest_serror -> kvm_inject_vabt;
	arm64_is_ras_serror	[label="arm64_is_ras_serror()"];
	kvm_handle_guest_serror -> arm64_is_ras_serror;
	arm64_is_fatal_ras_serror	[label="arm64_is_fatal_ras_serror()"];
	kvm_handle_guest_serror -> arm64_is_fatal_ras_serror;
	handle_trap_exceptions -> kvm_incr_pc;
	kvm_condition_valid	[label="kvm_condition_valid()"];
	handle_trap_exceptions -> kvm_condition_valid;
	kvm_get_exit_handler	[label="exit_handle_fn kvm_get_exit_handler (struct kvm_vcpu *vcpu)
arch/arm64/kvm/handle_exit.c:283"];
	handle_trap_exceptions -> kvm_get_exit_handler;
	kvm_get_exit_handler -> kvm_vcpu_get_esr;
	kvm_get_exit_handler -> ESR_ELx_EC;
	kvm_arm_vcpu_suspend -> kvm_make_request;
	kvm_arm_vcpu_suspend -> kvm_vcpu_kick;
	kvm_arm_vcpu_suspend -> WRITE_ONCE;
	kvm_arch_vcpu_ioctl_vcpu_init -> bool;
	kvm_arch_vcpu_ioctl_vcpu_init -> cpus_have_final_cap;
	kvm_arch_vcpu_ioctl_vcpu_init -> BIT;
	kvm_arch_vcpu_ioctl_vcpu_init -> WRITE_ONCE;
	kvm_arch_vcpu_ioctl_vcpu_init -> spin_lock;
	kvm_arch_vcpu_ioctl_vcpu_init -> spin_unlock;
	kvm_arch_vcpu_ioctl_vcpu_init -> vcpu_has_run_once;
	kvm_vcpu_set_target	[label="int kvm_vcpu_set_target (struct kvm_vcpu *vcpu, const struct kvm_vcpu_init *init)
arch/arm64/kvm/arm.c:1366"];
	kvm_arch_vcpu_ioctl_vcpu_init -> kvm_vcpu_set_target;
	stage2_unmap_vm	[label="void stage2_unmap_vm (struct kvm *kvm)
arch/arm64/kvm/mmu.c:990"];
	kvm_arch_vcpu_ioctl_vcpu_init -> stage2_unmap_vm;
	icache_inval_all_pou	[label="icache_inval_all_pou()"];
	kvm_arch_vcpu_ioctl_vcpu_init -> icache_inval_all_pou;
	vcpu_reset_hcr	[label="vcpu_reset_hcr()"];
	kvm_arch_vcpu_ioctl_vcpu_init -> vcpu_reset_hcr;
	kvm_get_reset_cptr_el2	[label="kvm_get_reset_cptr_el2()"];
	kvm_arch_vcpu_ioctl_vcpu_init -> kvm_get_reset_cptr_el2;
	set_core_reg	[label="int set_core_reg (struct kvm_vcpu *vcpu, const struct kvm_one_reg *reg)
arch/arm64/kvm/guest.c:215"];
	kvm_arm_set_reg -> set_core_reg;
	kvm_arm_set_fw_reg	[label="int kvm_arm_set_fw_reg (struct kvm_vcpu *vcpu, const struct kvm_one_reg *reg)
arch/arm64/kvm/hypercalls.c:551"];
	kvm_arm_set_reg -> kvm_arm_set_fw_reg;
	set_sve_reg	[label="int set_sve_reg (struct kvm_vcpu *vcpu, const struct kvm_one_reg *reg)
arch/arm64/kvm/guest.c:510"];
	kvm_arm_set_reg -> set_sve_reg;
	is_timer_reg	[label="bool is_timer_reg (u64 index)
arch/arm64/kvm/guest.c:604"];
	kvm_arm_set_reg -> is_timer_reg;
	set_timer_reg	[label="int set_timer_reg (struct kvm_vcpu *vcpu, const struct kvm_one_reg *reg)
arch/arm64/kvm/guest.c:629"];
	kvm_arm_set_reg -> set_timer_reg;
	kvm_arm_sys_reg_set_reg	[label="int kvm_arm_sys_reg_set_reg (struct kvm_vcpu *vcpu, const struct kvm_one_reg *reg)
arch/arm64/kvm/sys_regs.c:3610"];
	kvm_arm_set_reg -> kvm_arm_sys_reg_set_reg;
	kvm_arm_get_reg -> is_timer_reg;
	get_core_reg	[label="int get_core_reg (struct kvm_vcpu *vcpu, const struct kvm_one_reg *reg)
arch/arm64/kvm/guest.c:186"];
	kvm_arm_get_reg -> get_core_reg;
	kvm_arm_get_fw_reg	[label="int kvm_arm_get_fw_reg (struct kvm_vcpu *vcpu, const struct kvm_one_reg *reg)
arch/arm64/kvm/hypercalls.c:476"];
	kvm_arm_get_reg -> kvm_arm_get_fw_reg;
	get_sve_reg	[label="int get_sve_reg (struct kvm_vcpu *vcpu, const struct kvm_one_reg *reg)
arch/arm64/kvm/guest.c:484"];
	kvm_arm_get_reg -> get_sve_reg;
	get_timer_reg	[label="int get_timer_reg (struct kvm_vcpu *vcpu, const struct kvm_one_reg *reg)
arch/arm64/kvm/guest.c:642"];
	kvm_arm_get_reg -> get_timer_reg;
	kvm_arm_sys_reg_get_reg	[label="int kvm_arm_sys_reg_get_reg (struct kvm_vcpu *vcpu, const struct kvm_one_reg *reg)
arch/arm64/kvm/sys_regs.c:3566"];
	kvm_arm_get_reg -> kvm_arm_sys_reg_get_reg;
	num_core_regs	[label="unsigned long num_core_regs (const struct kvm_vcpu *vcpu)
arch/arm64/kvm/guest.c:588"];
	kvm_arm_num_regs -> num_core_regs;
	num_sve_regs	[label="unsigned long num_sve_regs (const struct kvm_vcpu *vcpu)
arch/arm64/kvm/guest.c:651"];
	kvm_arm_num_regs -> num_sve_regs;
	kvm_arm_num_sys_reg_descs	[label="unsigned long kvm_arm_num_sys_reg_descs (struct kvm_vcpu *vcpu)
arch/arm64/kvm/sys_regs.c:3708"];
	kvm_arm_num_regs -> kvm_arm_num_sys_reg_descs;
	kvm_arm_get_fw_num_regs	[label="int kvm_arm_get_fw_num_regs (struct kvm_vcpu *vcpu)
arch/arm64/kvm/hypercalls.c:408"];
	kvm_arm_num_regs -> kvm_arm_get_fw_num_regs;
	kvm_arm_copy_reg_indices -> kvm_arm_get_fw_num_regs;
	copy_core_reg_indices	[label="int copy_core_reg_indices (const struct kvm_vcpu *vcpu, u64 __user *uindices)
arch/arm64/kvm/guest.c:545"];
	kvm_arm_copy_reg_indices -> copy_core_reg_indices;
	copy_sve_reg_indices	[label="int copy_sve_reg_indices (const struct kvm_vcpu *vcpu, u64 __user *uindices)
arch/arm64/kvm/guest.c:665"];
	kvm_arm_copy_reg_indices -> copy_sve_reg_indices;
	kvm_arm_copy_fw_reg_indices	[label="int kvm_arm_copy_fw_reg_indices (struct kvm_vcpu *vcpu, u64 __user *uindices)
arch/arm64/kvm/hypercalls.c:413"];
	kvm_arm_copy_reg_indices -> kvm_arm_copy_fw_reg_indices;
	copy_timer_indices	[label="int copy_timer_indices (struct kvm_vcpu *vcpu, u64 __user *uindices)
arch/arm64/kvm/guest.c:618"];
	kvm_arm_copy_reg_indices -> copy_timer_indices;
	kvm_arm_copy_sys_reg_indices	[label="int kvm_arm_copy_sys_reg_indices (struct kvm_vcpu *vcpu, u64 __user *uindices)
arch/arm64/kvm/sys_regs.c:3715"];
	kvm_arm_copy_reg_indices -> kvm_arm_copy_sys_reg_indices;
	kvm_arm_vcpu_arch_set_attr	[label="int kvm_arm_vcpu_arch_set_attr (struct kvm_vcpu *vcpu, struct kvm_device_attr *attr)
arch/arm64/kvm/guest.c:943"];
	kvm_arm_vcpu_set_attr -> kvm_arm_vcpu_arch_set_attr;
	kvm_arm_vcpu_arch_get_attr	[label="int kvm_arm_vcpu_arch_get_attr (struct kvm_vcpu *vcpu, struct kvm_device_attr *attr)
arch/arm64/kvm/guest.c:968"];
	kvm_arm_vcpu_get_attr -> kvm_arm_vcpu_arch_get_attr;
	kvm_arm_vcpu_arch_has_attr	[label="int kvm_arm_vcpu_arch_has_attr (struct kvm_vcpu *vcpu, struct kvm_device_attr *attr)
arch/arm64/kvm/guest.c:991"];
	kvm_arm_vcpu_has_attr -> kvm_arm_vcpu_arch_has_attr;
	kvm_arm_vcpu_get_events -> memset;
	kvm_arm_vcpu_set_events -> ARRAY_SIZE;
	kvm_arm_vcpu_finalize -> vcpu_has_sve;
	kvm_arm_vcpu_finalize -> kvm_arm_vcpu_sve_finalized;
	kvm_vcpu_finalize_sve	[label="int kvm_vcpu_finalize_sve (struct kvm_vcpu *vcpu)
arch/arm64/kvm/reset.c:92"];
	kvm_arm_vcpu_finalize -> kvm_vcpu_finalize_sve;
	kvm_vcpu_set_target -> kvm_vcpu_initialized;
	kvm_vcpu_set_target -> kvm_reset_vcpu;
	kvm_target_cpu	[label="u32 __attribute_const__ kvm_target_cpu (void)
arch/arm64/kvm/guest.c:857"];
	kvm_vcpu_set_target -> kvm_target_cpu;
	kvm_vcpu_init_check_features	[label="int kvm_vcpu_init_check_features (struct kvm_vcpu *vcpu, const struct kvm_vcpu_init *init)
arch/arm64/kvm/arm.c:1268"];
	kvm_vcpu_set_target -> kvm_vcpu_init_check_features;
	kvm_vcpu_init_changed	[label="bool kvm_vcpu_init_changed (struct kvm_vcpu *vcpu, const struct kvm_vcpu_init *init)
arch/arm64/kvm/arm.c:1312"];
	kvm_vcpu_set_target -> kvm_vcpu_init_changed;
	stage2_unmap_vm -> srcu_read_lock;
	stage2_unmap_vm -> write_lock;
	stage2_unmap_vm -> kvm_memslots;
	stage2_unmap_vm -> kvm_for_each_memslot;
	stage2_unmap_vm -> write_unlock;
	stage2_unmap_vm -> srcu_read_unlock;
	stage2_unmap_vm -> mmap_read_lock;
	stage2_unmap_vm -> mmap_read_unlock;
	stage2_unmap_memslot	[label="void stage2_unmap_memslot (struct kvm *kvm, struct kvm_memory_slot *memslot)
arch/arm64/kvm/mmu.c:941"];
	stage2_unmap_vm -> stage2_unmap_memslot;
	read_cpuid_implementor	[label="read_cpuid_implementor()"];
	kvm_target_cpu -> read_cpuid_implementor;
	read_cpuid_part_number	[label="read_cpuid_part_number()"];
	kvm_target_cpu -> read_cpuid_part_number;
	kvm_vcpu_init_check_features -> kvm_has_mte;
	kvm_vcpu_init_check_features -> test_bit;
	kvm_vcpu_init_check_features -> ARRAY_SIZE;
	system_supported_vcpu_features	[label="unsigned long system_supported_vcpu_features (void)
arch/arm64/kvm/arm.c:1244"];
	kvm_vcpu_init_check_features -> system_supported_vcpu_features;
	bitmap_equal	[label="bitmap_equal()"];
	kvm_vcpu_init_changed -> bitmap_equal;
	system_supported_vcpu_features -> cpus_have_final_cap;
	system_supported_vcpu_features -> kvm_arm_support_pmu_v3;
	system_supported_vcpu_features -> system_supports_sve;
	system_supported_vcpu_features -> system_has_full_ptr_auth;
	clear_bit	[label="clear_bit()"];
	system_supported_vcpu_features -> clear_bit;
	stage2_unmap_memslot -> min;
	stage2_unmap_memslot -> max;
	find_vma_intersection	[label="find_vma_intersection()"];
	stage2_unmap_memslot -> find_vma_intersection;
	unmap_stage2_range	[label="void unmap_stage2_range (struct kvm_s2_mmu *mmu, phys_addr_t start, u64 size)
arch/arm64/kvm/mmu.c:331"];
	stage2_unmap_memslot -> unmap_stage2_range;
	set_core_reg -> kvm_supports_32bit_el0;
	set_core_reg -> vcpu_el1_is_32bit;
	set_core_reg -> vcpu_has_nv;
	set_core_reg -> vcpu_cpsr;
	set_core_reg -> vcpu_pc;
	set_core_reg -> memcpy;
	set_core_reg -> vcpu_get_reg;
	set_core_reg -> vcpu_set_reg;
	set_core_reg -> copy_from_user;
	core_reg_offset_from_id	[label="u64 core_reg_offset_from_id (u64 id)
arch/arm64/kvm/guest.c:71"];
	set_core_reg -> core_reg_offset_from_id;
	KVM_REG_SIZE	[label="KVM_REG_SIZE()"];
	set_core_reg -> KVM_REG_SIZE;
	core_reg_addr	[label="void *core_reg_addr (struct kvm_vcpu *vcpu, const struct kvm_one_reg *reg)
arch/arm64/kvm/guest.c:121"];
	set_core_reg -> core_reg_addr;
	KVM_REG_ARM_CORE_REG	[label="KVM_REG_ARM_CORE_REG()"];
	set_core_reg -> KVM_REG_ARM_CORE_REG;
	kvm_arm_set_fw_reg -> bool;
	kvm_arm_set_fw_reg -> copy_from_user;
	kvm_arm_set_fw_reg -> vcpu_has_feature;
	kvm_arm_set_fw_reg -> KVM_REG_SIZE;
	get_kernel_wa_level	[label="int get_kernel_wa_level (u64 regid)
arch/arm64/kvm/hypercalls.c:431"];
	kvm_arm_set_fw_reg -> get_kernel_wa_level;
	kvm_arm_set_fw_reg_bmap	[label="int kvm_arm_set_fw_reg_bmap (struct kvm_vcpu *vcpu, u64 reg_id, u64 val)
arch/arm64/kvm/hypercalls.c:510"];
	kvm_arm_set_fw_reg -> kvm_arm_set_fw_reg_bmap;
	set_sve_reg -> copy_from_user;
	set_sve_reg -> kvm_arm_vcpu_sve_finalized;
	set_sve_vls	[label="int set_sve_vls (struct kvm_vcpu *vcpu, const struct kvm_one_reg *reg)
arch/arm64/kvm/guest.c:336"];
	set_sve_reg -> set_sve_vls;
	sve_reg_to_region	[label="int sve_reg_to_region (struct sve_state_reg_region *region, struct kvm_vcpu *vcpu, const struct kvm_one_reg *reg)
arch/arm64/kvm/\
guest.c:417"];
	set_sve_reg -> sve_reg_to_region;
	set_timer_reg -> copy_from_user;
	set_timer_reg -> KVM_REG_SIZE;
	kvm_arm_timer_set_reg	[label="int kvm_arm_timer_set_reg (struct kvm_vcpu *vcpu, u64 regid, u64 value)
arch/arm64/kvm/arch_timer.c:1049"];
	set_timer_reg -> kvm_arm_timer_set_reg;
	kvm_arm_sys_reg_set_reg -> ARRAY_SIZE;
	demux_c15_set	[label="int demux_c15_set (struct kvm_vcpu *vcpu, u64 id, void __user *uaddr)
arch/arm64/kvm/sys_regs.c:3513"];
	kvm_arm_sys_reg_set_reg -> demux_c15_set;
	set_invariant_sys_reg	[label="int set_invariant_sys_reg (u64 id, u64 __user *uaddr)
arch/arm64/kvm/sys_regs.c:3468"];
	kvm_arm_sys_reg_set_reg -> set_invariant_sys_reg;
	kvm_sys_reg_set_user	[label="int kvm_sys_reg_set_user (struct kvm_vcpu *vcpu, const struct kvm_one_reg *reg, const struct sys_reg_desc table[], unsigned int \
num)
arch/arm64/kvm/sys_regs.c:3582"];
	kvm_arm_sys_reg_set_reg -> kvm_sys_reg_set_user;
	core_reg_addr -> core_reg_offset_from_id;
	core_reg_addr -> KVM_REG_SIZE;
	core_reg_addr -> KVM_REG_ARM_CORE_REG;
	core_reg_size_from_offset	[label="int core_reg_size_from_offset (const struct kvm_vcpu *vcpu, u64 off)
arch/arm64/kvm/guest.c:76"];
	core_reg_addr -> core_reg_size_from_offset;
	core_reg_size_from_offset -> vcpu_has_sve;
	core_reg_size_from_offset -> IS_ALIGNED;
	core_reg_size_from_offset -> KVM_REG_ARM_CORE_REG;
	core_reg_offset_is_vreg	[label="bool core_reg_offset_is_vreg (u64 off)
arch/arm64/kvm/guest.c:65"];
	core_reg_size_from_offset -> core_reg_offset_is_vreg;
	core_reg_offset_is_vreg -> KVM_REG_ARM_CORE_REG;
	get_kernel_wa_level -> cpus_have_final_cap;
	get_kernel_wa_level -> arm64_get_spectre_v2_state;
	get_kernel_wa_level -> arm64_get_spectre_v4_state;
	get_kernel_wa_level -> arm64_get_spectre_bhb_state;
	kvm_arm_set_fw_reg_bmap -> WRITE_ONCE;
	kvm_arm_set_fw_reg_bmap -> kvm_vm_has_ran_once;
	kvm_arm_set_fw_reg_bmap -> mutex_lock;
	kvm_arm_set_fw_reg_bmap -> mutex_unlock;
	set_sve_vls -> vcpu_has_sve;
	set_sve_vls -> WARN_ON;
	set_sve_vls -> copy_from_user;
	set_sve_vls -> kvm_arm_vcpu_sve_finalized;
	vq_present	[label="vq_present()"];
	set_sve_vls -> vq_present;
	sve_vq_from_vl	[label="sve_vq_from_vl()"];
	set_sve_vls -> sve_vq_from_vl;
	sve_vq_available	[label="sve_vq_available()"];
	set_sve_vls -> sve_vq_available;
	sve_vl_from_vq	[label="sve_vl_from_vq()"];
	set_sve_vls -> sve_vl_from_vq;
	sve_reg_to_region -> vcpu_has_sve;
	sve_reg_to_region -> WARN_ON;
	sve_reg_to_region -> min;
	sve_reg_to_region -> vcpu_sve_max_vq;
	sve_reg_to_region -> BUILD_BUG_ON;
	sve_reg_to_region -> vcpu_sve_state_size;
	KVM_REG_ARM64_SVE_ZREG	[label="KVM_REG_ARM64_SVE_ZREG()"];
	sve_reg_to_region -> KVM_REG_ARM64_SVE_ZREG;
	KVM_REG_ARM64_SVE_PREG	[label="KVM_REG_ARM64_SVE_PREG()"];
	sve_reg_to_region -> KVM_REG_ARM64_SVE_PREG;
	KVM_REG_ARM64_SVE_FFR	[label="KVM_REG_ARM64_SVE_FFR()"];
	sve_reg_to_region -> KVM_REG_ARM64_SVE_FFR;
	SVE_SIG_ZREG_OFFSET	[label="SVE_SIG_ZREG_OFFSET()"];
	sve_reg_to_region -> SVE_SIG_ZREG_OFFSET;
	SVE_SIG_ZREG_SIZE	[label="SVE_SIG_ZREG_SIZE()"];
	sve_reg_to_region -> SVE_SIG_ZREG_SIZE;
	SVE_SIG_PREG_OFFSET	[label="SVE_SIG_PREG_OFFSET()"];
	sve_reg_to_region -> SVE_SIG_PREG_OFFSET;
	SVE_SIG_PREG_SIZE	[label="SVE_SIG_PREG_SIZE()"];
	sve_reg_to_region -> SVE_SIG_PREG_SIZE;
	array_index_nospec	[label="array_index_nospec()"];
	sve_reg_to_region -> array_index_nospec;
	kvm_arm_timer_set_reg -> kvm_arm_timer_write;
	kvm_arm_timer_set_reg -> vcpu_vtimer;
	kvm_arm_timer_set_reg -> vcpu_ptimer;
	kvm_arm_timer_set_reg -> kvm_phys_timer_read;
	kvm_arm_timer_set_reg -> test_bit;
	timer_set_offset	[label="void timer_set_offset (struct arch_timer_context *ctxt, u64 offset)
arch/arm64/kvm/arch_timer.c:163"];
	kvm_arm_timer_set_reg -> timer_set_offset;
	timer_set_offset -> arch_timer_ctx_index;
	timer_set_offset -> WRITE_ONCE;
	timer_set_offset -> WARN;
	demux_c15_set -> get_user;
	demux_c15_set -> KVM_REG_SIZE;
	set_ccsidr	[label="int set_ccsidr (struct kvm_vcpu *vcpu, u32 csselr, u32 val)
arch/arm64/kvm/sys_regs.c:152"];
	demux_c15_set -> set_ccsidr;
	set_invariant_sys_reg -> ARRAY_SIZE;
	set_invariant_sys_reg -> get_user;
	get_reg_by_id	[label="const struct sys_reg_desc *get_reg_by_id (u64 id, const struct sys_reg_desc table[], unsigned int num)
arch/arm64/kvm/sys_regs.c:\
3389"];
	set_invariant_sys_reg -> get_reg_by_id;
	kvm_sys_reg_set_user -> get_user;
	id_to_sys_reg_desc	[label="const struct sys_reg_desc *id_to_sys_reg_desc (struct kvm_vcpu *vcpu, u64 id, const struct sys_reg_desc table[], unsigned int num)
\
arch/arm64/kvm/sys_regs.c:3403"];
	kvm_sys_reg_set_user -> id_to_sys_reg_desc;
	sysreg_hidden_user	[label="sysreg_hidden_user()"];
	kvm_sys_reg_set_user -> sysreg_hidden_user;
	sysreg_user_write_ignore	[label="sysreg_user_write_ignore()"];
	kvm_sys_reg_set_user -> sysreg_user_write_ignore;
	set_ccsidr -> get_ccsidr;
	set_ccsidr -> get_min_cache_line_size;
	set_ccsidr -> FIELD_GET;
	kmalloc_array	[label="kmalloc_array()"];
	set_ccsidr -> kmalloc_array;
	get_reg_by_id -> find_reg;
	index_to_params	[label="bool index_to_params (u64 id, struct sys_reg_params *params)
arch/arm64/kvm/sys_regs.c:3360"];
	get_reg_by_id -> index_to_params;
	id_to_sys_reg_desc -> sysreg_hidden;
	id_to_sys_reg_desc -> get_reg_by_id;
	get_core_reg -> copy_to_user;
	get_core_reg -> core_reg_offset_from_id;
	get_core_reg -> KVM_REG_SIZE;
	get_core_reg -> core_reg_addr;
	kvm_arm_get_fw_reg -> READ_ONCE;
	kvm_arm_get_fw_reg -> kvm_psci_version;
	kvm_arm_get_fw_reg -> copy_to_user;
	kvm_arm_get_fw_reg -> KVM_REG_SIZE;
	kvm_arm_get_fw_reg -> get_kernel_wa_level;
	get_sve_reg -> copy_to_user;
	get_sve_reg -> kvm_arm_vcpu_sve_finalized;
	get_sve_reg -> sve_reg_to_region;
	get_sve_vls	[label="int get_sve_vls (struct kvm_vcpu *vcpu, const struct kvm_one_reg *reg)
arch/arm64/kvm/guest.c:312"];
	get_sve_reg -> get_sve_vls;
	clear_user	[label="clear_user()"];
	get_sve_reg -> clear_user;
	get_timer_reg -> copy_to_user;
	get_timer_reg -> kvm_arm_timer_get_reg;
	get_timer_reg -> KVM_REG_SIZE;
	kvm_arm_sys_reg_get_reg -> ARRAY_SIZE;
	demux_c15_get	[label="int demux_c15_get (struct kvm_vcpu *vcpu, u64 id, void __user *uaddr)
arch/arm64/kvm/sys_regs.c:3488"];
	kvm_arm_sys_reg_get_reg -> demux_c15_get;
	get_invariant_sys_reg	[label="int get_invariant_sys_reg (u64 id, u64 __user *uaddr)
arch/arm64/kvm/sys_regs.c:3456"];
	kvm_arm_sys_reg_get_reg -> get_invariant_sys_reg;
	kvm_sys_reg_get_user	[label="int kvm_sys_reg_get_user (struct kvm_vcpu *vcpu, const struct kvm_one_reg *reg, const struct sys_reg_desc table[], unsigned int \
num)
arch/arm64/kvm/sys_regs.c:3541"];
	kvm_arm_sys_reg_get_reg -> kvm_sys_reg_get_user;
	get_sve_vls -> vcpu_has_sve;
	get_sve_vls -> WARN_ON;
	get_sve_vls -> memset;
	get_sve_vls -> vcpu_sve_max_vq;
	get_sve_vls -> copy_to_user;
	get_sve_vls -> sve_vq_available;
	sve_vl_valid	[label="sve_vl_valid()"];
	get_sve_vls -> sve_vl_valid;
	vq_word	[label="vq_word()"];
	get_sve_vls -> vq_word;
	vq_mask	[label="vq_mask()"];
	get_sve_vls -> vq_mask;
	demux_c15_get -> get_ccsidr;
	demux_c15_get -> KVM_REG_SIZE;
	put_user	[label="put_user()"];
	demux_c15_get -> put_user;
	get_invariant_sys_reg -> ARRAY_SIZE;
	get_invariant_sys_reg -> get_reg_by_id;
	get_invariant_sys_reg -> put_user;
	kvm_sys_reg_get_user -> id_to_sys_reg_desc;
	kvm_sys_reg_get_user -> sysreg_hidden_user;
	kvm_sys_reg_get_user -> put_user;
	num_core_regs -> copy_core_reg_indices;
	num_sve_regs -> vcpu_has_sve;
	num_sve_regs -> WARN_ON;
	num_sve_regs -> kvm_arm_vcpu_sve_finalized;
	vcpu_sve_slices	[label="vcpu_sve_slices()"];
	num_sve_regs -> vcpu_sve_slices;
	kvm_arm_num_sys_reg_descs -> ARRAY_SIZE;
	num_demux_regs	[label="unsigned int num_demux_regs (void)
arch/arm64/kvm/sys_regs.c:3626"];
	kvm_arm_num_sys_reg_descs -> num_demux_regs;
	walk_sys_regs	[label="int walk_sys_regs (struct kvm_vcpu *vcpu, u64 __user *uind)
arch/arm64/kvm/sys_regs.c:3691"];
	kvm_arm_num_sys_reg_descs -> walk_sys_regs;
	kvm_arm_get_fw_num_regs -> ARRAY_SIZE;
	copy_core_reg_indices -> WARN_ON;
	copy_core_reg_indices -> core_reg_size_from_offset;
	copy_core_reg_indices -> put_user;
	walk_sys_regs -> ARRAY_SIZE;
	walk_one_sys_reg	[label="int walk_one_sys_reg (const struct kvm_vcpu *vcpu, const struct sys_reg_desc *rd, u64 __user **uind, unsigned int *total)
arch/arm64/\
kvm/sys_regs.c:3668"];
	walk_sys_regs -> walk_one_sys_reg;
	walk_one_sys_reg -> sysreg_hidden_user;
	copy_reg_to_user	[label="bool copy_reg_to_user (const struct sys_reg_desc *reg, u64 __user **uind)
arch/arm64/kvm/sys_regs.c:3656"];
	walk_one_sys_reg -> copy_reg_to_user;
	copy_reg_to_user -> put_user;
	sys_reg_to_index	[label="u64 sys_reg_to_index (const struct sys_reg_desc *reg)
arch/arm64/kvm/sys_regs.c:3645"];
	copy_reg_to_user -> sys_reg_to_index;
	copy_sve_reg_indices -> vcpu_has_sve;
	copy_sve_reg_indices -> WARN_ON;
	copy_sve_reg_indices -> kvm_arm_vcpu_sve_finalized;
	copy_sve_reg_indices -> KVM_REG_ARM64_SVE_ZREG;
	copy_sve_reg_indices -> KVM_REG_ARM64_SVE_PREG;
	copy_sve_reg_indices -> KVM_REG_ARM64_SVE_FFR;
	copy_sve_reg_indices -> put_user;
	copy_sve_reg_indices -> vcpu_sve_slices;
	kvm_arm_copy_fw_reg_indices -> ARRAY_SIZE;
	kvm_arm_copy_fw_reg_indices -> put_user;
	kvm_arm_copy_sys_reg_indices -> ARRAY_SIZE;
	kvm_arm_copy_sys_reg_indices -> put_user;
	kvm_arm_copy_sys_reg_indices -> walk_sys_regs;
	kvm_arm_copy_sys_reg_indices -> sys_reg_to_index;
	write_demux_regids	[label="int write_demux_regids (u64 __user *uindices)
arch/arm64/kvm/sys_regs.c:3631"];
	kvm_arm_copy_sys_reg_indices -> write_demux_regids;
	write_demux_regids -> put_user;
	kvm_arm_vcpu_arch_set_attr -> mutex_lock;
	kvm_arm_vcpu_arch_set_attr -> mutex_unlock;
	kvm_arm_pmu_v3_set_attr	[label="int kvm_arm_pmu_v3_set_attr (struct kvm_vcpu *vcpu, struct kvm_device_attr *attr)
arch/arm64/kvm/pmu-emul.c:981"];
	kvm_arm_vcpu_arch_set_attr -> kvm_arm_pmu_v3_set_attr;
	kvm_arm_timer_set_attr	[label="int kvm_arm_timer_set_attr (struct kvm_vcpu *vcpu, struct kvm_device_attr *attr)
arch/arm64/kvm/arch_timer.c:1560"];
	kvm_arm_vcpu_arch_set_attr -> kvm_arm_timer_set_attr;
	kvm_arm_pvtime_set_attr	[label="int kvm_arm_pvtime_set_attr (struct kvm_vcpu *vcpu, struct kvm_device_attr *attr)
arch/arm64/kvm/pvtime.c:75"];
	kvm_arm_vcpu_arch_set_attr -> kvm_arm_pvtime_set_attr;
	kvm_arm_pmu_v3_set_attr -> irqchip_in_kernel;
	kvm_arm_pmu_v3_set_attr -> kvm_vcpu_has_pmu;
	kvm_arm_pmu_v3_set_attr -> kvm_debug;
	kvm_arm_pmu_v3_set_attr -> kvm_vm_has_ran_once;
	kvm_arm_pmu_v3_set_attr -> bitmap_clear;
	kvm_arm_pmu_v3_set_attr -> bitmap_zero;
	kvm_arm_pmu_v3_set_attr -> copy_from_user;
	kvm_arm_pmu_v3_set_attr -> lockdep_assert_held;
	kvm_arm_pmu_v3_set_attr -> kvm_arm_pmu_get_pmuver_limit;
	kvm_arm_pmu_v3_set_attr -> irq_is_ppi;
	kvm_arm_pmu_v3_set_attr -> kvm_arm_pmu_irq_initialized;
	kvm_arm_pmu_v3_set_attr -> get_user;
	irq_is_spi	[label="irq_is_spi()"];
	kvm_arm_pmu_v3_set_attr -> irq_is_spi;
	pmu_irq_is_valid	[label="bool pmu_irq_is_valid (struct kvm *kvm, int irq)
arch/arm64/kvm/pmu-emul.c:884"];
	kvm_arm_pmu_v3_set_attr -> pmu_irq_is_valid;
	bitmap_alloc	[label="bitmap_alloc()"];
	kvm_arm_pmu_v3_set_attr -> bitmap_alloc;
	bitmap_fill	[label="bitmap_fill()"];
	kvm_arm_pmu_v3_set_attr -> bitmap_fill;
	bitmap_set	[label="bitmap_set()"];
	kvm_arm_pmu_v3_set_attr -> bitmap_set;
	kvm_arm_pmu_v3_set_pmu	[label="int kvm_arm_pmu_v3_set_pmu (struct kvm_vcpu *vcpu, int pmu_id)
arch/arm64/kvm/pmu-emul.c:951"];
	kvm_arm_pmu_v3_set_attr -> kvm_arm_pmu_v3_set_pmu;
	kvm_arm_pmu_v3_init	[label="int kvm_arm_pmu_v3_init (struct kvm_vcpu *vcpu)
arch/arm64/kvm/pmu-emul.c:850"];
	kvm_arm_pmu_v3_set_attr -> kvm_arm_pmu_v3_init;
	kvm_arm_timer_set_attr -> irqchip_in_kernel;
	kvm_arm_timer_set_attr -> test_bit;
	kvm_arm_timer_set_attr -> mutex_lock;
	kvm_arm_timer_set_attr -> mutex_unlock;
	kvm_arm_timer_set_attr -> irq_is_ppi;
	kvm_arm_timer_set_attr -> get_user;
	kvm_arm_pvtime_set_attr -> srcu_read_lock;
	kvm_arm_pvtime_set_attr -> srcu_read_unlock;
	kvm_arm_pvtime_set_attr -> kvm_is_error_hva;
	kvm_arm_pvtime_set_attr -> IS_ALIGNED;
	kvm_arm_pvtime_set_attr -> kvm_arm_pvtime_supported;
	kvm_arm_pvtime_set_attr -> get_user;
	gfn_to_hva	[label="unsigned long gfn_to_hva (struct kvm *kvm, gfn_t gfn)
virt/kvm/kvm_main.c:2450"];
	kvm_arm_pvtime_set_attr -> gfn_to_hva;
	pmu_irq_is_valid -> kvm_for_each_vcpu;
	pmu_irq_is_valid -> irq_is_ppi;
	pmu_irq_is_valid -> kvm_arm_pmu_irq_initialized;
	kvm_arm_pmu_v3_set_pmu -> kvm_vm_has_ran_once;
	kvm_arm_pmu_v3_set_pmu -> mutex_lock;
	kvm_arm_pmu_v3_set_pmu -> mutex_unlock;
	kvm_arm_pmu_v3_set_pmu -> cpumask_copy;
	kvm_arm_pmu_v3_set_pmu -> lockdep_assert_held;
	kvm_arm_pmu_v3_set_pmu -> list_for_each_entry;
	kvm_arm_set_pmu	[label="void kvm_arm_set_pmu (struct kvm *kvm, struct arm_pmu *arm_pmu)
arch/arm64/kvm/pmu-emul.c:920"];
	kvm_arm_pmu_v3_set_pmu -> kvm_arm_set_pmu;
	kvm_arm_pmu_v3_init -> irqchip_in_kernel;
	kvm_arm_pmu_v3_init -> kvm_arm_pmu_irq_initialized;
	vgic_initialized	[label="vgic_initialized()"];
	kvm_arm_pmu_v3_init -> vgic_initialized;
	kvm_vgic_set_owner	[label="kvm_vgic_set_owner()"];
	kvm_arm_pmu_v3_init -> kvm_vgic_set_owner;
	init_irq_work	[label="init_irq_work()"];
	kvm_arm_pmu_v3_init -> init_irq_work;
	kvm_pmu_perf_overflow_notify_vcpu	[label="void kvm_pmu_perf_overflow_notify_vcpu (struct irq_work *work)
arch/arm64/kvm/pmu-emul.c:428"];
	kvm_arm_pmu_v3_init -> kvm_pmu_perf_overflow_notify_vcpu;
	kvm_arm_set_pmu -> lockdep_assert_held;
	kvm_arm_pmu_get_max_counters	[label="u8 kvm_arm_pmu_get_max_counters (struct kvm *kvm)
arch/arm64/kvm/pmu-emul.c:909"];
	kvm_arm_set_pmu -> kvm_arm_pmu_get_max_counters;
	kvm_pmu_perf_overflow_notify_vcpu -> container_of;
	kvm_pmu_perf_overflow_notify_vcpu -> kvm_vcpu_kick;
	gfn_to_hva -> gfn_to_memslot;
	gfn_to_hva -> gfn_to_hva_many;
	kvm_arm_pmu_v3_get_attr	[label="int kvm_arm_pmu_v3_get_attr (struct kvm_vcpu *vcpu, struct kvm_device_attr *attr)
arch/arm64/kvm/pmu-emul.c:1084"];
	kvm_arm_vcpu_arch_get_attr -> kvm_arm_pmu_v3_get_attr;
	kvm_arm_timer_get_attr	[label="int kvm_arm_timer_get_attr (struct kvm_vcpu *vcpu, struct kvm_device_attr *attr)
arch/arm64/kvm/arch_timer.c:1612"];
	kvm_arm_vcpu_arch_get_attr -> kvm_arm_timer_get_attr;
	kvm_arm_pvtime_get_attr	[label="int kvm_arm_pvtime_get_attr (struct kvm_vcpu *vcpu, struct kvm_device_attr *attr)
arch/arm64/kvm/pvtime.c:107"];
	kvm_arm_vcpu_arch_get_attr -> kvm_arm_pvtime_get_attr;
	kvm_arm_pmu_v3_get_attr -> irqchip_in_kernel;
	kvm_arm_pmu_v3_get_attr -> kvm_vcpu_has_pmu;
	kvm_arm_pmu_v3_get_attr -> kvm_arm_pmu_irq_initialized;
	kvm_arm_pmu_v3_get_attr -> put_user;
	kvm_arm_timer_get_attr -> vcpu_hvtimer;
	kvm_arm_timer_get_attr -> vcpu_hptimer;
	kvm_arm_timer_get_attr -> vcpu_vtimer;
	kvm_arm_timer_get_attr -> vcpu_ptimer;
	kvm_arm_timer_get_attr -> timer_irq;
	kvm_arm_timer_get_attr -> put_user;
	kvm_arm_pvtime_get_attr -> kvm_arm_pvtime_supported;
	kvm_arm_pvtime_get_attr -> put_user;
	kvm_arm_pmu_v3_has_attr	[label="int kvm_arm_pmu_v3_has_attr (struct kvm_vcpu *vcpu, struct kvm_device_attr *attr)
arch/arm64/kvm/pmu-emul.c:1108"];
	kvm_arm_vcpu_arch_has_attr -> kvm_arm_pmu_v3_has_attr;
	kvm_arm_timer_has_attr	[label="int kvm_arm_timer_has_attr (struct kvm_vcpu *vcpu, struct kvm_device_attr *attr)
arch/arm64/kvm/arch_timer.c:1639"];
	kvm_arm_vcpu_arch_has_attr -> kvm_arm_timer_has_attr;
	kvm_arm_pvtime_has_attr	[label="int kvm_arm_pvtime_has_attr (struct kvm_vcpu *vcpu, struct kvm_device_attr *attr)
arch/arm64/kvm/pvtime.c:124"];
	kvm_arm_vcpu_arch_has_attr -> kvm_arm_pvtime_has_attr;
	kvm_arm_pmu_v3_has_attr -> kvm_vcpu_has_pmu;
	kvm_arm_pvtime_has_attr -> kvm_arm_pvtime_supported;
	kvm_vcpu_finalize_sve -> WARN_ON;
	kvm_vcpu_finalize_sve -> kfree;
	kvm_vcpu_finalize_sve -> vcpu_set_flag;
	kvm_vcpu_finalize_sve -> sve_max_virtualisable_vl;
	kvm_vcpu_finalize_sve -> kzalloc;
	kvm_vcpu_finalize_sve -> vcpu_sve_state_size;
	kvm_vcpu_finalize_sve -> kvm_share_hyp;
	kvm_vcpu_finalize_sve -> sve_vl_valid;
}
