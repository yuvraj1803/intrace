// subgraph node: kvm_arm_init
// subgraph edge: kvm_arm_init->bool
// subgraph node: bool
// subgraph edge: kvm_arm_init->cpus_have_final_cap
// subgraph node: cpus_have_final_cap
// subgraph edge: kvm_arm_init->is_protected_kvm_enabled
// subgraph node: is_protected_kvm_enabled
// subgraph edge: kvm_arm_init->is_kernel_in_hyp_mode
// subgraph node: is_kernel_in_hyp_mode
// subgraph edge: kvm_arm_init->is_hyp_mode_available
// subgraph node: is_hyp_mode_available
// subgraph edge: kvm_arm_init->kvm_err
// subgraph node: kvm_err
// subgraph edge: kvm_arm_init->kvm_info
// subgraph node: kvm_info
// subgraph edge: kvm_arm_init->kvm_get_mode
// subgraph node: kvm_get_mode
// subgraph edge: kvm_arm_init->kvm_sys_reg_table_init
// subgraph node: kvm_sys_reg_table_init
// subgraph edge: kvm_sys_reg_table_init->bool
// subgraph edge: kvm_sys_reg_table_init->kvm_get_mode
// subgraph edge: kvm_sys_reg_table_init->check_sysreg_table
// subgraph node: check_sysreg_table
// subgraph edge: check_sysreg_table->kvm_err
// subgraph edge: check_sysreg_table->cmp_sys_reg
// subgraph node: cmp_sys_reg
// subgraph edge: kvm_sys_reg_table_init->ARRAY_SIZE
// subgraph node: ARRAY_SIZE
// subgraph edge: kvm_sys_reg_table_init->encoding_to_params
// subgraph node: encoding_to_params
// subgraph edge: kvm_sys_reg_table_init->find_reg
// subgraph node: find_reg
// subgraph edge: kvm_sys_reg_table_init->populate_nv_trap_config
// subgraph node: populate_nv_trap_config
// subgraph edge: populate_nv_trap_config->cpus_have_final_cap
// subgraph edge: populate_nv_trap_config->BIT
// subgraph node: BIT
// subgraph edge: populate_nv_trap_config->kvm_info
// subgraph edge: populate_nv_trap_config->ARRAY_SIZE
// subgraph edge: populate_nv_trap_config->BUILD_BUG_ON
// subgraph node: BUILD_BUG_ON
// subgraph edge: populate_nv_trap_config->xa_destroy
// subgraph node: xa_destroy
// subgraph edge: kvm_arm_init->kvm_set_ipa_limit
// subgraph node: kvm_set_ipa_limit
// subgraph edge: kvm_set_ipa_limit->read_sanitised_ftr_reg
// subgraph node: read_sanitised_ftr_reg
// subgraph edge: kvm_set_ipa_limit->kvm_debug
// subgraph node: kvm_debug
// subgraph edge: kvm_set_ipa_limit->min
// subgraph node: min
// subgraph edge: kvm_set_ipa_limit->kvm_err
// subgraph edge: kvm_set_ipa_limit->cpuid_feature_extract_unsigned_field
// subgraph node: cpuid_feature_extract_unsigned_field
// subgraph edge: kvm_set_ipa_limit->kvm_info
// subgraph edge: kvm_set_ipa_limit->id_aa64mmfr0_parange_to_phys_shift
// subgraph node: id_aa64mmfr0_parange_to_phys_shift
// subgraph edge: kvm_arm_init->kvm_arm_init_sve
// subgraph node: kvm_arm_init_sve
// subgraph edge: kvm_arm_init_sve->WARN_ON
// subgraph node: WARN_ON
// subgraph edge: kvm_arm_init_sve->system_supports_sve
// subgraph node: system_supports_sve
// subgraph edge: kvm_arm_init_sve->sve_max_virtualisable_vl
// subgraph node: sve_max_virtualisable_vl
// subgraph edge: kvm_arm_init_sve->sve_max_vl
// subgraph node: sve_max_vl
// subgraph edge: kvm_arm_init_sve->pr_warn
// subgraph node: pr_warn
// subgraph edge: kvm_arm_init->kvm_arm_vmid_alloc_init
// subgraph node: kvm_arm_vmid_alloc_init
// subgraph edge: kvm_arm_vmid_alloc_init->WARN_ON
// subgraph edge: kvm_arm_vmid_alloc_init->atomic64_set
// subgraph node: atomic64_set
// subgraph edge: kvm_arm_vmid_alloc_init->kvm_get_vmid_bits
// subgraph node: kvm_get_vmid_bits
// subgraph edge: kvm_arm_vmid_alloc_init->num_possible_cpus
// subgraph node: num_possible_cpus
// subgraph edge: kvm_arm_vmid_alloc_init->bitmap_zalloc
// subgraph node: bitmap_zalloc
// subgraph edge: kvm_arm_init->init_hyp_mode
// subgraph node: init_hyp_mode
// subgraph edge: init_hyp_mode->cpus_have_final_cap
// subgraph edge: init_hyp_mode->memcpy
// subgraph node: memcpy
// subgraph edge: init_hyp_mode->is_protected_kvm_enabled
// subgraph edge: init_hyp_mode->kvm_err
// subgraph edge: init_hyp_mode->teardown_hyp_mode
// subgraph node: teardown_hyp_mode
// subgraph edge: teardown_hyp_mode->for_each_possible_cpu
// subgraph node: for_each_possible_cpu
// subgraph edge: teardown_hyp_mode->per_cpu
// subgraph node: per_cpu
// subgraph edge: teardown_hyp_mode->nvhe_percpu_order
// subgraph node: nvhe_percpu_order
// subgraph edge: nvhe_percpu_order->nvhe_percpu_size
// subgraph node: nvhe_percpu_size
// subgraph edge: nvhe_percpu_size->CHOOSE_NVHE_SYM
// subgraph node: CHOOSE_NVHE_SYM
// subgraph edge: nvhe_percpu_order->get_order
// subgraph node: get_order
// subgraph edge: teardown_hyp_mode->kvm_nvhe_sym
// subgraph node: kvm_nvhe_sym
// subgraph edge: teardown_hyp_mode->free_hyp_pgds
// subgraph node: free_hyp_pgds
// subgraph edge: free_hyp_pgds->kfree
// subgraph node: kfree
// subgraph edge: free_hyp_pgds->mutex_lock
// subgraph node: mutex_lock
// subgraph edge: free_hyp_pgds->mutex_unlock
// subgraph node: mutex_unlock
// subgraph edge: free_hyp_pgds->kvm_pgtable_hyp_destroy
// subgraph node: kvm_pgtable_hyp_destroy
// subgraph edge: teardown_hyp_mode->free_page
// subgraph node: free_page
// subgraph edge: teardown_hyp_mode->free_pages
// subgraph node: free_pages
// subgraph edge: init_hyp_mode->kvm_mmu_init
// subgraph node: kvm_mmu_init
// subgraph edge: kvm_mmu_init->BUG_ON
// subgraph node: BUG_ON
// subgraph edge: kvm_mmu_init->kvm_debug
// subgraph edge: kvm_mmu_init->kfree
// subgraph edge: kvm_mmu_init->kvm_err
// subgraph edge: kvm_mmu_init->ALIGN_DOWN
// subgraph node: ALIGN_DOWN
// subgraph edge: kvm_mmu_init->ALIGN
// subgraph node: ALIGN
// subgraph edge: kvm_mmu_init->max
// subgraph node: max
// subgraph edge: kvm_mmu_init->kern_hyp_va
// subgraph node: kern_hyp_va
// subgraph edge: kvm_mmu_init->kzalloc
// subgraph node: kzalloc
// subgraph edge: kvm_mmu_init->kvm_pgtable_hyp_init
// subgraph node: kvm_pgtable_hyp_init
// subgraph edge: kvm_mmu_init->kvm_map_idmap_text
// subgraph node: kvm_map_idmap_text
// subgraph edge: kvm_map_idmap_text->kvm_err
// subgraph edge: kvm_mmu_init->kvm_pgtable_hyp_destroy
// subgraph edge: init_hyp_mode->for_each_possible_cpu
// subgraph edge: init_hyp_mode->per_cpu
// subgraph edge: init_hyp_mode->alloc_pages
// subgraph node: alloc_pages
// subgraph edge: init_hyp_mode->nvhe_percpu_order
// subgraph edge: init_hyp_mode->page_address
// subgraph node: page_address
// subgraph edge: init_hyp_mode->CHOOSE_NVHE_SYM
// subgraph edge: init_hyp_mode->nvhe_percpu_size
// subgraph edge: init_hyp_mode->kvm_nvhe_sym
// subgraph edge: init_hyp_mode->create_hyp_mappings
// subgraph node: create_hyp_mappings
// subgraph edge: create_hyp_mappings->is_kernel_in_hyp_mode
// subgraph edge: create_hyp_mappings->kern_hyp_va
// subgraph edge: create_hyp_mappings->kvm_host_owns_hyp_mappings
// subgraph node: kvm_host_owns_hyp_mappings
// subgraph edge: kvm_host_owns_hyp_mappings->WARN_ON
// subgraph edge: kvm_host_owns_hyp_mappings->is_protected_kvm_enabled
// subgraph edge: kvm_host_owns_hyp_mappings->is_kernel_in_hyp_mode
// subgraph edge: kvm_host_owns_hyp_mappings->static_branch_likely
// subgraph node: static_branch_likely
// subgraph edge: create_hyp_mappings->PAGE_ALIGN
// subgraph node: PAGE_ALIGN
// subgraph edge: create_hyp_mappings->kvm_kaddr_to_phys
// subgraph node: kvm_kaddr_to_phys
// subgraph edge: kvm_kaddr_to_phys->BUG_ON
// subgraph edge: kvm_kaddr_to_phys->is_vmalloc_addr
// subgraph node: is_vmalloc_addr
// subgraph edge: kvm_kaddr_to_phys->virt_addr_valid
// subgraph node: virt_addr_valid
// subgraph edge: kvm_kaddr_to_phys->page_to_phys
// subgraph node: page_to_phys
// subgraph edge: kvm_kaddr_to_phys->vmalloc_to_page
// subgraph node: vmalloc_to_page
// subgraph edge: kvm_kaddr_to_phys->offset_in_page
// subgraph node: offset_in_page
// subgraph edge: init_hyp_mode->kvm_ksym_ref
// subgraph node: kvm_ksym_ref
// subgraph edge: init_hyp_mode->per_cpu_ptr_nvhe_sym
// subgraph node: per_cpu_ptr_nvhe_sym
// subgraph edge: init_hyp_mode->create_hyp_stack
// subgraph node: create_hyp_stack
// subgraph edge: create_hyp_stack->mutex_lock
// subgraph edge: create_hyp_stack->mutex_unlock
// subgraph edge: create_hyp_stack->kvm_err
// subgraph edge: create_hyp_stack->ALIGN_DOWN
// subgraph edge: init_hyp_mode->cpu_prepare_hyp_mode
// subgraph node: cpu_prepare_hyp_mode
// subgraph edge: cpu_prepare_hyp_mode->cpus_have_final_cap
// subgraph edge: cpu_prepare_hyp_mode->read_sysreg
// subgraph node: read_sysreg
// subgraph edge: cpu_prepare_hyp_mode->is_protected_kvm_enabled
// subgraph edge: cpu_prepare_hyp_mode->CHOOSE_NVHE_SYM
// subgraph edge: cpu_prepare_hyp_mode->kvm_ksym_ref
// subgraph edge: cpu_prepare_hyp_mode->per_cpu_ptr_nvhe_sym
// subgraph edge: cpu_prepare_hyp_mode->kasan_reset_tag
// subgraph node: kasan_reset_tag
// subgraph edge: cpu_prepare_hyp_mode->TCR_T0SZ
// subgraph node: TCR_T0SZ
// subgraph edge: cpu_prepare_hyp_mode->kvm_mmu_get_httbr
// subgraph node: kvm_mmu_get_httbr
// subgraph edge: cpu_prepare_hyp_mode->kvm_flush_dcache_to_poc
// subgraph node: kvm_flush_dcache_to_poc
// subgraph edge: init_hyp_mode->kvm_hyp_init_symbols
// subgraph node: kvm_hyp_init_symbols
// subgraph edge: kvm_hyp_init_symbols->read_sanitised_ftr_reg
// subgraph edge: kvm_hyp_init_symbols->kvm_nvhe_sym
// subgraph edge: kvm_hyp_init_symbols->get_hyp_id_aa64pfr0_el1
// subgraph node: get_hyp_id_aa64pfr0_el1
// subgraph edge: get_hyp_id_aa64pfr0_el1->read_sanitised_ftr_reg
// subgraph edge: get_hyp_id_aa64pfr0_el1->FIELD_PREP
// subgraph node: FIELD_PREP
// subgraph edge: get_hyp_id_aa64pfr0_el1->arm64_get_spectre_v2_state
// subgraph node: arm64_get_spectre_v2_state
// subgraph edge: get_hyp_id_aa64pfr0_el1->ARM64_FEATURE_MASK
// subgraph node: ARM64_FEATURE_MASK
// subgraph edge: get_hyp_id_aa64pfr0_el1->arm64_get_meltdown_state
// subgraph node: arm64_get_meltdown_state
// subgraph edge: init_hyp_mode->IS_ENABLED
// subgraph node: IS_ENABLED
// subgraph edge: init_hyp_mode->pkvm_hyp_init_ptrauth
// subgraph node: pkvm_hyp_init_ptrauth
// subgraph edge: pkvm_hyp_init_ptrauth->get_random_long
// subgraph node: get_random_long
// subgraph edge: pkvm_hyp_init_ptrauth->for_each_possible_cpu
// subgraph edge: pkvm_hyp_init_ptrauth->per_cpu_ptr_nvhe_sym
// subgraph edge: init_hyp_mode->init_cpu_logical_map
// subgraph node: init_cpu_logical_map
// subgraph edge: init_cpu_logical_map->for_each_online_cpu
// subgraph node: for_each_online_cpu
// subgraph edge: init_cpu_logical_map->cpu_logical_map
// subgraph node: cpu_logical_map
// subgraph edge: init_hyp_mode->init_psci_relay
// subgraph node: init_psci_relay
// subgraph edge: init_psci_relay->kvm_err
// subgraph edge: init_psci_relay->arm_smccc_get_version
// subgraph node: arm_smccc_get_version
// subgraph edge: init_psci_relay->PSCI_VERSION
// subgraph node: PSCI_VERSION
// subgraph edge: init_psci_relay->get_psci_0_1_function_ids
// subgraph node: get_psci_0_1_function_ids
// subgraph edge: init_psci_relay->init_psci_0_1_impl_state
// subgraph node: init_psci_0_1_impl_state
// subgraph edge: init_hyp_mode->kvm_hyp_init_protection
// subgraph node: kvm_hyp_init_protection
// subgraph edge: kvm_hyp_init_protection->create_hyp_mappings
// subgraph edge: kvm_hyp_init_protection->phys_to_virt
// subgraph node: phys_to_virt
// subgraph edge: kvm_hyp_init_protection->do_pkvm_init
// subgraph node: do_pkvm_init
// subgraph edge: do_pkvm_init->preempt_disable
// subgraph node: preempt_disable
// subgraph edge: do_pkvm_init->preempt_enable
// subgraph node: preempt_enable
// subgraph edge: do_pkvm_init->cpu_hyp_init_context
// subgraph node: cpu_hyp_init_context
// subgraph edge: cpu_hyp_init_context->is_kernel_in_hyp_mode
// subgraph edge: cpu_hyp_init_context->kvm_init_host_cpu_context
// subgraph node: kvm_init_host_cpu_context
// subgraph edge: cpu_hyp_init_context->this_cpu_ptr_hyp_sym
// subgraph node: this_cpu_ptr_hyp_sym
// subgraph edge: cpu_hyp_init_context->cpu_init_hyp_mode
// subgraph node: cpu_init_hyp_mode
// subgraph edge: cpu_init_hyp_mode->arm64_get_spectre_v4_state
// subgraph node: arm64_get_spectre_v4_state
// subgraph edge: cpu_init_hyp_mode->hyp_install_host_vector
// subgraph node: hyp_install_host_vector
// subgraph edge: hyp_install_host_vector->WARN_ON
// subgraph edge: hyp_install_host_vector->BUG_ON
// subgraph edge: hyp_install_host_vector->kvm_get_idmap_vector
// subgraph node: kvm_get_idmap_vector
// subgraph edge: hyp_install_host_vector->system_capabilities_finalized
// subgraph node: system_capabilities_finalized
// subgraph edge: hyp_install_host_vector->this_cpu_ptr_nvhe_sym
// subgraph node: this_cpu_ptr_nvhe_sym
// subgraph edge: hyp_install_host_vector->arm_smccc_1_1_hvc
// subgraph node: arm_smccc_1_1_hvc
// subgraph edge: hyp_install_host_vector->KVM_HOST_SMCCC_FUNC
// subgraph node: KVM_HOST_SMCCC_FUNC
// subgraph edge: hyp_install_host_vector->virt_to_phys
// subgraph node: virt_to_phys
// subgraph edge: cpu_init_hyp_mode->this_cpu_has_cap
// subgraph node: this_cpu_has_cap
// subgraph edge: cpu_init_hyp_mode->kvm_call_hyp_nvhe
// subgraph node: kvm_call_hyp_nvhe
// subgraph edge: do_pkvm_init->cpu_hyp_init_features
// subgraph node: cpu_hyp_init_features
// subgraph edge: cpu_hyp_init_features->is_kernel_in_hyp_mode
// subgraph edge: cpu_hyp_init_features->cpu_set_hyp_vector
// subgraph node: cpu_set_hyp_vector
// subgraph edge: cpu_set_hyp_vector->this_cpu_ptr
// subgraph node: this_cpu_ptr
// subgraph edge: cpu_set_hyp_vector->is_protected_kvm_enabled
// subgraph edge: cpu_set_hyp_vector->this_cpu_ptr_hyp_sym
// subgraph edge: cpu_set_hyp_vector->kvm_call_hyp_nvhe
// subgraph edge: cpu_hyp_init_features->kvm_arm_init_debug
// subgraph node: kvm_arm_init_debug
// subgraph edge: kvm_arm_init_debug->kvm_call_hyp_ret
// subgraph node: kvm_call_hyp_ret
// subgraph edge: cpu_hyp_init_features->kvm_timer_init_vhe
// subgraph node: kvm_timer_init_vhe
// subgraph edge: kvm_timer_init_vhe->cpus_have_final_cap
// subgraph edge: kvm_timer_init_vhe->sysreg_clear_set
// subgraph node: sysreg_clear_set
// subgraph edge: cpu_hyp_init_features->kvm_vgic_init_cpu_hardware
// subgraph node: kvm_vgic_init_cpu_hardware
// subgraph edge: do_pkvm_init->kvm_call_hyp_nvhe
// subgraph edge: do_pkvm_init->num_possible_cpus
// subgraph edge: do_pkvm_init->kvm_nvhe_sym
// subgraph edge: do_pkvm_init->kvm_ksym_ref
// subgraph edge: do_pkvm_init->kern_hyp_va
// subgraph edge: kvm_hyp_init_protection->free_hyp_pgds
// subgraph edge: kvm_arm_init->kvm_init_vector_slots
// subgraph node: kvm_init_vector_slots
// subgraph edge: kvm_init_vector_slots->is_protected_kvm_enabled
// subgraph edge: kvm_init_vector_slots->kvm_ksym_ref
// subgraph edge: kvm_init_vector_slots->kern_hyp_va
// subgraph edge: kvm_init_vector_slots->kvm_init_vector_slot
// subgraph node: kvm_init_vector_slot
// subgraph edge: kvm_init_vector_slots->kvm_system_needs_idmapped_vectors
// subgraph node: kvm_system_needs_idmapped_vectors
// subgraph edge: kvm_init_vector_slots->create_hyp_exec_mappings
// subgraph node: create_hyp_exec_mappings
// subgraph edge: create_hyp_exec_mappings->BUG_ON
// subgraph edge: create_hyp_exec_mappings->is_kernel_in_hyp_mode
// subgraph edge: kvm_arm_init->init_subsystems
// subgraph node: init_subsystems
// subgraph edge: init_subsystems->is_protected_kvm_enabled
// subgraph edge: init_subsystems->on_each_cpu
// subgraph node: on_each_cpu
// subgraph edge: init_subsystems->cpu_hyp_init
// subgraph node: cpu_hyp_init
// subgraph edge: cpu_hyp_init->cpu_hyp_reinit
// subgraph node: cpu_hyp_reinit
// subgraph edge: cpu_hyp_reinit->cpu_hyp_reset
// subgraph node: cpu_hyp_reset
// subgraph edge: cpu_hyp_reset->is_kernel_in_hyp_mode
// subgraph edge: cpu_hyp_reinit->cpu_hyp_init_context
// subgraph edge: cpu_hyp_reinit->cpu_hyp_init_features
// subgraph edge: init_subsystems->hyp_cpu_pm_init
// subgraph node: hyp_cpu_pm_init
// subgraph edge: hyp_cpu_pm_init->is_protected_kvm_enabled
// subgraph edge: hyp_cpu_pm_init->cpu_pm_register_notifier
// subgraph node: cpu_pm_register_notifier
// subgraph edge: init_subsystems->kvm_vgic_hyp_init
// subgraph node: kvm_vgic_hyp_init
// subgraph edge: init_subsystems->kvm_timer_hyp_init
// subgraph node: kvm_timer_hyp_init
// subgraph edge: kvm_timer_hyp_init->has_vhe
// subgraph node: has_vhe
// subgraph edge: kvm_timer_hyp_init->kvm_debug
// subgraph edge: kvm_timer_hyp_init->static_branch_enable
// subgraph node: static_branch_enable
// subgraph edge: kvm_timer_hyp_init->kvm_err
// subgraph edge: kvm_timer_hyp_init->arch_timer_get_kvm_info
// subgraph node: arch_timer_get_kvm_info
// subgraph edge: kvm_timer_hyp_init->kvm_irq_init
// subgraph node: kvm_irq_init
// subgraph edge: kvm_irq_init->WARN_ON
// subgraph edge: kvm_irq_init->kvm_err
// subgraph edge: kvm_irq_init->kvm_irq_fixup_flags
// subgraph node: kvm_irq_fixup_flags
// subgraph edge: kvm_irq_fixup_flags->kvm_err
// subgraph edge: kvm_irq_fixup_flags->irq_get_trigger_type
// subgraph node: irq_get_trigger_type
// subgraph edge: kvm_irq_init->irq_domain_alloc_named_fwnode
// subgraph node: irq_domain_alloc_named_fwnode
// subgraph edge: kvm_irq_init->irq_get_irq_data
// subgraph node: irq_get_irq_data
// subgraph edge: kvm_irq_init->irq_domain_create_hierarchy
// subgraph node: irq_domain_create_hierarchy
// subgraph edge: kvm_irq_init->irq_domain_free_fwnode
// subgraph node: irq_domain_free_fwnode
// subgraph edge: kvm_irq_init->irq_domain_push_irq
// subgraph node: irq_domain_push_irq
// subgraph edge: kvm_timer_hyp_init->request_percpu_irq
// subgraph node: request_percpu_irq
// subgraph edge: kvm_timer_hyp_init->kvm_arch_timer_handler
// subgraph node: kvm_arch_timer_handler
// subgraph edge: kvm_arch_timer_handler->get_timer_map
// subgraph node: get_timer_map
// subgraph edge: get_timer_map->vcpu_has_nv
// subgraph node: vcpu_has_nv
// subgraph edge: get_timer_map->is_hyp_ctxt
// subgraph node: is_hyp_ctxt
// subgraph edge: get_timer_map->vcpu_hvtimer
// subgraph node: vcpu_hvtimer
// subgraph edge: get_timer_map->vcpu_hptimer
// subgraph node: vcpu_hptimer
// subgraph edge: get_timer_map->vcpu_vtimer
// subgraph node: vcpu_vtimer
// subgraph edge: get_timer_map->vcpu_ptimer
// subgraph node: vcpu_ptimer
// subgraph edge: get_timer_map->has_vhe
// subgraph edge: get_timer_map->trace_kvm_get_timer_map
// subgraph node: trace_kvm_get_timer_map
// subgraph edge: kvm_arch_timer_handler->kvm_timer_should_fire
// subgraph node: kvm_timer_should_fire
// subgraph edge: kvm_timer_should_fire->kvm_phys_timer_read
// subgraph node: kvm_phys_timer_read
// subgraph edge: kvm_timer_should_fire->timer_get_offset
// subgraph node: timer_get_offset
// subgraph edge: kvm_timer_should_fire->arch_timer_ctx_index
// subgraph node: arch_timer_ctx_index
// subgraph edge: kvm_timer_should_fire->kvm_timer_irq_can_fire
// subgraph node: kvm_timer_irq_can_fire
// subgraph edge: kvm_timer_irq_can_fire->WARN_ON
// subgraph edge: kvm_timer_irq_can_fire->timer_get_ctl
// subgraph node: timer_get_ctl
// subgraph edge: timer_get_ctl->arch_timer_ctx_index
// subgraph edge: timer_get_ctl->WARN_ON
// subgraph edge: kvm_timer_should_fire->read_sysreg_el0
// subgraph node: read_sysreg_el0
// subgraph edge: kvm_timer_should_fire->timer_get_cval
// subgraph node: timer_get_cval
// subgraph edge: timer_get_cval->arch_timer_ctx_index
// subgraph edge: timer_get_cval->WARN_ON
// subgraph edge: kvm_arch_timer_handler->kvm_timer_update_irq
// subgraph node: kvm_timer_update_irq
// subgraph edge: kvm_timer_update_irq->WARN_ON
// subgraph edge: kvm_timer_update_irq->trace_kvm_timer_update_irq
// subgraph node: trace_kvm_timer_update_irq
// subgraph edge: kvm_timer_update_irq->timer_irq
// subgraph node: timer_irq
// subgraph edge: kvm_timer_update_irq->userspace_irqchip
// subgraph node: userspace_irqchip
// subgraph edge: userspace_irqchip->static_branch_unlikely
// subgraph node: static_branch_unlikely
// subgraph edge: userspace_irqchip->unlikely
// subgraph node: unlikely
// subgraph edge: userspace_irqchip->irqchip_in_kernel
// subgraph node: irqchip_in_kernel
// subgraph edge: kvm_timer_update_irq->kvm_vgic_inject_irq
// subgraph node: kvm_vgic_inject_irq
// subgraph edge: kvm_arch_timer_handler->userspace_irqchip
// subgraph edge: kvm_arch_timer_handler->static_branch_unlikely
// subgraph edge: kvm_arch_timer_handler->disable_percpu_irq
// subgraph node: disable_percpu_irq
// subgraph edge: kvm_timer_hyp_init->kvm_get_running_vcpus
// subgraph node: kvm_get_running_vcpus
// subgraph edge: kvm_timer_hyp_init->irq_set_vcpu_affinity
// subgraph node: irq_set_vcpu_affinity
// subgraph edge: kvm_timer_hyp_init->free_percpu_irq
// subgraph node: free_percpu_irq
// subgraph edge: init_subsystems->kvm_register_perf_callbacks
// subgraph node: kvm_register_perf_callbacks
// subgraph edge: kvm_register_perf_callbacks->perf_register_guest_info_callbacks
// subgraph node: perf_register_guest_info_callbacks
// subgraph edge: init_subsystems->hyp_cpu_pm_exit
// subgraph node: hyp_cpu_pm_exit
// subgraph edge: hyp_cpu_pm_exit->is_protected_kvm_enabled
// subgraph edge: hyp_cpu_pm_exit->cpu_pm_unregister_notifier
// subgraph node: cpu_pm_unregister_notifier
// subgraph edge: init_subsystems->cpu_hyp_uninit
// subgraph node: cpu_hyp_uninit
// subgraph edge: cpu_hyp_uninit->cpu_hyp_reset
// subgraph edge: kvm_arm_init->kvm_init
// subgraph node: kvm_init
// subgraph edge: kvm_init->pr_err
// subgraph node: pr_err
// subgraph edge: kvm_init->WARN_ON_ONCE
// subgraph node: WARN_ON_ONCE
// subgraph edge: kvm_init->for_each_possible_cpu
// subgraph edge: kvm_init->per_cpu
// subgraph edge: kvm_init->cpuhp_setup_state_nocalls
// subgraph node: cpuhp_setup_state_nocalls
// subgraph edge: kvm_init->kvm_online_cpu
// subgraph node: kvm_online_cpu
// subgraph edge: kvm_online_cpu->mutex_lock
// subgraph edge: kvm_online_cpu->mutex_unlock
// subgraph edge: kvm_init->kvm_offline_cpu
// subgraph node: kvm_offline_cpu
// subgraph edge: kvm_offline_cpu->mutex_lock
// subgraph edge: kvm_offline_cpu->mutex_unlock
// subgraph edge: kvm_offline_cpu->hardware_disable_nolock
// subgraph node: hardware_disable_nolock
// subgraph edge: hardware_disable_nolock->kvm_arch_hardware_disable
// subgraph node: kvm_arch_hardware_disable
// subgraph edge: kvm_arch_hardware_disable->is_protected_kvm_enabled
// subgraph edge: kvm_arch_hardware_disable->cpu_hyp_uninit
// subgraph edge: kvm_arch_hardware_disable->kvm_timer_cpu_down
// subgraph node: kvm_timer_cpu_down
// subgraph edge: kvm_timer_cpu_down->disable_percpu_irq
// subgraph edge: kvm_arch_hardware_disable->kvm_vgic_cpu_down
// subgraph node: kvm_vgic_cpu_down
// subgraph edge: kvm_init->register_syscore_ops
// subgraph node: register_syscore_ops
// subgraph edge: kvm_init->kmem_cache_create_usercopy
// subgraph node: kmem_cache_create_usercopy
// subgraph edge: kvm_init->offsetof
// subgraph node: offsetof
// subgraph edge: kvm_init->offsetofend
// subgraph node: offsetofend
// subgraph edge: kvm_init->alloc_cpumask_var_node
// subgraph node: alloc_cpumask_var_node
// subgraph edge: kvm_init->cpu_to_node
// subgraph node: cpu_to_node
// subgraph edge: kvm_init->kvm_irqfd_init
// subgraph node: kvm_irqfd_init
// subgraph edge: kvm_irqfd_init->alloc_workqueue
// subgraph node: alloc_workqueue
// subgraph edge: kvm_init->kvm_async_pf_init
// subgraph node: kvm_async_pf_init
// subgraph edge: kvm_async_pf_init->KMEM_CACHE
// subgraph node: KMEM_CACHE
// subgraph edge: kvm_init->kvm_sched_in
// subgraph node: kvm_sched_in
// subgraph edge: kvm_sched_in->WRITE_ONCE
// subgraph node: WRITE_ONCE
// subgraph edge: kvm_sched_in->kvm_arch_vcpu_load
// subgraph node: kvm_arch_vcpu_load
// subgraph edge: kvm_arch_vcpu_load->has_vhe
// subgraph edge: kvm_arch_vcpu_load->kvm_call_hyp
// subgraph node: kvm_call_hyp
// subgraph edge: kvm_arch_vcpu_load->kvm_vcpu_pmu_restore_guest
// subgraph node: kvm_vcpu_pmu_restore_guest
// subgraph edge: kvm_vcpu_pmu_restore_guest->preempt_disable
// subgraph edge: kvm_vcpu_pmu_restore_guest->preempt_enable
// subgraph edge: kvm_vcpu_pmu_restore_guest->has_vhe
// subgraph edge: kvm_vcpu_pmu_restore_guest->kvm_arm_support_pmu_v3
// subgraph node: kvm_arm_support_pmu_v3
// subgraph edge: kvm_vcpu_pmu_restore_guest->kvm_get_pmu_events
// subgraph node: kvm_get_pmu_events
// subgraph edge: kvm_get_pmu_events->this_cpu_ptr
// subgraph edge: kvm_vcpu_pmu_restore_guest->kvm_vcpu_pmu_enable_el0
// subgraph node: kvm_vcpu_pmu_enable_el0
// subgraph edge: kvm_vcpu_pmu_enable_el0->for_each_set_bit
// subgraph node: for_each_set_bit
// subgraph edge: kvm_vcpu_pmu_enable_el0->kvm_vcpu_pmu_read_evtype_direct
// subgraph node: kvm_vcpu_pmu_read_evtype_direct
// subgraph edge: kvm_vcpu_pmu_read_evtype_direct->WARN_ON
// subgraph edge: kvm_vcpu_pmu_read_evtype_direct->read_sysreg
// subgraph edge: kvm_vcpu_pmu_read_evtype_direct->PMEVTYPER_CASES
// subgraph node: PMEVTYPER_CASES
// subgraph edge: kvm_vcpu_pmu_enable_el0->kvm_vcpu_pmu_write_evtype_direct
// subgraph node: kvm_vcpu_pmu_write_evtype_direct
// subgraph edge: kvm_vcpu_pmu_write_evtype_direct->WARN_ON
// subgraph edge: kvm_vcpu_pmu_write_evtype_direct->PMEVTYPER_CASES
// subgraph edge: kvm_vcpu_pmu_write_evtype_direct->write_sysreg
// subgraph node: write_sysreg
// subgraph edge: kvm_vcpu_pmu_restore_guest->kvm_vcpu_pmu_disable_el0
// subgraph node: kvm_vcpu_pmu_disable_el0
// subgraph edge: kvm_vcpu_pmu_disable_el0->for_each_set_bit
// subgraph edge: kvm_vcpu_pmu_disable_el0->kvm_vcpu_pmu_read_evtype_direct
// subgraph edge: kvm_vcpu_pmu_disable_el0->kvm_vcpu_pmu_write_evtype_direct
// subgraph edge: kvm_arch_vcpu_load->kvm_make_request
// subgraph node: kvm_make_request
// subgraph edge: kvm_arch_vcpu_load->this_cpu_ptr
// subgraph edge: kvm_arch_vcpu_load->kvm_vgic_load
// subgraph node: kvm_vgic_load
// subgraph edge: kvm_arch_vcpu_load->kvm_timer_vcpu_load
// subgraph node: kvm_timer_vcpu_load
// subgraph edge: kvm_timer_vcpu_load->vcpu_has_nv
// subgraph edge: kvm_timer_vcpu_load->get_timer_map
// subgraph edge: kvm_timer_vcpu_load->timer_emulate
// subgraph node: timer_emulate
// subgraph edge: timer_emulate->bool
// subgraph edge: timer_emulate->kvm_timer_should_fire
// subgraph edge: timer_emulate->trace_kvm_timer_emulate
// subgraph node: trace_kvm_timer_emulate
// subgraph edge: timer_emulate->kvm_timer_update_irq
// subgraph edge: timer_emulate->kvm_timer_irq_can_fire
// subgraph edge: timer_emulate->soft_timer_start
// subgraph node: soft_timer_start
// subgraph edge: soft_timer_start->hrtimer_start
// subgraph node: hrtimer_start
// subgraph edge: soft_timer_start->ktime_add_ns
// subgraph node: ktime_add_ns
// subgraph edge: soft_timer_start->ktime_get
// subgraph node: ktime_get
// subgraph edge: timer_emulate->kvm_timer_compute_delta
// subgraph node: kvm_timer_compute_delta
// subgraph edge: kvm_timer_compute_delta->timer_get_cval
// subgraph edge: kvm_timer_compute_delta->kvm_counter_compute_delta
// subgraph node: kvm_counter_compute_delta
// subgraph edge: kvm_counter_compute_delta->kvm_phys_timer_read
// subgraph edge: kvm_counter_compute_delta->timer_get_offset
// subgraph edge: kvm_counter_compute_delta->cyclecounter_cyc2ns
// subgraph node: cyclecounter_cyc2ns
// subgraph edge: kvm_timer_vcpu_load->timer_restore_state
// subgraph node: timer_restore_state
// subgraph edge: timer_restore_state->BUG
// subgraph node: BUG
// subgraph edge: timer_restore_state->timer_get_offset
// subgraph edge: timer_restore_state->arch_timer_ctx_index
// subgraph edge: timer_restore_state->timer_get_cval
// subgraph edge: timer_restore_state->timer_get_ctl
// subgraph edge: timer_restore_state->vcpu_timer
// subgraph node: vcpu_timer
// subgraph edge: timer_restore_state->local_irq_save
// subgraph node: local_irq_save
// subgraph edge: timer_restore_state->write_sysreg_el0
// subgraph node: write_sysreg_el0
// subgraph edge: timer_restore_state->isb
// subgraph node: isb
// subgraph edge: timer_restore_state->set_cntvoff
// subgraph node: set_cntvoff
// subgraph edge: set_cntvoff->kvm_call_hyp
// subgraph edge: timer_restore_state->set_cntpoff
// subgraph node: set_cntpoff
// subgraph edge: set_cntpoff->has_cntpoff
// subgraph node: has_cntpoff
// subgraph edge: set_cntpoff->write_sysreg_s
// subgraph node: write_sysreg_s
// subgraph edge: timer_restore_state->local_irq_restore
// subgraph node: local_irq_restore
// subgraph edge: timer_restore_state->trace_kvm_timer_restore_state
// subgraph node: trace_kvm_timer_restore_state
// subgraph edge: kvm_timer_vcpu_load->unlikely
// subgraph edge: kvm_timer_vcpu_load->vcpu_timer
// subgraph edge: kvm_timer_vcpu_load->static_branch_likely
// subgraph edge: kvm_timer_vcpu_load->kvm_timer_vcpu_load_nested_switch
// subgraph node: kvm_timer_vcpu_load_nested_switch
// subgraph edge: kvm_timer_vcpu_load_nested_switch->vcpu_hvtimer
// subgraph edge: kvm_timer_vcpu_load_nested_switch->timer_irq
// subgraph edge: kvm_timer_vcpu_load_nested_switch->irqchip_in_kernel
// subgraph edge: kvm_timer_vcpu_load_nested_switch->vcpu_el2_e2h_is_set
// subgraph node: vcpu_el2_e2h_is_set
// subgraph edge: kvm_timer_vcpu_load_nested_switch->WARN_ON_ONCE
// subgraph edge: kvm_timer_vcpu_load_nested_switch->kvm_vgic_get_map
// subgraph node: kvm_vgic_get_map
// subgraph edge: kvm_timer_vcpu_load_nested_switch->kvm_vgic_unmap_phys_irq
// subgraph node: kvm_vgic_unmap_phys_irq
// subgraph edge: kvm_timer_vcpu_load_nested_switch->kvm_vgic_map_phys_irq
// subgraph node: kvm_vgic_map_phys_irq
// subgraph edge: kvm_timer_vcpu_load->kvm_timer_vcpu_load_gic
// subgraph node: kvm_timer_vcpu_load_gic
// subgraph edge: kvm_timer_vcpu_load_gic->bool
// subgraph edge: kvm_timer_vcpu_load_gic->kvm_timer_should_fire
// subgraph edge: kvm_timer_vcpu_load_gic->kvm_timer_update_irq
// subgraph edge: kvm_timer_vcpu_load_gic->timer_irq
// subgraph edge: kvm_timer_vcpu_load_gic->irqchip_in_kernel
// subgraph edge: kvm_timer_vcpu_load_gic->kvm_vgic_map_is_active
// subgraph node: kvm_vgic_map_is_active
// subgraph edge: kvm_timer_vcpu_load_gic->set_timer_irq_phys_active
// subgraph node: set_timer_irq_phys_active
// subgraph edge: set_timer_irq_phys_active->WARN_ON
// subgraph edge: set_timer_irq_phys_active->irq_set_irqchip_state
// subgraph node: irq_set_irqchip_state
// subgraph edge: kvm_timer_vcpu_load->kvm_timer_vcpu_load_nogic
// subgraph node: kvm_timer_vcpu_load_nogic
// subgraph edge: kvm_timer_vcpu_load_nogic->vcpu_vtimer
// subgraph edge: kvm_timer_vcpu_load_nogic->kvm_timer_should_fire
// subgraph edge: kvm_timer_vcpu_load_nogic->kvm_timer_update_irq
// subgraph edge: kvm_timer_vcpu_load_nogic->disable_percpu_irq
// subgraph edge: kvm_timer_vcpu_load_nogic->enable_percpu_irq
// subgraph node: enable_percpu_irq
// subgraph edge: kvm_timer_vcpu_load->kvm_timer_unblocking
// subgraph node: kvm_timer_unblocking
// subgraph edge: kvm_timer_unblocking->soft_timer_cancel
// subgraph node: soft_timer_cancel
// subgraph edge: soft_timer_cancel->hrtimer_cancel
// subgraph node: hrtimer_cancel
// subgraph edge: kvm_timer_unblocking->vcpu_timer
// subgraph edge: kvm_timer_vcpu_load->timer_set_traps
// subgraph node: timer_set_traps
// subgraph edge: timer_set_traps->vcpu_has_nv
// subgraph edge: timer_set_traps->is_hyp_ctxt
// subgraph edge: timer_set_traps->has_vhe
// subgraph edge: timer_set_traps->timer_get_offset
// subgraph edge: timer_set_traps->bool
// subgraph edge: timer_set_traps->has_cntpoff
// subgraph edge: timer_set_traps->vcpu_el2_e2h_is_set
// subgraph edge: timer_set_traps->sysreg_clear_set
// subgraph edge: timer_set_traps->assign_clear_set_bit
// subgraph node: assign_clear_set_bit
// subgraph edge: kvm_arch_vcpu_load->kvm_vcpu_load_vhe
// subgraph node: kvm_vcpu_load_vhe
// subgraph edge: kvm_arch_vcpu_load->kvm_arch_vcpu_load_fp
// subgraph node: kvm_arch_vcpu_load_fp
// subgraph edge: kvm_arch_vcpu_load_fp->BUG_ON
// subgraph edge: kvm_arch_vcpu_load_fp->read_sysreg
// subgraph edge: kvm_arch_vcpu_load_fp->vcpu_clear_flag
// subgraph node: vcpu_clear_flag
// subgraph edge: kvm_arch_vcpu_load_fp->system_supports_sme
// subgraph node: system_supports_sme
// subgraph edge: kvm_arch_vcpu_load_fp->fpsimd_save_and_flush_cpu_state
// subgraph node: fpsimd_save_and_flush_cpu_state
// subgraph edge: kvm_arch_vcpu_load_fp->system_supports_fpsimd
// subgraph node: system_supports_fpsimd
// subgraph edge: kvm_arch_vcpu_load_fp->fpsimd_kvm_prepare
// subgraph node: fpsimd_kvm_prepare
// subgraph edge: kvm_arch_vcpu_load_fp->vcpu_set_flag
// subgraph node: vcpu_set_flag
// subgraph edge: kvm_arch_vcpu_load_fp->read_sysreg_s
// subgraph node: read_sysreg_s
// subgraph edge: kvm_arch_vcpu_load->kvm_arm_is_pvtime_enabled
// subgraph node: kvm_arm_is_pvtime_enabled
// subgraph edge: kvm_arch_vcpu_load->single_task_running
// subgraph node: single_task_running
// subgraph edge: kvm_arch_vcpu_load->vcpu_clear_wfx_traps
// subgraph node: vcpu_clear_wfx_traps
// subgraph edge: kvm_arch_vcpu_load->vcpu_set_wfx_traps
// subgraph node: vcpu_set_wfx_traps
// subgraph edge: kvm_arch_vcpu_load->vcpu_has_ptrauth
// subgraph node: vcpu_has_ptrauth
// subgraph edge: kvm_arch_vcpu_load->vcpu_ptrauth_disable
// subgraph node: vcpu_ptrauth_disable
// subgraph edge: kvm_arch_vcpu_load->kvm_arch_vcpu_load_debug_state_flags
// subgraph node: kvm_arch_vcpu_load_debug_state_flags
// subgraph edge: kvm_arch_vcpu_load_debug_state_flags->has_vhe
// subgraph edge: kvm_arch_vcpu_load_debug_state_flags->read_sysreg
// subgraph edge: kvm_arch_vcpu_load_debug_state_flags->BIT
// subgraph edge: kvm_arch_vcpu_load_debug_state_flags->vcpu_set_flag
// subgraph edge: kvm_arch_vcpu_load_debug_state_flags->read_sysreg_s
// subgraph edge: kvm_arch_vcpu_load_debug_state_flags->cpuid_feature_extract_unsigned_field
// subgraph edge: kvm_arch_vcpu_load->cpumask_test_cpu
// subgraph node: cpumask_test_cpu
// subgraph edge: kvm_arch_vcpu_load->vcpu_set_on_unsupported_cpu
// subgraph node: vcpu_set_on_unsupported_cpu
// subgraph edge: kvm_sched_in->preempt_notifier_to_vcpu
// subgraph node: preempt_notifier_to_vcpu
// subgraph edge: preempt_notifier_to_vcpu->container_of
// subgraph node: container_of
// subgraph edge: kvm_sched_in->kvm_arch_sched_in
// subgraph node: kvm_arch_sched_in
// subgraph edge: kvm_init->kvm_sched_out
// subgraph node: kvm_sched_out
// subgraph edge: kvm_sched_out->WRITE_ONCE
// subgraph edge: kvm_sched_out->kvm_arch_vcpu_put
// subgraph node: kvm_arch_vcpu_put
// subgraph edge: kvm_arch_vcpu_put->has_vhe
// subgraph edge: kvm_arch_vcpu_put->kvm_arch_vcpu_put_debug_state_flags
// subgraph node: kvm_arch_vcpu_put_debug_state_flags
// subgraph edge: kvm_arch_vcpu_put_debug_state_flags->vcpu_clear_flag
// subgraph edge: kvm_arch_vcpu_put->kvm_arch_vcpu_put_fp
// subgraph node: kvm_arch_vcpu_put_fp
// subgraph edge: kvm_arch_vcpu_put_fp->vcpu_has_sve
// subgraph node: vcpu_has_sve
// subgraph edge: kvm_arch_vcpu_put_fp->vcpu_get_flag
// subgraph node: vcpu_get_flag
// subgraph edge: kvm_arch_vcpu_put_fp->has_vhe
// subgraph edge: kvm_arch_vcpu_put_fp->local_irq_save
// subgraph edge: kvm_arch_vcpu_put_fp->isb
// subgraph edge: kvm_arch_vcpu_put_fp->local_irq_restore
// subgraph edge: kvm_arch_vcpu_put_fp->system_supports_sme
// subgraph edge: kvm_arch_vcpu_put_fp->sysreg_clear_set
// subgraph edge: kvm_arch_vcpu_put_fp->read_sysreg_el1
// subgraph node: read_sysreg_el1
// subgraph edge: kvm_arch_vcpu_put_fp->sve_cond_update_zcr_vq
// subgraph node: sve_cond_update_zcr_vq
// subgraph edge: kvm_arch_vcpu_put_fp->vcpu_sve_max_vq
// subgraph node: vcpu_sve_max_vq
// subgraph edge: kvm_arch_vcpu_put_fp->fpsimd_save_and_flush_cpu_state
// subgraph edge: kvm_arch_vcpu_put_fp->system_supports_sve
// subgraph edge: kvm_arch_vcpu_put->kvm_vcpu_put_vhe
// subgraph node: kvm_vcpu_put_vhe
// subgraph edge: kvm_arch_vcpu_put->kvm_timer_vcpu_put
// subgraph node: kvm_timer_vcpu_put
// subgraph edge: kvm_timer_vcpu_put->get_timer_map
// subgraph edge: kvm_timer_vcpu_put->soft_timer_cancel
// subgraph edge: kvm_timer_vcpu_put->timer_save_state
// subgraph node: timer_save_state
// subgraph edge: timer_save_state->BUG
// subgraph edge: timer_save_state->timer_set_cval
// subgraph node: timer_set_cval
// subgraph edge: timer_set_cval->arch_timer_ctx_index
// subgraph edge: timer_set_cval->WARN_ON
// subgraph edge: timer_save_state->timer_get_offset
// subgraph edge: timer_save_state->timer_set_ctl
// subgraph node: timer_set_ctl
// subgraph edge: timer_set_ctl->arch_timer_ctx_index
// subgraph edge: timer_set_ctl->WARN_ON
// subgraph edge: timer_save_state->arch_timer_ctx_index
// subgraph edge: timer_save_state->read_sysreg_el0
// subgraph edge: timer_save_state->vcpu_timer
// subgraph edge: timer_save_state->local_irq_save
// subgraph edge: timer_save_state->write_sysreg_el0
// subgraph edge: timer_save_state->isb
// subgraph edge: timer_save_state->set_cntvoff
// subgraph edge: timer_save_state->set_cntpoff
// subgraph edge: timer_save_state->trace_kvm_timer_save_state
// subgraph node: trace_kvm_timer_save_state
// subgraph edge: timer_save_state->local_irq_restore
// subgraph edge: kvm_timer_vcpu_put->unlikely
// subgraph edge: kvm_timer_vcpu_put->vcpu_timer
// subgraph edge: kvm_timer_vcpu_put->kvm_vcpu_is_blocking
// subgraph node: kvm_vcpu_is_blocking
// subgraph edge: kvm_timer_vcpu_put->kvm_timer_blocking
// subgraph node: kvm_timer_blocking
// subgraph edge: kvm_timer_blocking->get_timer_map
// subgraph edge: kvm_timer_blocking->kvm_timer_irq_can_fire
// subgraph edge: kvm_timer_blocking->soft_timer_start
// subgraph edge: kvm_timer_blocking->vcpu_timer
// subgraph edge: kvm_timer_blocking->vcpu_has_wfit_active
// subgraph node: vcpu_has_wfit_active
// subgraph edge: vcpu_has_wfit_active->vcpu_get_flag
// subgraph edge: vcpu_has_wfit_active->cpus_have_final_cap
// subgraph edge: kvm_timer_blocking->kvm_timer_earliest_exp
// subgraph node: kvm_timer_earliest_exp
// subgraph edge: kvm_timer_earliest_exp->kvm_timer_irq_can_fire
// subgraph edge: kvm_timer_earliest_exp->kvm_timer_compute_delta
// subgraph edge: kvm_timer_earliest_exp->min
// subgraph edge: kvm_timer_earliest_exp->vcpu_has_wfit_active
// subgraph edge: kvm_timer_earliest_exp->nr_timers
// subgraph node: nr_timers
// subgraph edge: nr_timers->vcpu_has_nv
// subgraph edge: kvm_timer_earliest_exp->WARN
// subgraph node: WARN
// subgraph edge: kvm_timer_earliest_exp->wfit_delay_ns
// subgraph node: wfit_delay_ns
// subgraph edge: wfit_delay_ns->vcpu_has_nv
// subgraph edge: wfit_delay_ns->is_hyp_ctxt
// subgraph edge: wfit_delay_ns->vcpu_hvtimer
// subgraph edge: wfit_delay_ns->vcpu_vtimer
// subgraph edge: wfit_delay_ns->kvm_counter_compute_delta
// subgraph edge: wfit_delay_ns->vcpu_get_reg
// subgraph node: vcpu_get_reg
// subgraph edge: wfit_delay_ns->kvm_vcpu_sys_get_rt
// subgraph node: kvm_vcpu_sys_get_rt
// subgraph edge: kvm_arch_vcpu_put->kvm_vgic_put
// subgraph node: kvm_vgic_put
// subgraph edge: kvm_arch_vcpu_put->kvm_vcpu_pmu_restore_host
// subgraph node: kvm_vcpu_pmu_restore_host
// subgraph edge: kvm_vcpu_pmu_restore_host->has_vhe
// subgraph edge: kvm_vcpu_pmu_restore_host->kvm_arm_support_pmu_v3
// subgraph edge: kvm_vcpu_pmu_restore_host->kvm_get_pmu_events
// subgraph edge: kvm_vcpu_pmu_restore_host->kvm_vcpu_pmu_enable_el0
// subgraph edge: kvm_vcpu_pmu_restore_host->kvm_vcpu_pmu_disable_el0
// subgraph edge: kvm_arch_vcpu_put->kvm_arm_vmid_clear_active
// subgraph node: kvm_arm_vmid_clear_active
// subgraph edge: kvm_arm_vmid_clear_active->this_cpu_ptr
// subgraph edge: kvm_arm_vmid_clear_active->atomic64_set
// subgraph edge: kvm_arch_vcpu_put->vcpu_clear_on_unsupported_cpu
// subgraph node: vcpu_clear_on_unsupported_cpu
// subgraph edge: kvm_sched_out->preempt_notifier_to_vcpu
// subgraph edge: kvm_init->kvm_init_debug
// subgraph node: kvm_init_debug
// subgraph edge: kvm_init_debug->debugfs_create_dir
// subgraph node: debugfs_create_dir
// subgraph edge: kvm_init_debug->kvm_stats_debugfs_mode
// subgraph node: kvm_stats_debugfs_mode
// subgraph edge: kvm_init_debug->debugfs_create_file
// subgraph node: debugfs_create_file
// subgraph edge: kvm_init->kvm_vfio_ops_init
// subgraph node: kvm_vfio_ops_init
// subgraph edge: kvm_vfio_ops_init->kvm_register_device_ops
// subgraph node: kvm_register_device_ops
// subgraph edge: kvm_register_device_ops->ARRAY_SIZE
// subgraph edge: kvm_init->misc_register
// subgraph node: misc_register
// subgraph edge: kvm_init->kvm_vfio_ops_exit
// subgraph node: kvm_vfio_ops_exit
// subgraph edge: kvm_vfio_ops_exit->kvm_unregister_device_ops
// subgraph node: kvm_unregister_device_ops
// subgraph edge: kvm_init->kvm_async_pf_deinit
// subgraph node: kvm_async_pf_deinit
// subgraph edge: kvm_async_pf_deinit->kmem_cache_destroy
// subgraph node: kmem_cache_destroy
// subgraph edge: kvm_init->kvm_irqfd_exit
// subgraph node: kvm_irqfd_exit
// subgraph edge: kvm_irqfd_exit->destroy_workqueue
// subgraph node: destroy_workqueue
// subgraph edge: kvm_init->free_cpumask_var
// subgraph node: free_cpumask_var
// subgraph edge: kvm_init->kmem_cache_destroy
// subgraph edge: kvm_init->unregister_syscore_ops
// subgraph node: unregister_syscore_ops
// subgraph edge: kvm_init->cpuhp_remove_state_nocalls
// subgraph node: cpuhp_remove_state_nocalls
// subgraph edge: kvm_arm_init->teardown_subsystems
// subgraph node: teardown_subsystems
// subgraph edge: teardown_subsystems->hyp_cpu_pm_exit
// subgraph edge: teardown_subsystems->kvm_unregister_perf_callbacks
// subgraph node: kvm_unregister_perf_callbacks
// subgraph edge: kvm_unregister_perf_callbacks->perf_unregister_guest_info_callbacks
// subgraph node: perf_unregister_guest_info_callbacks
// subgraph edge: kvm_arm_init->teardown_hyp_mode
// subgraph edge: kvm_arm_init->kvm_arm_vmid_alloc_free
// subgraph node: kvm_arm_vmid_alloc_free
// subgraph edge: kvm_arm_vmid_alloc_free->bitmap_free
// subgraph node: bitmap_free
digraph gvpr_result {
	node [shape=box];
	vcpu_has_sve	[label="vcpu_has_sve()"];
	vcpu_get_flag	[label="vcpu_get_flag()"];
	vcpu_has_nv	[label="vcpu_has_nv()"];
	BUG	[label="BUG()"];
	get_timer_map	[label="void get_timer_map (struct kvm_vcpu *vcpu, struct timer_map *map)
arch/arm64/kvm/arch_timer.c:178"];
	get_timer_map -> vcpu_has_nv;
	is_hyp_ctxt	[label="is_hyp_ctxt()"];
	get_timer_map -> is_hyp_ctxt;
	vcpu_hvtimer	[label="vcpu_hvtimer()"];
	get_timer_map -> vcpu_hvtimer;
	vcpu_hptimer	[label="vcpu_hptimer()"];
	get_timer_map -> vcpu_hptimer;
	vcpu_vtimer	[label="vcpu_vtimer()"];
	get_timer_map -> vcpu_vtimer;
	vcpu_ptimer	[label="vcpu_ptimer()"];
	get_timer_map -> vcpu_ptimer;
	has_vhe	[label="has_vhe()"];
	get_timer_map -> has_vhe;
	trace_kvm_get_timer_map	[label="trace_kvm_get_timer_map()"];
	get_timer_map -> trace_kvm_get_timer_map;
	soft_timer_cancel	[label="void soft_timer_cancel (struct hrtimer *hrt)
arch/arm64/kvm/arch_timer.c:219"];
	hrtimer_cancel	[label="hrtimer_cancel()"];
	soft_timer_cancel -> hrtimer_cancel;
	timer_emulate	[label="void timer_emulate (struct arch_timer_context *ctx)
arch/arm64/kvm/arch_timer.c:465"];
	bool	[label="bool()"];
	timer_emulate -> bool;
	kvm_timer_should_fire	[label="bool kvm_timer_should_fire (struct arch_timer_context *timer_ctx)
arch/arm64/kvm/arch_timer.c:381"];
	timer_emulate -> kvm_timer_should_fire;
	trace_kvm_timer_emulate	[label="trace_kvm_timer_emulate()"];
	timer_emulate -> trace_kvm_timer_emulate;
	kvm_timer_update_irq	[label="void kvm_timer_update_irq (struct kvm_vcpu *vcpu, bool new_level, struct arch_timer_context *timer_ctx)
arch/arm64/kvm/arch_timer.c:\
446"];
	timer_emulate -> kvm_timer_update_irq;
	kvm_timer_irq_can_fire	[label="bool kvm_timer_irq_can_fire (struct arch_timer_context *timer_ctx)
arch/arm64/kvm/arch_timer.c:279"];
	timer_emulate -> kvm_timer_irq_can_fire;
	soft_timer_start	[label="void soft_timer_start (struct hrtimer *hrt, u64 ns)
arch/arm64/kvm/arch_timer.c:213"];
	timer_emulate -> soft_timer_start;
	kvm_timer_compute_delta	[label="u64 kvm_timer_compute_delta (struct arch_timer_context *timer_ctx)
arch/arm64/kvm/arch_timer.c:274"];
	timer_emulate -> kvm_timer_compute_delta;
	preempt_disable	[label="preempt_disable()"];
	timer_save_state	[label="void timer_save_state (struct arch_timer_context *ctx)
arch/arm64/kvm/arch_timer.c:498"];
	timer_save_state -> BUG;
	timer_set_cval	[label="void timer_set_cval (struct arch_timer_context *ctxt, u64 cval)
arch/arm64/kvm/arch_timer.c:141"];
	timer_save_state -> timer_set_cval;
	timer_get_offset	[label="u64 timer_get_offset (struct arch_timer_context *ctxt)
arch/arm64/kvm/arch_timer.c:104"];
	timer_save_state -> timer_get_offset;
	timer_set_ctl	[label="void timer_set_ctl (struct arch_timer_context *ctxt, u32 ctl)
arch/arm64/kvm/arch_timer.c:119"];
	timer_save_state -> timer_set_ctl;
	arch_timer_ctx_index	[label="arch_timer_ctx_index()"];
	timer_save_state -> arch_timer_ctx_index;
	read_sysreg_el0	[label="read_sysreg_el0()"];
	timer_save_state -> read_sysreg_el0;
	vcpu_timer	[label="vcpu_timer()"];
	timer_save_state -> vcpu_timer;
	local_irq_save	[label="local_irq_save()"];
	timer_save_state -> local_irq_save;
	write_sysreg_el0	[label="write_sysreg_el0()"];
	timer_save_state -> write_sysreg_el0;
	isb	[label="isb()"];
	timer_save_state -> isb;
	set_cntvoff	[label="void set_cntvoff (u64 cntvoff)
arch/arm64/kvm/arch_timer.c:487"];
	timer_save_state -> set_cntvoff;
	set_cntpoff	[label="void set_cntpoff (u64 cntpoff)
arch/arm64/kvm/arch_timer.c:492"];
	timer_save_state -> set_cntpoff;
	trace_kvm_timer_save_state	[label="trace_kvm_timer_save_state()"];
	timer_save_state -> trace_kvm_timer_save_state;
	local_irq_restore	[label="local_irq_restore()"];
	timer_save_state -> local_irq_restore;
	timer_restore_state	[label="void timer_restore_state (struct arch_timer_context *ctx)
arch/arm64/kvm/arch_timer.c:604"];
	timer_restore_state -> BUG;
	timer_restore_state -> timer_get_offset;
	timer_restore_state -> arch_timer_ctx_index;
	timer_get_cval	[label="u64 timer_get_cval (struct arch_timer_context *ctxt)
arch/arm64/kvm/arch_timer.c:85"];
	timer_restore_state -> timer_get_cval;
	timer_get_ctl	[label="u32 timer_get_ctl (struct arch_timer_context *ctxt)
arch/arm64/kvm/arch_timer.c:66"];
	timer_restore_state -> timer_get_ctl;
	timer_restore_state -> vcpu_timer;
	timer_restore_state -> local_irq_save;
	timer_restore_state -> write_sysreg_el0;
	timer_restore_state -> isb;
	timer_restore_state -> set_cntvoff;
	timer_restore_state -> set_cntpoff;
	timer_restore_state -> local_irq_restore;
	trace_kvm_timer_restore_state	[label="trace_kvm_timer_restore_state()"];
	timer_restore_state -> trace_kvm_timer_restore_state;
	preempt_enable	[label="preempt_enable()"];
	timer_set_cval -> arch_timer_ctx_index;
	WARN_ON	[label="WARN_ON()"];
	timer_set_cval -> WARN_ON;
	kvm_phys_timer_read	[label="u64 kvm_phys_timer_read (void)
arch/arm64/kvm/arch_timer.c:173"];
	timer_set_ctl -> arch_timer_ctx_index;
	timer_set_ctl -> WARN_ON;
	kvm_timer_should_fire -> kvm_phys_timer_read;
	kvm_timer_should_fire -> timer_get_offset;
	kvm_timer_should_fire -> arch_timer_ctx_index;
	kvm_timer_should_fire -> kvm_timer_irq_can_fire;
	kvm_timer_should_fire -> read_sysreg_el0;
	kvm_timer_should_fire -> timer_get_cval;
	kvm_timer_update_irq -> WARN_ON;
	trace_kvm_timer_update_irq	[label="trace_kvm_timer_update_irq()"];
	kvm_timer_update_irq -> trace_kvm_timer_update_irq;
	timer_irq	[label="timer_irq()"];
	kvm_timer_update_irq -> timer_irq;
	userspace_irqchip	[label="inline bool userspace_irqchip (struct kvm *kvm)
arch/arm64/kvm/arch_timer.c:207"];
	kvm_timer_update_irq -> userspace_irqchip;
	kvm_vgic_inject_irq	[label="kvm_vgic_inject_irq()"];
	kvm_timer_update_irq -> kvm_vgic_inject_irq;
	kvm_timer_irq_can_fire -> WARN_ON;
	kvm_timer_irq_can_fire -> timer_get_ctl;
	hrtimer_start	[label="hrtimer_start()"];
	soft_timer_start -> hrtimer_start;
	ktime_add_ns	[label="ktime_add_ns()"];
	soft_timer_start -> ktime_add_ns;
	ktime_get	[label="ktime_get()"];
	soft_timer_start -> ktime_get;
	kvm_timer_compute_delta -> timer_get_cval;
	kvm_counter_compute_delta	[label="u64 kvm_counter_compute_delta (struct arch_timer_context *timer_ctx, u64 val)
arch/arm64/kvm/arch_timer.c:256"];
	kvm_timer_compute_delta -> kvm_counter_compute_delta;
	timer_get_cval -> arch_timer_ctx_index;
	timer_get_cval -> WARN_ON;
	timer_get_ctl -> arch_timer_ctx_index;
	timer_get_ctl -> WARN_ON;
	static_branch_unlikely	[label="static_branch_unlikely()"];
	userspace_irqchip -> static_branch_unlikely;
	unlikely	[label="unlikely()"];
	userspace_irqchip -> unlikely;
	irqchip_in_kernel	[label="irqchip_in_kernel()"];
	userspace_irqchip -> irqchip_in_kernel;
	kvm_counter_compute_delta -> kvm_phys_timer_read;
	kvm_counter_compute_delta -> timer_get_offset;
	cyclecounter_cyc2ns	[label="cyclecounter_cyc2ns()"];
	kvm_counter_compute_delta -> cyclecounter_cyc2ns;
	kvm_call_hyp	[label="kvm_call_hyp()"];
	set_cntvoff -> kvm_call_hyp;
	has_cntpoff	[label="has_cntpoff()"];
	set_cntpoff -> has_cntpoff;
	write_sysreg_s	[label="write_sysreg_s()"];
	set_cntpoff -> write_sysreg_s;
	read_sanitised_ftr_reg	[label="read_sanitised_ftr_reg()"];
	cpus_have_final_cap	[label="cpus_have_final_cap()"];
	FIELD_PREP	[label="FIELD_PREP()"];
	BUG_ON	[label="BUG_ON()"];
	read_sysreg	[label="read_sysreg()"];
	BIT	[label="BIT()"];
	kvm_vcpu_pmu_restore_guest	[label="void kvm_vcpu_pmu_restore_guest (struct kvm_vcpu *vcpu)
arch/arm64/kvm/pmu.c:176"];
	kvm_vcpu_pmu_restore_guest -> preempt_disable;
	kvm_vcpu_pmu_restore_guest -> preempt_enable;
	kvm_vcpu_pmu_restore_guest -> has_vhe;
	kvm_arm_support_pmu_v3	[label="kvm_arm_support_pmu_v3()"];
	kvm_vcpu_pmu_restore_guest -> kvm_arm_support_pmu_v3;
	kvm_get_pmu_events	[label="struct kvm_pmu_events *kvm_get_pmu_events (void)
arch/arm64/kvm/pmu.c:29"];
	kvm_vcpu_pmu_restore_guest -> kvm_get_pmu_events;
	kvm_vcpu_pmu_enable_el0	[label="void kvm_vcpu_pmu_enable_el0 (unsigned long events)
arch/arm64/kvm/pmu.c:143"];
	kvm_vcpu_pmu_restore_guest -> kvm_vcpu_pmu_enable_el0;
	kvm_vcpu_pmu_disable_el0	[label="void kvm_vcpu_pmu_disable_el0 (unsigned long events)
arch/arm64/kvm/pmu.c:158"];
	kvm_vcpu_pmu_restore_guest -> kvm_vcpu_pmu_disable_el0;
	kvm_debug	[label="kvm_debug()"];
	container_of	[label="container_of()"];
	kvm_make_request	[label="kvm_make_request()"];
	for_each_set_bit	[label="for_each_set_bit()"];
	WRITE_ONCE	[label="WRITE_ONCE()"];
	this_cpu_ptr	[label="this_cpu_ptr()"];
	kvm_get_pmu_events -> this_cpu_ptr;
	kvm_vcpu_pmu_enable_el0 -> for_each_set_bit;
	kvm_vcpu_pmu_read_evtype_direct	[label="u64 kvm_vcpu_pmu_read_evtype_direct (int idx)
arch/arm64/kvm/pmu.c:111"];
	kvm_vcpu_pmu_enable_el0 -> kvm_vcpu_pmu_read_evtype_direct;
	kvm_vcpu_pmu_write_evtype_direct	[label="void kvm_vcpu_pmu_write_evtype_direct (int idx, u32 val)
arch/arm64/kvm/pmu.c:128"];
	kvm_vcpu_pmu_enable_el0 -> kvm_vcpu_pmu_write_evtype_direct;
	kvm_vcpu_pmu_disable_el0 -> for_each_set_bit;
	kvm_vcpu_pmu_disable_el0 -> kvm_vcpu_pmu_read_evtype_direct;
	kvm_vcpu_pmu_disable_el0 -> kvm_vcpu_pmu_write_evtype_direct;
	kvm_vcpu_pmu_read_evtype_direct -> WARN_ON;
	kvm_vcpu_pmu_read_evtype_direct -> read_sysreg;
	PMEVTYPER_CASES	[label="PMEVTYPER_CASES()"];
	kvm_vcpu_pmu_read_evtype_direct -> PMEVTYPER_CASES;
	kvm_vcpu_pmu_write_evtype_direct -> WARN_ON;
	kvm_vcpu_pmu_write_evtype_direct -> PMEVTYPER_CASES;
	write_sysreg	[label="write_sysreg()"];
	kvm_vcpu_pmu_write_evtype_direct -> write_sysreg;
	vcpu_el2_e2h_is_set	[label="vcpu_el2_e2h_is_set()"];
	kfree	[label="kfree()"];
	memcpy	[label="memcpy()"];
	is_protected_kvm_enabled	[label="is_protected_kvm_enabled()"];
	is_kernel_in_hyp_mode	[label="is_kernel_in_hyp_mode()"];
	is_hyp_mode_available	[label="is_hyp_mode_available()"];
	pr_err	[label="pr_err()"];
	static_branch_enable	[label="static_branch_enable()"];
	on_each_cpu	[label="on_each_cpu()"];
	min	[label="min()"];
	mutex_lock	[label="mutex_lock()"];
	mutex_unlock	[label="mutex_unlock()"];
	WARN_ON_ONCE	[label="WARN_ON_ONCE()"];
	vcpu_get_reg	[label="vcpu_get_reg()"];
	kvm_err	[label="kvm_err()"];
	kvm_arch_vcpu_put	[label="void kvm_arch_vcpu_put (struct kvm_vcpu *vcpu)
arch/arm64/kvm/arm.c:473"];
	kvm_arch_vcpu_put -> has_vhe;
	kvm_arch_vcpu_put_debug_state_flags	[label="void kvm_arch_vcpu_put_debug_state_flags (struct kvm_vcpu *vcpu)
arch/arm64/kvm/debug.c:340"];
	kvm_arch_vcpu_put -> kvm_arch_vcpu_put_debug_state_flags;
	kvm_arch_vcpu_put_fp	[label="void kvm_arch_vcpu_put_fp (struct kvm_vcpu *vcpu)
arch/arm64/kvm/fpsimd.c:175"];
	kvm_arch_vcpu_put -> kvm_arch_vcpu_put_fp;
	kvm_vcpu_put_vhe	[label="kvm_vcpu_put_vhe()"];
	kvm_arch_vcpu_put -> kvm_vcpu_put_vhe;
	kvm_timer_vcpu_put	[label="void kvm_timer_vcpu_put (struct kvm_vcpu *vcpu)
arch/arm64/kvm/arch_timer.c:878"];
	kvm_arch_vcpu_put -> kvm_timer_vcpu_put;
	kvm_vgic_put	[label="kvm_vgic_put()"];
	kvm_arch_vcpu_put -> kvm_vgic_put;
	kvm_vcpu_pmu_restore_host	[label="void kvm_vcpu_pmu_restore_host (struct kvm_vcpu *vcpu)
arch/arm64/kvm/pmu.c:197"];
	kvm_arch_vcpu_put -> kvm_vcpu_pmu_restore_host;
	kvm_arm_vmid_clear_active	[label="void kvm_arm_vmid_clear_active (void)
arch/arm64/kvm/vmid.c:133"];
	kvm_arch_vcpu_put -> kvm_arm_vmid_clear_active;
	vcpu_clear_on_unsupported_cpu	[label="vcpu_clear_on_unsupported_cpu()"];
	kvm_arch_vcpu_put -> vcpu_clear_on_unsupported_cpu;
	kvm_arch_vcpu_load	[label="void kvm_arch_vcpu_load (struct kvm_vcpu *vcpu, int cpu)
arch/arm64/kvm/arm.c:427"];
	kvm_arch_vcpu_load -> has_vhe;
	kvm_arch_vcpu_load -> kvm_call_hyp;
	kvm_arch_vcpu_load -> kvm_vcpu_pmu_restore_guest;
	kvm_arch_vcpu_load -> kvm_make_request;
	kvm_arch_vcpu_load -> this_cpu_ptr;
	kvm_vgic_load	[label="kvm_vgic_load()"];
	kvm_arch_vcpu_load -> kvm_vgic_load;
	kvm_timer_vcpu_load	[label="void kvm_timer_vcpu_load (struct kvm_vcpu *vcpu)
arch/arm64/kvm/arch_timer.c:827"];
	kvm_arch_vcpu_load -> kvm_timer_vcpu_load;
	kvm_vcpu_load_vhe	[label="kvm_vcpu_load_vhe()"];
	kvm_arch_vcpu_load -> kvm_vcpu_load_vhe;
	kvm_arch_vcpu_load_fp	[label="void kvm_arch_vcpu_load_fp (struct kvm_vcpu *vcpu)
arch/arm64/kvm/fpsimd.c:75"];
	kvm_arch_vcpu_load -> kvm_arch_vcpu_load_fp;
	kvm_arm_is_pvtime_enabled	[label="kvm_arm_is_pvtime_enabled()"];
	kvm_arch_vcpu_load -> kvm_arm_is_pvtime_enabled;
	single_task_running	[label="single_task_running()"];
	kvm_arch_vcpu_load -> single_task_running;
	vcpu_clear_wfx_traps	[label="vcpu_clear_wfx_traps()"];
	kvm_arch_vcpu_load -> vcpu_clear_wfx_traps;
	vcpu_set_wfx_traps	[label="vcpu_set_wfx_traps()"];
	kvm_arch_vcpu_load -> vcpu_set_wfx_traps;
	vcpu_has_ptrauth	[label="vcpu_has_ptrauth()"];
	kvm_arch_vcpu_load -> vcpu_has_ptrauth;
	vcpu_ptrauth_disable	[label="vcpu_ptrauth_disable()"];
	kvm_arch_vcpu_load -> vcpu_ptrauth_disable;
	kvm_arch_vcpu_load_debug_state_flags	[label="void kvm_arch_vcpu_load_debug_state_flags (struct kvm_vcpu *vcpu)
arch/arm64/kvm/debug.c:317"];
	kvm_arch_vcpu_load -> kvm_arch_vcpu_load_debug_state_flags;
	cpumask_test_cpu	[label="cpumask_test_cpu()"];
	kvm_arch_vcpu_load -> cpumask_test_cpu;
	vcpu_set_on_unsupported_cpu	[label="vcpu_set_on_unsupported_cpu()"];
	kvm_arch_vcpu_load -> vcpu_set_on_unsupported_cpu;
	vcpu_clear_flag	[label="vcpu_clear_flag()"];
	kvm_arch_vcpu_put_debug_state_flags -> vcpu_clear_flag;
	kvm_arch_vcpu_put_fp -> vcpu_has_sve;
	kvm_arch_vcpu_put_fp -> vcpu_get_flag;
	kvm_arch_vcpu_put_fp -> has_vhe;
	kvm_arch_vcpu_put_fp -> local_irq_save;
	kvm_arch_vcpu_put_fp -> isb;
	kvm_arch_vcpu_put_fp -> local_irq_restore;
	system_supports_sme	[label="system_supports_sme()"];
	kvm_arch_vcpu_put_fp -> system_supports_sme;
	sysreg_clear_set	[label="sysreg_clear_set()"];
	kvm_arch_vcpu_put_fp -> sysreg_clear_set;
	read_sysreg_el1	[label="read_sysreg_el1()"];
	kvm_arch_vcpu_put_fp -> read_sysreg_el1;
	sve_cond_update_zcr_vq	[label="sve_cond_update_zcr_vq()"];
	kvm_arch_vcpu_put_fp -> sve_cond_update_zcr_vq;
	vcpu_sve_max_vq	[label="vcpu_sve_max_vq()"];
	kvm_arch_vcpu_put_fp -> vcpu_sve_max_vq;
	fpsimd_save_and_flush_cpu_state	[label="fpsimd_save_and_flush_cpu_state()"];
	kvm_arch_vcpu_put_fp -> fpsimd_save_and_flush_cpu_state;
	system_supports_sve	[label="system_supports_sve()"];
	kvm_arch_vcpu_put_fp -> system_supports_sve;
	kvm_timer_vcpu_put -> get_timer_map;
	kvm_timer_vcpu_put -> soft_timer_cancel;
	kvm_timer_vcpu_put -> timer_save_state;
	kvm_timer_vcpu_put -> unlikely;
	kvm_timer_vcpu_put -> vcpu_timer;
	kvm_vcpu_is_blocking	[label="kvm_vcpu_is_blocking()"];
	kvm_timer_vcpu_put -> kvm_vcpu_is_blocking;
	kvm_timer_blocking	[label="void kvm_timer_blocking (struct kvm_vcpu *vcpu)
arch/arm64/kvm/arch_timer.c:572"];
	kvm_timer_vcpu_put -> kvm_timer_blocking;
	kvm_vcpu_pmu_restore_host -> has_vhe;
	kvm_vcpu_pmu_restore_host -> kvm_arm_support_pmu_v3;
	kvm_vcpu_pmu_restore_host -> kvm_get_pmu_events;
	kvm_vcpu_pmu_restore_host -> kvm_vcpu_pmu_enable_el0;
	kvm_vcpu_pmu_restore_host -> kvm_vcpu_pmu_disable_el0;
	kvm_arm_vmid_clear_active -> this_cpu_ptr;
	atomic64_set	[label="atomic64_set()"];
	kvm_arm_vmid_clear_active -> atomic64_set;
	kvm_timer_blocking -> get_timer_map;
	kvm_timer_blocking -> kvm_timer_irq_can_fire;
	kvm_timer_blocking -> soft_timer_start;
	kvm_timer_blocking -> vcpu_timer;
	vcpu_has_wfit_active	[label="bool vcpu_has_wfit_active (struct kvm_vcpu *vcpu)
arch/arm64/kvm/arch_timer.c:287"];
	kvm_timer_blocking -> vcpu_has_wfit_active;
	kvm_timer_earliest_exp	[label="u64 kvm_timer_earliest_exp (struct kvm_vcpu *vcpu)
arch/arm64/kvm/arch_timer.c:308"];
	kvm_timer_blocking -> kvm_timer_earliest_exp;
	vcpu_has_wfit_active -> vcpu_get_flag;
	vcpu_has_wfit_active -> cpus_have_final_cap;
	kvm_timer_earliest_exp -> kvm_timer_irq_can_fire;
	kvm_timer_earliest_exp -> kvm_timer_compute_delta;
	kvm_timer_earliest_exp -> min;
	kvm_timer_earliest_exp -> vcpu_has_wfit_active;
	nr_timers	[label="int nr_timers (struct kvm_vcpu *vcpu)
arch/arm64/kvm/arch_timer.c:58"];
	kvm_timer_earliest_exp -> nr_timers;
	WARN	[label="WARN()"];
	kvm_timer_earliest_exp -> WARN;
	wfit_delay_ns	[label="u64 wfit_delay_ns (struct kvm_vcpu *vcpu)
arch/arm64/kvm/arch_timer.c:293"];
	kvm_timer_earliest_exp -> wfit_delay_ns;
	nr_timers -> vcpu_has_nv;
	wfit_delay_ns -> vcpu_has_nv;
	wfit_delay_ns -> is_hyp_ctxt;
	wfit_delay_ns -> vcpu_hvtimer;
	wfit_delay_ns -> vcpu_vtimer;
	wfit_delay_ns -> kvm_counter_compute_delta;
	wfit_delay_ns -> vcpu_get_reg;
	kvm_vcpu_sys_get_rt	[label="kvm_vcpu_sys_get_rt()"];
	wfit_delay_ns -> kvm_vcpu_sys_get_rt;
	kvm_timer_vcpu_load -> vcpu_has_nv;
	kvm_timer_vcpu_load -> get_timer_map;
	kvm_timer_vcpu_load -> timer_emulate;
	kvm_timer_vcpu_load -> timer_restore_state;
	kvm_timer_vcpu_load -> unlikely;
	kvm_timer_vcpu_load -> vcpu_timer;
	static_branch_likely	[label="static_branch_likely()"];
	kvm_timer_vcpu_load -> static_branch_likely;
	kvm_timer_vcpu_load_nested_switch	[label="void kvm_timer_vcpu_load_nested_switch (struct kvm_vcpu *vcpu, struct timer_map *map)
arch/arm64/kvm/arch_timer.c:714"];
	kvm_timer_vcpu_load -> kvm_timer_vcpu_load_nested_switch;
	kvm_timer_vcpu_load_gic	[label="void kvm_timer_vcpu_load_gic (struct arch_timer_context *ctx)
arch/arm64/kvm/arch_timer.c:656"];
	kvm_timer_vcpu_load -> kvm_timer_vcpu_load_gic;
	kvm_timer_vcpu_load_nogic	[label="void kvm_timer_vcpu_load_nogic (struct kvm_vcpu *vcpu)
arch/arm64/kvm/arch_timer.c:677"];
	kvm_timer_vcpu_load -> kvm_timer_vcpu_load_nogic;
	kvm_timer_unblocking	[label="void kvm_timer_unblocking (struct kvm_vcpu *vcpu)
arch/arm64/kvm/arch_timer.c:597"];
	kvm_timer_vcpu_load -> kvm_timer_unblocking;
	timer_set_traps	[label="void timer_set_traps (struct kvm_vcpu *vcpu, struct timer_map *map)
arch/arm64/kvm/arch_timer.c:765"];
	kvm_timer_vcpu_load -> timer_set_traps;
	kvm_arch_vcpu_load_fp -> BUG_ON;
	kvm_arch_vcpu_load_fp -> read_sysreg;
	kvm_arch_vcpu_load_fp -> vcpu_clear_flag;
	kvm_arch_vcpu_load_fp -> system_supports_sme;
	kvm_arch_vcpu_load_fp -> fpsimd_save_and_flush_cpu_state;
	system_supports_fpsimd	[label="system_supports_fpsimd()"];
	kvm_arch_vcpu_load_fp -> system_supports_fpsimd;
	fpsimd_kvm_prepare	[label="fpsimd_kvm_prepare()"];
	kvm_arch_vcpu_load_fp -> fpsimd_kvm_prepare;
	vcpu_set_flag	[label="vcpu_set_flag()"];
	kvm_arch_vcpu_load_fp -> vcpu_set_flag;
	read_sysreg_s	[label="read_sysreg_s()"];
	kvm_arch_vcpu_load_fp -> read_sysreg_s;
	kvm_arch_vcpu_load_debug_state_flags -> has_vhe;
	kvm_arch_vcpu_load_debug_state_flags -> read_sysreg;
	kvm_arch_vcpu_load_debug_state_flags -> BIT;
	kvm_arch_vcpu_load_debug_state_flags -> vcpu_set_flag;
	kvm_arch_vcpu_load_debug_state_flags -> read_sysreg_s;
	cpuid_feature_extract_unsigned_field	[label="cpuid_feature_extract_unsigned_field()"];
	kvm_arch_vcpu_load_debug_state_flags -> cpuid_feature_extract_unsigned_field;
	kvm_timer_vcpu_load_nested_switch -> vcpu_hvtimer;
	kvm_timer_vcpu_load_nested_switch -> timer_irq;
	kvm_timer_vcpu_load_nested_switch -> irqchip_in_kernel;
	kvm_timer_vcpu_load_nested_switch -> vcpu_el2_e2h_is_set;
	kvm_timer_vcpu_load_nested_switch -> WARN_ON_ONCE;
	kvm_vgic_get_map	[label="kvm_vgic_get_map()"];
	kvm_timer_vcpu_load_nested_switch -> kvm_vgic_get_map;
	kvm_vgic_unmap_phys_irq	[label="kvm_vgic_unmap_phys_irq()"];
	kvm_timer_vcpu_load_nested_switch -> kvm_vgic_unmap_phys_irq;
	kvm_vgic_map_phys_irq	[label="kvm_vgic_map_phys_irq()"];
	kvm_timer_vcpu_load_nested_switch -> kvm_vgic_map_phys_irq;
	kvm_timer_vcpu_load_gic -> bool;
	kvm_timer_vcpu_load_gic -> kvm_timer_should_fire;
	kvm_timer_vcpu_load_gic -> kvm_timer_update_irq;
	kvm_timer_vcpu_load_gic -> timer_irq;
	kvm_timer_vcpu_load_gic -> irqchip_in_kernel;
	kvm_vgic_map_is_active	[label="kvm_vgic_map_is_active()"];
	kvm_timer_vcpu_load_gic -> kvm_vgic_map_is_active;
	set_timer_irq_phys_active	[label="inline void set_timer_irq_phys_active (struct arch_timer_context *ctx, bool active)
arch/arm64/kvm/arch_timer.c:649"];
	kvm_timer_vcpu_load_gic -> set_timer_irq_phys_active;
	kvm_timer_vcpu_load_nogic -> vcpu_vtimer;
	kvm_timer_vcpu_load_nogic -> kvm_timer_should_fire;
	kvm_timer_vcpu_load_nogic -> kvm_timer_update_irq;
	disable_percpu_irq	[label="disable_percpu_irq()"];
	kvm_timer_vcpu_load_nogic -> disable_percpu_irq;
	enable_percpu_irq	[label="enable_percpu_irq()"];
	kvm_timer_vcpu_load_nogic -> enable_percpu_irq;
	kvm_timer_unblocking -> soft_timer_cancel;
	kvm_timer_unblocking -> vcpu_timer;
	timer_set_traps -> vcpu_has_nv;
	timer_set_traps -> is_hyp_ctxt;
	timer_set_traps -> has_vhe;
	timer_set_traps -> timer_get_offset;
	timer_set_traps -> bool;
	timer_set_traps -> has_cntpoff;
	timer_set_traps -> vcpu_el2_e2h_is_set;
	timer_set_traps -> sysreg_clear_set;
	assign_clear_set_bit	[label="assign_clear_set_bit()"];
	timer_set_traps -> assign_clear_set_bit;
	set_timer_irq_phys_active -> WARN_ON;
	irq_set_irqchip_state	[label="irq_set_irqchip_state()"];
	set_timer_irq_phys_active -> irq_set_irqchip_state;
	arm64_get_spectre_v2_state	[label="arm64_get_spectre_v2_state()"];
	arm64_get_spectre_v4_state	[label="arm64_get_spectre_v4_state()"];
	get_random_long	[label="get_random_long()"];
	cpu_hyp_reset	[label="void cpu_hyp_reset (void)
arch/arm64/kvm/arm.c:1914"];
	cpu_hyp_reset -> is_kernel_in_hyp_mode;
	cpu_hyp_reinit	[label="void cpu_hyp_reinit (void)
arch/arm64/kvm/arm.c:1971"];
	cpu_hyp_reinit -> cpu_hyp_reset;
	cpu_hyp_init_context	[label="void cpu_hyp_init_context (void)
arch/arm64/kvm/arm.c:1951"];
	cpu_hyp_reinit -> cpu_hyp_init_context;
	cpu_hyp_init_features	[label="void cpu_hyp_init_features (void)
arch/arm64/kvm/arm.c:1959"];
	cpu_hyp_reinit -> cpu_hyp_init_features;
	cpu_hyp_init_context -> is_kernel_in_hyp_mode;
	kvm_init_host_cpu_context	[label="kvm_init_host_cpu_context()"];
	cpu_hyp_init_context -> kvm_init_host_cpu_context;
	this_cpu_ptr_hyp_sym	[label="this_cpu_ptr_hyp_sym()"];
	cpu_hyp_init_context -> this_cpu_ptr_hyp_sym;
	cpu_init_hyp_mode	[label="void cpu_init_hyp_mode (void)
arch/arm64/kvm/arm.c:1900"];
	cpu_hyp_init_context -> cpu_init_hyp_mode;
	cpu_hyp_init_features -> is_kernel_in_hyp_mode;
	cpu_set_hyp_vector	[label="void cpu_set_hyp_vector (void)
arch/arm64/kvm/arm.c:1940"];
	cpu_hyp_init_features -> cpu_set_hyp_vector;
	kvm_arm_init_debug	[label="void kvm_arm_init_debug (void)
arch/arm64/kvm/debug.c:78"];
	cpu_hyp_init_features -> kvm_arm_init_debug;
	kvm_timer_init_vhe	[label="void kvm_timer_init_vhe (void)
arch/arm64/kvm/arch_timer.c:1554"];
	cpu_hyp_init_features -> kvm_timer_init_vhe;
	kvm_vgic_init_cpu_hardware	[label="kvm_vgic_init_cpu_hardware()"];
	cpu_hyp_init_features -> kvm_vgic_init_cpu_hardware;
	cpu_init_hyp_mode -> arm64_get_spectre_v4_state;
	hyp_install_host_vector	[label="void hyp_install_host_vector (void)
arch/arm64/kvm/arm.c:1880"];
	cpu_init_hyp_mode -> hyp_install_host_vector;
	this_cpu_has_cap	[label="this_cpu_has_cap()"];
	cpu_init_hyp_mode -> this_cpu_has_cap;
	kvm_call_hyp_nvhe	[label="kvm_call_hyp_nvhe()"];
	cpu_init_hyp_mode -> kvm_call_hyp_nvhe;
	hyp_install_host_vector -> WARN_ON;
	hyp_install_host_vector -> BUG_ON;
	kvm_get_idmap_vector	[label="phys_addr_t kvm_get_idmap_vector (void)
arch/arm64/kvm/mmu.c:1827"];
	hyp_install_host_vector -> kvm_get_idmap_vector;
	system_capabilities_finalized	[label="system_capabilities_finalized()"];
	hyp_install_host_vector -> system_capabilities_finalized;
	this_cpu_ptr_nvhe_sym	[label="this_cpu_ptr_nvhe_sym()"];
	hyp_install_host_vector -> this_cpu_ptr_nvhe_sym;
	arm_smccc_1_1_hvc	[label="arm_smccc_1_1_hvc()"];
	hyp_install_host_vector -> arm_smccc_1_1_hvc;
	KVM_HOST_SMCCC_FUNC	[label="KVM_HOST_SMCCC_FUNC()"];
	hyp_install_host_vector -> KVM_HOST_SMCCC_FUNC;
	virt_to_phys	[label="virt_to_phys()"];
	hyp_install_host_vector -> virt_to_phys;
	cpu_set_hyp_vector -> this_cpu_ptr;
	cpu_set_hyp_vector -> is_protected_kvm_enabled;
	cpu_set_hyp_vector -> this_cpu_ptr_hyp_sym;
	cpu_set_hyp_vector -> kvm_call_hyp_nvhe;
	kvm_call_hyp_ret	[label="kvm_call_hyp_ret()"];
	kvm_arm_init_debug -> kvm_call_hyp_ret;
	kvm_timer_init_vhe -> cpus_have_final_cap;
	kvm_timer_init_vhe -> sysreg_clear_set;
	kvm_arm_init	[label="__init int kvm_arm_init (void)
arch/arm64/kvm/arm.c:2521"];
	kvm_arm_init -> bool;
	kvm_arm_init -> cpus_have_final_cap;
	kvm_arm_init -> is_protected_kvm_enabled;
	kvm_arm_init -> is_kernel_in_hyp_mode;
	kvm_arm_init -> is_hyp_mode_available;
	kvm_arm_init -> kvm_err;
	kvm_info	[label="kvm_info()"];
	kvm_arm_init -> kvm_info;
	kvm_get_mode	[label="enum kvm_mode kvm_get_mode (void)
arch/arm64/kvm/arm.c:2647"];
	kvm_arm_init -> kvm_get_mode;
	kvm_sys_reg_table_init	[label="int __init kvm_sys_reg_table_init (void)
arch/arm64/kvm/sys_regs.c:3794"];
	kvm_arm_init -> kvm_sys_reg_table_init;
	kvm_set_ipa_limit	[label="int __init kvm_set_ipa_limit (void)
arch/arm64/kvm/reset.c:274"];
	kvm_arm_init -> kvm_set_ipa_limit;
	kvm_arm_init_sve	[label="int __init kvm_arm_init_sve (void)
arch/arm64/kvm/reset.c:50"];
	kvm_arm_init -> kvm_arm_init_sve;
	kvm_arm_vmid_alloc_init	[label="int __init kvm_arm_vmid_alloc_init (void)
arch/arm64/kvm/vmid.c:180"];
	kvm_arm_init -> kvm_arm_vmid_alloc_init;
	init_hyp_mode	[label="int __init init_hyp_mode (void)
arch/arm64/kvm/arm.c:2288"];
	kvm_arm_init -> init_hyp_mode;
	kvm_init_vector_slots	[label="int kvm_init_vector_slots (void)
arch/arm64/kvm/arm.c:1813"];
	kvm_arm_init -> kvm_init_vector_slots;
	init_subsystems	[label="int __init init_subsystems (void)
arch/arm64/kvm/arm.c:2121"];
	kvm_arm_init -> init_subsystems;
	kvm_init	[label="int kvm_init (unsigned vcpu_size, unsigned vcpu_align, struct module *module)
virt/kvm/kvm_main.c:6048"];
	kvm_arm_init -> kvm_init;
	teardown_subsystems	[label="void __init teardown_subsystems (void)
arch/arm64/kvm/arm.c:2171"];
	kvm_arm_init -> teardown_subsystems;
	teardown_hyp_mode	[label="void __init teardown_hyp_mode (void)
arch/arm64/kvm/arm.c:2177"];
	kvm_arm_init -> teardown_hyp_mode;
	kvm_arm_vmid_alloc_free	[label="void __init kvm_arm_vmid_alloc_free (void)
arch/arm64/kvm/vmid.c:197"];
	kvm_arm_init -> kvm_arm_vmid_alloc_free;
	kvm_sys_reg_table_init -> bool;
	kvm_sys_reg_table_init -> kvm_get_mode;
	check_sysreg_table	[label="bool check_sysreg_table (const struct sys_reg_desc *table, unsigned int n, bool is_32)
arch/arm64/kvm/sys_regs.c:2914"];
	kvm_sys_reg_table_init -> check_sysreg_table;
	ARRAY_SIZE	[label="ARRAY_SIZE()"];
	kvm_sys_reg_table_init -> ARRAY_SIZE;
	encoding_to_params	[label="encoding_to_params()"];
	kvm_sys_reg_table_init -> encoding_to_params;
	find_reg	[label="find_reg()"];
	kvm_sys_reg_table_init -> find_reg;
	populate_nv_trap_config	[label="int __init populate_nv_trap_config (void)
arch/arm64/kvm/emulate-nested.c:1701"];
	kvm_sys_reg_table_init -> populate_nv_trap_config;
	kvm_set_ipa_limit -> read_sanitised_ftr_reg;
	kvm_set_ipa_limit -> kvm_debug;
	kvm_set_ipa_limit -> min;
	kvm_set_ipa_limit -> kvm_err;
	kvm_set_ipa_limit -> cpuid_feature_extract_unsigned_field;
	kvm_set_ipa_limit -> kvm_info;
	id_aa64mmfr0_parange_to_phys_shift	[label="id_aa64mmfr0_parange_to_phys_shift()"];
	kvm_set_ipa_limit -> id_aa64mmfr0_parange_to_phys_shift;
	kvm_arm_init_sve -> WARN_ON;
	kvm_arm_init_sve -> system_supports_sve;
	sve_max_virtualisable_vl	[label="sve_max_virtualisable_vl()"];
	kvm_arm_init_sve -> sve_max_virtualisable_vl;
	sve_max_vl	[label="sve_max_vl()"];
	kvm_arm_init_sve -> sve_max_vl;
	pr_warn	[label="pr_warn()"];
	kvm_arm_init_sve -> pr_warn;
	kvm_arm_vmid_alloc_init -> WARN_ON;
	kvm_arm_vmid_alloc_init -> atomic64_set;
	kvm_get_vmid_bits	[label="kvm_get_vmid_bits()"];
	kvm_arm_vmid_alloc_init -> kvm_get_vmid_bits;
	num_possible_cpus	[label="num_possible_cpus()"];
	kvm_arm_vmid_alloc_init -> num_possible_cpus;
	bitmap_zalloc	[label="bitmap_zalloc()"];
	kvm_arm_vmid_alloc_init -> bitmap_zalloc;
	init_hyp_mode -> cpus_have_final_cap;
	init_hyp_mode -> memcpy;
	init_hyp_mode -> is_protected_kvm_enabled;
	init_hyp_mode -> kvm_err;
	init_hyp_mode -> teardown_hyp_mode;
	kvm_mmu_init	[label="int __init kvm_mmu_init (u32 *hyp_va_bits)
arch/arm64/kvm/mmu.c:1857"];
	init_hyp_mode -> kvm_mmu_init;
	for_each_possible_cpu	[label="for_each_possible_cpu()"];
	init_hyp_mode -> for_each_possible_cpu;
	per_cpu	[label="per_cpu()"];
	init_hyp_mode -> per_cpu;
	alloc_pages	[label="alloc_pages()"];
	init_hyp_mode -> alloc_pages;
	nvhe_percpu_order	[label="unsigned long nvhe_percpu_order (void)
arch/arm64/kvm/arm.c:1798"];
	init_hyp_mode -> nvhe_percpu_order;
	page_address	[label="page_address()"];
	init_hyp_mode -> page_address;
	CHOOSE_NVHE_SYM	[label="CHOOSE_NVHE_SYM()"];
	init_hyp_mode -> CHOOSE_NVHE_SYM;
	nvhe_percpu_size	[label="unsigned long nvhe_percpu_size (void)
arch/arm64/kvm/arm.c:1792"];
	init_hyp_mode -> nvhe_percpu_size;
	kvm_nvhe_sym	[label="kvm_nvhe_sym()"];
	init_hyp_mode -> kvm_nvhe_sym;
	create_hyp_mappings	[label="int create_hyp_mappings (void *from, void *to, enum kvm_pgtable_prot prot)
arch/arm64/kvm/mmu.c:574"];
	init_hyp_mode -> create_hyp_mappings;
	kvm_ksym_ref	[label="kvm_ksym_ref()"];
	init_hyp_mode -> kvm_ksym_ref;
	per_cpu_ptr_nvhe_sym	[label="per_cpu_ptr_nvhe_sym()"];
	init_hyp_mode -> per_cpu_ptr_nvhe_sym;
	create_hyp_stack	[label="int create_hyp_stack (phys_addr_t phys_addr, unsigned long *haddr)
arch/arm64/kvm/mmu.c:691"];
	init_hyp_mode -> create_hyp_stack;
	cpu_prepare_hyp_mode	[label="void __init cpu_prepare_hyp_mode (int cpu, u32 hyp_va_bits)
arch/arm64/kvm/arm.c:1837"];
	init_hyp_mode -> cpu_prepare_hyp_mode;
	kvm_hyp_init_symbols	[label="void kvm_hyp_init_symbols (void)
arch/arm64/kvm/arm.c:2234"];
	init_hyp_mode -> kvm_hyp_init_symbols;
	IS_ENABLED	[label="IS_ENABLED()"];
	init_hyp_mode -> IS_ENABLED;
	pkvm_hyp_init_ptrauth	[label="void pkvm_hyp_init_ptrauth (void)
arch/arm64/kvm/arm.c:2267"];
	init_hyp_mode -> pkvm_hyp_init_ptrauth;
	init_cpu_logical_map	[label="void __init init_cpu_logical_map (void)
arch/arm64/kvm/arm.c:2080"];
	init_hyp_mode -> init_cpu_logical_map;
	init_psci_relay	[label="bool __init init_psci_relay (void)
arch/arm64/kvm/arm.c:2097"];
	init_hyp_mode -> init_psci_relay;
	kvm_hyp_init_protection	[label="int __init kvm_hyp_init_protection (u32 hyp_va_bits)
arch/arm64/kvm/arm.c:2249"];
	init_hyp_mode -> kvm_hyp_init_protection;
	kvm_init_vector_slots -> is_protected_kvm_enabled;
	kvm_init_vector_slots -> kvm_ksym_ref;
	kern_hyp_va	[label="kern_hyp_va()"];
	kvm_init_vector_slots -> kern_hyp_va;
	kvm_init_vector_slot	[label="void kvm_init_vector_slot (void *base, enum arm64_hyp_spectre_vector slot)
arch/arm64/kvm/arm.c:1808"];
	kvm_init_vector_slots -> kvm_init_vector_slot;
	kvm_system_needs_idmapped_vectors	[label="kvm_system_needs_idmapped_vectors()"];
	kvm_init_vector_slots -> kvm_system_needs_idmapped_vectors;
	create_hyp_exec_mappings	[label="int create_hyp_exec_mappings (phys_addr_t phys_addr, size_t size, void **haddr)
arch/arm64/kvm/mmu.c:778"];
	kvm_init_vector_slots -> create_hyp_exec_mappings;
	init_subsystems -> is_protected_kvm_enabled;
	init_subsystems -> on_each_cpu;
	cpu_hyp_init	[label="void cpu_hyp_init (void *discard)
arch/arm64/kvm/arm.c:1978"];
	init_subsystems -> cpu_hyp_init;
	hyp_cpu_pm_init	[label="inline void __init hyp_cpu_pm_init (void)
arch/arm64/kvm/arm.c:2072"];
	init_subsystems -> hyp_cpu_pm_init;
	kvm_vgic_hyp_init	[label="kvm_vgic_hyp_init()"];
	init_subsystems -> kvm_vgic_hyp_init;
	kvm_timer_hyp_init	[label="int __init kvm_timer_hyp_init (bool has_gic)
arch/arm64/kvm/arch_timer.c:1368"];
	init_subsystems -> kvm_timer_hyp_init;
	kvm_register_perf_callbacks	[label="void kvm_register_perf_callbacks (unsigned int (*pt_intr_handler) (void))
virt/kvm/kvm_main.c:6037"];
	init_subsystems -> kvm_register_perf_callbacks;
	hyp_cpu_pm_exit	[label="inline void __init hyp_cpu_pm_exit (void)
arch/arm64/kvm/arm.c:2075"];
	init_subsystems -> hyp_cpu_pm_exit;
	cpu_hyp_uninit	[label="void cpu_hyp_uninit (void *discard)
arch/arm64/kvm/arm.c:1986"];
	init_subsystems -> cpu_hyp_uninit;
	kvm_init -> pr_err;
	kvm_init -> WARN_ON_ONCE;
	kvm_init -> for_each_possible_cpu;
	kvm_init -> per_cpu;
	cpuhp_setup_state_nocalls	[label="cpuhp_setup_state_nocalls()"];
	kvm_init -> cpuhp_setup_state_nocalls;
	kvm_online_cpu	[label="int kvm_online_cpu (unsigned int cpu)
virt/kvm/kvm_main.c:5194"];
	kvm_init -> kvm_online_cpu;
	kvm_offline_cpu	[label="int kvm_offline_cpu (unsigned int cpu)
virt/kvm/kvm_main.c:5224"];
	kvm_init -> kvm_offline_cpu;
	register_syscore_ops	[label="register_syscore_ops()"];
	kvm_init -> register_syscore_ops;
	kmem_cache_create_usercopy	[label="kmem_cache_create_usercopy()"];
	kvm_init -> kmem_cache_create_usercopy;
	offsetof	[label="offsetof()"];
	kvm_init -> offsetof;
	offsetofend	[label="offsetofend()"];
	kvm_init -> offsetofend;
	alloc_cpumask_var_node	[label="alloc_cpumask_var_node()"];
	kvm_init -> alloc_cpumask_var_node;
	cpu_to_node	[label="cpu_to_node()"];
	kvm_init -> cpu_to_node;
	kvm_irqfd_init	[label="int kvm_irqfd_init (void)
virt/kvm/eventfd.c:685"];
	kvm_init -> kvm_irqfd_init;
	kvm_async_pf_init	[label="int kvm_async_pf_init (void)
virt/kvm/async_pf.c:22"];
	kvm_init -> kvm_async_pf_init;
	kvm_sched_in	[label="void kvm_sched_in (struct preempt_notifier *pn, int cpu)
virt/kvm/kvm_main.c:5950"];
	kvm_init -> kvm_sched_in;
	kvm_sched_out	[label="void kvm_sched_out (struct preempt_notifier *pn, struct task_struct *next)
virt/kvm/kvm_main.c:5962"];
	kvm_init -> kvm_sched_out;
	kvm_init_debug	[label="void kvm_init_debug (void)
virt/kvm/kvm_main.c:5913"];
	kvm_init -> kvm_init_debug;
	kvm_vfio_ops_init	[label="int kvm_vfio_ops_init (void)
virt/kvm/vfio.c:386"];
	kvm_init -> kvm_vfio_ops_init;
	misc_register	[label="misc_register()"];
	kvm_init -> misc_register;
	kvm_vfio_ops_exit	[label="void kvm_vfio_ops_exit (void)
virt/kvm/vfio.c:391"];
	kvm_init -> kvm_vfio_ops_exit;
	kvm_async_pf_deinit	[label="void kvm_async_pf_deinit (void)
virt/kvm/async_pf.c:32"];
	kvm_init -> kvm_async_pf_deinit;
	kvm_irqfd_exit	[label="void kvm_irqfd_exit (void)
virt/kvm/eventfd.c:694"];
	kvm_init -> kvm_irqfd_exit;
	free_cpumask_var	[label="free_cpumask_var()"];
	kvm_init -> free_cpumask_var;
	kmem_cache_destroy	[label="kmem_cache_destroy()"];
	kvm_init -> kmem_cache_destroy;
	unregister_syscore_ops	[label="unregister_syscore_ops()"];
	kvm_init -> unregister_syscore_ops;
	cpuhp_remove_state_nocalls	[label="cpuhp_remove_state_nocalls()"];
	kvm_init -> cpuhp_remove_state_nocalls;
	teardown_subsystems -> hyp_cpu_pm_exit;
	kvm_unregister_perf_callbacks	[label="void kvm_unregister_perf_callbacks (void)
virt/kvm/kvm_main.c:6042"];
	teardown_subsystems -> kvm_unregister_perf_callbacks;
	teardown_hyp_mode -> for_each_possible_cpu;
	teardown_hyp_mode -> per_cpu;
	teardown_hyp_mode -> nvhe_percpu_order;
	teardown_hyp_mode -> kvm_nvhe_sym;
	free_hyp_pgds	[label="void __init free_hyp_pgds (void)
arch/arm64/kvm/mmu.c:372"];
	teardown_hyp_mode -> free_hyp_pgds;
	free_page	[label="free_page()"];
	teardown_hyp_mode -> free_page;
	free_pages	[label="free_pages()"];
	teardown_hyp_mode -> free_pages;
	bitmap_free	[label="bitmap_free()"];
	kvm_arm_vmid_alloc_free -> bitmap_free;
	check_sysreg_table -> kvm_err;
	cmp_sys_reg	[label="cmp_sys_reg()"];
	check_sysreg_table -> cmp_sys_reg;
	populate_nv_trap_config -> cpus_have_final_cap;
	populate_nv_trap_config -> BIT;
	populate_nv_trap_config -> kvm_info;
	populate_nv_trap_config -> ARRAY_SIZE;
	BUILD_BUG_ON	[label="BUILD_BUG_ON()"];
	populate_nv_trap_config -> BUILD_BUG_ON;
	xa_destroy	[label="xa_destroy()"];
	populate_nv_trap_config -> xa_destroy;
	kvm_mmu_init -> BUG_ON;
	kvm_mmu_init -> kvm_debug;
	kvm_mmu_init -> kfree;
	kvm_mmu_init -> kvm_err;
	ALIGN_DOWN	[label="ALIGN_DOWN()"];
	kvm_mmu_init -> ALIGN_DOWN;
	ALIGN	[label="ALIGN()"];
	kvm_mmu_init -> ALIGN;
	max	[label="max()"];
	kvm_mmu_init -> max;
	kvm_mmu_init -> kern_hyp_va;
	kzalloc	[label="kzalloc()"];
	kvm_mmu_init -> kzalloc;
	kvm_pgtable_hyp_init	[label="kvm_pgtable_hyp_init()"];
	kvm_mmu_init -> kvm_pgtable_hyp_init;
	kvm_map_idmap_text	[label="int kvm_map_idmap_text (void)
arch/arm64/kvm/mmu.c:1832"];
	kvm_mmu_init -> kvm_map_idmap_text;
	kvm_pgtable_hyp_destroy	[label="kvm_pgtable_hyp_destroy()"];
	kvm_mmu_init -> kvm_pgtable_hyp_destroy;
	nvhe_percpu_order -> nvhe_percpu_size;
	get_order	[label="get_order()"];
	nvhe_percpu_order -> get_order;
	nvhe_percpu_size -> CHOOSE_NVHE_SYM;
	create_hyp_mappings -> is_kernel_in_hyp_mode;
	create_hyp_mappings -> kern_hyp_va;
	kvm_host_owns_hyp_mappings	[label="bool kvm_host_owns_hyp_mappings (void)
arch/arm64/kvm/mmu.c:383"];
	create_hyp_mappings -> kvm_host_owns_hyp_mappings;
	PAGE_ALIGN	[label="PAGE_ALIGN()"];
	create_hyp_mappings -> PAGE_ALIGN;
	kvm_kaddr_to_phys	[label="phys_addr_t kvm_kaddr_to_phys (void *kaddr)
arch/arm64/kvm/mmu.c:419"];
	create_hyp_mappings -> kvm_kaddr_to_phys;
	create_hyp_stack -> mutex_lock;
	create_hyp_stack -> mutex_unlock;
	create_hyp_stack -> kvm_err;
	create_hyp_stack -> ALIGN_DOWN;
	cpu_prepare_hyp_mode -> cpus_have_final_cap;
	cpu_prepare_hyp_mode -> read_sysreg;
	cpu_prepare_hyp_mode -> is_protected_kvm_enabled;
	cpu_prepare_hyp_mode -> CHOOSE_NVHE_SYM;
	cpu_prepare_hyp_mode -> kvm_ksym_ref;
	cpu_prepare_hyp_mode -> per_cpu_ptr_nvhe_sym;
	kasan_reset_tag	[label="kasan_reset_tag()"];
	cpu_prepare_hyp_mode -> kasan_reset_tag;
	TCR_T0SZ	[label="TCR_T0SZ()"];
	cpu_prepare_hyp_mode -> TCR_T0SZ;
	kvm_mmu_get_httbr	[label="phys_addr_t kvm_mmu_get_httbr (void)
arch/arm64/kvm/mmu.c:1822"];
	cpu_prepare_hyp_mode -> kvm_mmu_get_httbr;
	kvm_flush_dcache_to_poc	[label="kvm_flush_dcache_to_poc()"];
	cpu_prepare_hyp_mode -> kvm_flush_dcache_to_poc;
	kvm_hyp_init_symbols -> read_sanitised_ftr_reg;
	kvm_hyp_init_symbols -> kvm_nvhe_sym;
	get_hyp_id_aa64pfr0_el1	[label="u64 get_hyp_id_aa64pfr0_el1 (void)
arch/arm64/kvm/arm.c:2210"];
	kvm_hyp_init_symbols -> get_hyp_id_aa64pfr0_el1;
	pkvm_hyp_init_ptrauth -> get_random_long;
	pkvm_hyp_init_ptrauth -> for_each_possible_cpu;
	pkvm_hyp_init_ptrauth -> per_cpu_ptr_nvhe_sym;
	for_each_online_cpu	[label="for_each_online_cpu()"];
	init_cpu_logical_map -> for_each_online_cpu;
	cpu_logical_map	[label="cpu_logical_map()"];
	init_cpu_logical_map -> cpu_logical_map;
	init_psci_relay -> kvm_err;
	arm_smccc_get_version	[label="arm_smccc_get_version()"];
	init_psci_relay -> arm_smccc_get_version;
	PSCI_VERSION	[label="PSCI_VERSION()"];
	init_psci_relay -> PSCI_VERSION;
	get_psci_0_1_function_ids	[label="get_psci_0_1_function_ids()"];
	init_psci_relay -> get_psci_0_1_function_ids;
	init_psci_0_1_impl_state	[label="init_psci_0_1_impl_state()"];
	init_psci_relay -> init_psci_0_1_impl_state;
	kvm_hyp_init_protection -> create_hyp_mappings;
	phys_to_virt	[label="phys_to_virt()"];
	kvm_hyp_init_protection -> phys_to_virt;
	do_pkvm_init	[label="int __init do_pkvm_init (u32 hyp_va_bits)
arch/arm64/kvm/arm.c:2188"];
	kvm_hyp_init_protection -> do_pkvm_init;
	kvm_hyp_init_protection -> free_hyp_pgds;
	kvm_map_idmap_text -> kvm_err;
	kvm_host_owns_hyp_mappings -> WARN_ON;
	kvm_host_owns_hyp_mappings -> is_protected_kvm_enabled;
	kvm_host_owns_hyp_mappings -> is_kernel_in_hyp_mode;
	kvm_host_owns_hyp_mappings -> static_branch_likely;
	kvm_kaddr_to_phys -> BUG_ON;
	is_vmalloc_addr	[label="is_vmalloc_addr()"];
	kvm_kaddr_to_phys -> is_vmalloc_addr;
	virt_addr_valid	[label="virt_addr_valid()"];
	kvm_kaddr_to_phys -> virt_addr_valid;
	page_to_phys	[label="page_to_phys()"];
	kvm_kaddr_to_phys -> page_to_phys;
	vmalloc_to_page	[label="vmalloc_to_page()"];
	kvm_kaddr_to_phys -> vmalloc_to_page;
	offset_in_page	[label="offset_in_page()"];
	kvm_kaddr_to_phys -> offset_in_page;
	get_hyp_id_aa64pfr0_el1 -> read_sanitised_ftr_reg;
	get_hyp_id_aa64pfr0_el1 -> FIELD_PREP;
	get_hyp_id_aa64pfr0_el1 -> arm64_get_spectre_v2_state;
	ARM64_FEATURE_MASK	[label="ARM64_FEATURE_MASK()"];
	get_hyp_id_aa64pfr0_el1 -> ARM64_FEATURE_MASK;
	arm64_get_meltdown_state	[label="arm64_get_meltdown_state()"];
	get_hyp_id_aa64pfr0_el1 -> arm64_get_meltdown_state;
	do_pkvm_init -> preempt_disable;
	do_pkvm_init -> preempt_enable;
	do_pkvm_init -> cpu_hyp_init_context;
	do_pkvm_init -> cpu_hyp_init_features;
	do_pkvm_init -> kvm_call_hyp_nvhe;
	do_pkvm_init -> num_possible_cpus;
	do_pkvm_init -> kvm_nvhe_sym;
	do_pkvm_init -> kvm_ksym_ref;
	do_pkvm_init -> kern_hyp_va;
	free_hyp_pgds -> kfree;
	free_hyp_pgds -> mutex_lock;
	free_hyp_pgds -> mutex_unlock;
	free_hyp_pgds -> kvm_pgtable_hyp_destroy;
	create_hyp_exec_mappings -> BUG_ON;
	create_hyp_exec_mappings -> is_kernel_in_hyp_mode;
	cpu_hyp_init -> cpu_hyp_reinit;
	hyp_cpu_pm_init -> is_protected_kvm_enabled;
	cpu_pm_register_notifier	[label="cpu_pm_register_notifier()"];
	hyp_cpu_pm_init -> cpu_pm_register_notifier;
	kvm_timer_hyp_init -> has_vhe;
	kvm_timer_hyp_init -> kvm_debug;
	kvm_timer_hyp_init -> static_branch_enable;
	kvm_timer_hyp_init -> kvm_err;
	arch_timer_get_kvm_info	[label="arch_timer_get_kvm_info()"];
	kvm_timer_hyp_init -> arch_timer_get_kvm_info;
	kvm_irq_init	[label="int kvm_irq_init (struct arch_timer_kvm_info *info)
arch/arm64/kvm/arch_timer.c:1320"];
	kvm_timer_hyp_init -> kvm_irq_init;
	request_percpu_irq	[label="request_percpu_irq()"];
	kvm_timer_hyp_init -> request_percpu_irq;
	kvm_arch_timer_handler	[label="irqreturn_t kvm_arch_timer_handler (int irq, void *dev_id)
arch/arm64/kvm/arch_timer.c:224"];
	kvm_timer_hyp_init -> kvm_arch_timer_handler;
	kvm_get_running_vcpus	[label="struct kvm_vcpu *__percpu *kvm_get_running_vcpus (void)
virt/kvm/kvm_main.c:5999"];
	kvm_timer_hyp_init -> kvm_get_running_vcpus;
	irq_set_vcpu_affinity	[label="irq_set_vcpu_affinity()"];
	kvm_timer_hyp_init -> irq_set_vcpu_affinity;
	free_percpu_irq	[label="free_percpu_irq()"];
	kvm_timer_hyp_init -> free_percpu_irq;
	perf_register_guest_info_callbacks	[label="perf_register_guest_info_callbacks()"];
	kvm_register_perf_callbacks -> perf_register_guest_info_callbacks;
	hyp_cpu_pm_exit -> is_protected_kvm_enabled;
	cpu_pm_unregister_notifier	[label="cpu_pm_unregister_notifier()"];
	hyp_cpu_pm_exit -> cpu_pm_unregister_notifier;
	cpu_hyp_uninit -> cpu_hyp_reset;
	kvm_irq_init -> WARN_ON;
	kvm_irq_init -> kvm_err;
	kvm_irq_fixup_flags	[label="void kvm_irq_fixup_flags (unsigned int virq, u32 *flags)
arch/arm64/kvm/arch_timer.c:1310"];
	kvm_irq_init -> kvm_irq_fixup_flags;
	irq_domain_alloc_named_fwnode	[label="irq_domain_alloc_named_fwnode()"];
	kvm_irq_init -> irq_domain_alloc_named_fwnode;
	irq_get_irq_data	[label="irq_get_irq_data()"];
	kvm_irq_init -> irq_get_irq_data;
	irq_domain_create_hierarchy	[label="irq_domain_create_hierarchy()"];
	kvm_irq_init -> irq_domain_create_hierarchy;
	irq_domain_free_fwnode	[label="irq_domain_free_fwnode()"];
	kvm_irq_init -> irq_domain_free_fwnode;
	irq_domain_push_irq	[label="irq_domain_push_irq()"];
	kvm_irq_init -> irq_domain_push_irq;
	kvm_arch_timer_handler -> get_timer_map;
	kvm_arch_timer_handler -> kvm_timer_should_fire;
	kvm_arch_timer_handler -> kvm_timer_update_irq;
	kvm_arch_timer_handler -> userspace_irqchip;
	kvm_arch_timer_handler -> static_branch_unlikely;
	kvm_arch_timer_handler -> disable_percpu_irq;
	kvm_irq_fixup_flags -> kvm_err;
	irq_get_trigger_type	[label="irq_get_trigger_type()"];
	kvm_irq_fixup_flags -> irq_get_trigger_type;
	kvm_online_cpu -> mutex_lock;
	kvm_online_cpu -> mutex_unlock;
	kvm_offline_cpu -> mutex_lock;
	kvm_offline_cpu -> mutex_unlock;
	hardware_disable_nolock	[label="void hardware_disable_nolock (void *junk)
virt/kvm/kvm_main.c:5210"];
	kvm_offline_cpu -> hardware_disable_nolock;
	alloc_workqueue	[label="alloc_workqueue()"];
	kvm_irqfd_init -> alloc_workqueue;
	KMEM_CACHE	[label="KMEM_CACHE()"];
	kvm_async_pf_init -> KMEM_CACHE;
	kvm_sched_in -> WRITE_ONCE;
	kvm_sched_in -> kvm_arch_vcpu_load;
	preempt_notifier_to_vcpu	[label="inline struct kvm_vcpu *preempt_notifier_to_vcpu (struct preempt_notifier *pn)
virt/kvm/kvm_main.c:5945"];
	kvm_sched_in -> preempt_notifier_to_vcpu;
	kvm_arch_sched_in	[label="kvm_arch_sched_in()"];
	kvm_sched_in -> kvm_arch_sched_in;
	kvm_sched_out -> WRITE_ONCE;
	kvm_sched_out -> kvm_arch_vcpu_put;
	kvm_sched_out -> preempt_notifier_to_vcpu;
	debugfs_create_dir	[label="debugfs_create_dir()"];
	kvm_init_debug -> debugfs_create_dir;
	kvm_stats_debugfs_mode	[label="umode_t kvm_stats_debugfs_mode (const struct _kvm_stats_desc *pdesc)
virt/kvm/kvm_main.c:1014"];
	kvm_init_debug -> kvm_stats_debugfs_mode;
	debugfs_create_file	[label="debugfs_create_file()"];
	kvm_init_debug -> debugfs_create_file;
	kvm_register_device_ops	[label="int kvm_register_device_ops (const struct kvm_device_ops *ops, u32 type)
virt/kvm/kvm_main.c:4450"];
	kvm_vfio_ops_init -> kvm_register_device_ops;
	kvm_unregister_device_ops	[label="void kvm_unregister_device_ops (u32 type)
virt/kvm/kvm_main.c:4462"];
	kvm_vfio_ops_exit -> kvm_unregister_device_ops;
	kvm_async_pf_deinit -> kmem_cache_destroy;
	destroy_workqueue	[label="destroy_workqueue()"];
	kvm_irqfd_exit -> destroy_workqueue;
	kvm_arch_hardware_disable	[label="void kvm_arch_hardware_disable (void)
arch/arm64/kvm/arm.c:2014"];
	hardware_disable_nolock -> kvm_arch_hardware_disable;
	kvm_arch_hardware_disable -> is_protected_kvm_enabled;
	kvm_arch_hardware_disable -> cpu_hyp_uninit;
	kvm_timer_cpu_down	[label="void kvm_timer_cpu_down (void)
arch/arm64/kvm/arch_timer.c:1042"];
	kvm_arch_hardware_disable -> kvm_timer_cpu_down;
	kvm_vgic_cpu_down	[label="kvm_vgic_cpu_down()"];
	kvm_arch_hardware_disable -> kvm_vgic_cpu_down;
	kvm_timer_cpu_down -> disable_percpu_irq;
	preempt_notifier_to_vcpu -> container_of;
	kvm_register_device_ops -> ARRAY_SIZE;
	perf_unregister_guest_info_callbacks	[label="perf_unregister_guest_info_callbacks()"];
	kvm_unregister_perf_callbacks -> perf_unregister_guest_info_callbacks;
}
